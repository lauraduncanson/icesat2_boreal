{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2.7 ICESat-2 biomass algorithm development"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### i) Description\n",
    "#### This notebook uses the sparse ICESat-2 AGB estimates and remote sensing covariates data (ex. extracted from ALOS-2, Landsat 8 OLI, Sentinel 2A...etc) for calibrating and testing AGB models using parametric and non-parametric statistical modeling approaches, such as OLS, RF, k-NN, SVM and ANN. \n",
    "\n",
    "#### ii) How the algorithm works?\n",
    "#### Users must to select the number of bootstrapping runs (ex. 100). In each run, the original dataset is divided into training (ex. 70%) and testing (ex. 30%) datastes for model calibration and validation. Users can select if they want to create the training and testing dataset using a random or stratified random sampling approach. R2, RMSE and MD are computed based on the training dataset. \n",
    "\n",
    "#### iii) Inputs\n",
    "####  -rep: number of bootstrapping runs\n",
    "####  -yvar: name of the response variable in the dataset (ex. \"g_agbm\")\n",
    "####  -xvars: vector containing the name of the covariates\n",
    "####  -s_train: percentage used selected the training dataset (ex.70), \n",
    "####  -data: dataset as SpatialPolygonDataFrame object\n",
    "####  -strat: If TRUE the original dataset will be splitted into training and testing using the stratified random approach. Otherwise, the random approach will be used. \n",
    "####  -bin: AGB bin value for the stratified random approach. A samples with replacement will be selected randomly within each AGB bin.\n",
    "\n",
    "#### iii) Outputs\n",
    "#### List object containing:\n",
    "####  -model_testing_pred: AGB prediction for each bootstrapping run within the testing dataset (data.frame object)\n",
    "####  -model_testing_stats_summary: Summary of the model-derived statatistics \n",
    "####  -stats_maps_boots: R2, RMSE, MD..etc statistical parameters for the mapping dataset within for each bootstrapping run (data.frame object)\n",
    "####  -stats_maps_boots2: R2, RMSE, MD..etc statistical parameters for the mapping dataset within for each bootstrapping run (data.frame object) (just another way to represent the data in R)\n",
    "####  -models as R objects\n",
    "\n",
    "#----------------------------------------------#\n",
    "############# functions ########################\n",
    "#----------------------------------------------#\n",
    "\n",
    "# get _legend ggplot\n",
    "get_legend<-function(myggplot){\n",
    "  tmp <- ggplot_gtable(ggplot_build(myggplot))\n",
    "  leg <- which(sapply(tmp$grobs, function(x) x$name) == \"guide-box\")\n",
    "  legend <- tmp$grobs[[leg]]\n",
    "  return(legend)\n",
    "}\n",
    "\n",
    "#stratified random function\n",
    "stratSample<-function(agb,bin, p){\n",
    "  \n",
    "  n<-length(agb)\n",
    "  ids<-1:n\n",
    "  \n",
    "  s<-round(n*p)\n",
    "  breaks<-seq(0,round(max(agb))+bin,bin)\n",
    "  ids_cut<-cut(agb+0.000000000001,breaks=breaks, labels=F)\n",
    "  \n",
    "  df<-cbind(agb,ids,ids_cut)\n",
    "  number_sample<-ceiling(s/length(unique(df[,3])))\n",
    "  sel_all<-NULL\n",
    "  \n",
    "  for ( i in sort(unique(df[,3]))){\n",
    "    # print(i)\n",
    "    sel<-subset(df,df[,3]==i)\n",
    "    \n",
    "    if (!nrow(sel)==0) {\n",
    "      if (nrow(sel) > 1) {\n",
    "        ids_sub<-sample(1:nrow(sel), number_sample, replace=T)\n",
    "        \n",
    "      } else{\n",
    "        ids_sub<-rep(nrow(sel),number_sample)\n",
    "      }\n",
    "    }\n",
    "    sel_all<-rbind(sel_all,sel[ids_sub,])  \n",
    "  }\n",
    "  \n",
    "  #print(nrow(sel_all))\n",
    "  #par(mfrow=c(1,3))\n",
    "  #hist(agb, breaks=breaks, main=\"all\")\n",
    "  #hist(agb[sel_all[,2]], breaks=breaks,main=\"training\")\n",
    "  #hist(agb[-sel_all[,2]], breaks=breaks, main=\"testing\")\n",
    "  return(ids_selected=sel_all[,2])\n",
    "}\n",
    "\n",
    "\n",
    "# newtargets for k-NN imputation methods\n",
    "newtargets2<-function (object=fit.knn.eu,newdata=testData.x, k = NULL, ann = NULL) {\n",
    "  if (class(object) != \"yai\") \n",
    "    stop(\"object must be class yai\")\n",
    "  if (object$method == \"ensemble\") \n",
    "    stop(\"newtargets can not be found for objects with method 'ensemble'.\")\n",
    "  if (is.null(newdata) | nrow(newdata) == 0) \n",
    "    stop(\"newdata is required\")\n",
    "  if (object$method == \"gnn\") \n",
    "    if (!requireNamespace(\"vegan\")) \n",
    "      stop(\"install vegan and try again\")\n",
    "  if (object$method == \"randomForest\") \n",
    "    if (!requireNamespace(\"randomForest\")) \n",
    "      stop(\"install randomForest and try again\")\n",
    "  if (object$method == \"gower\") {\n",
    "    stop(\"install gower and try again\")\n",
    "    gower_topn <- function(...) NULL\n",
    "  } else {\n",
    "    gower_topn <- gower::gower_topn\n",
    "  }\n",
    "  if (!requireNamespace(\"gower\")) \n",
    "    stop(\"install gower and try again\")\n",
    "  sumSqDiff = function(x, y) {\n",
    "    d = x - y\n",
    "    sum(d * d)\n",
    "  }\n",
    "  factorMatch = get(\"factorMatch\", asNamespace(\"yaImpute\"))\n",
    "  if (is.null(ann)) \n",
    "    ann = object$ann\n",
    "  if (!is.null(k)) \n",
    "    object$k = k\n",
    "  object$call = match.call()\n",
    "  obsDropped = NULL\n",
    "  if (is.null(attr(newdata, \"illegalLevelCounts\")) && \n",
    "      length(intersect(xvars(object), names(object$xlevels))) > \n",
    "      0) {\n",
    "    newdata = factorMatch(newdata, object$xlevels)\n",
    "    if (is.list(attr(newdata, \"illegalLevelCounts\"))) {\n",
    "      warning(\"NA's generated due to illegal level(s).\")\n",
    "      cat(\"Illegal levels\\n\")\n",
    "      print(attr(newdata, \"illegalLevelCounts\"))\n",
    "    }\n",
    "  }\n",
    "  if (is.null(object$theFormula)) {\n",
    "    have = intersect(colnames(object$xRefs), colnames(newdata))\n",
    "    if (length(have) != length(colnames(object$xRefs))) {\n",
    "      missing = setdiff(colnames(object$xRefs), colnames(newdata))\n",
    "      stop(paste(\"required column(s) missing:\", paste(missing, \n",
    "                                                      collapse = \", \")))\n",
    "    }\n",
    "    xall = na.omit(data.frame(newdata[, have]))\n",
    "    colnames(xall)<-colnames(newdata)\n",
    "    row.names(xall)<-row.names(newdata)\n",
    "    obsDropped = names(attributes(na.omit(xall))$na.action)\n",
    "    if (length(obsDropped) > 0) \n",
    "      warning(nrow(newdata) - nrow(xall), \" observation(s) removed\")\n",
    "  } \n",
    "  else {\n",
    "    xall = model.frame(object$theFormula$x, newdata)\n",
    "    if (!is.null(object$xDrop)) \n",
    "      xall = xall[, !object$xDrop, drop = FALSE]\n",
    "    obsDropped = setdiff(rownames(newdata), rownames(xall))\n",
    "    if (length(obsDropped)) \n",
    "      warning(length(obsDropped), \" observation(s) removed\")\n",
    "  }\n",
    "  if (nrow(xall) == 0) \n",
    "    stop(\"no observations\")\n",
    "  trgs = setdiff(rownames(xall), rownames(object$xRefs))\n",
    "  if (nrow(xall) != length(trgs)) {\n",
    "    obsDropped = union(obsDropped, intersect(rownames(object$xRefs), \n",
    "                                             rownames(xall)))\n",
    "    warning(nrow(xall) - length(trgs), \" row(s) in newdata are original references and ignored\")\n",
    "  }\n",
    "  theCols = colnames(object$xRefs)\n",
    "  if (object$method %in% c(\"msn\", \"msn2\", \"msnPP\", \n",
    "                           \"mahalanobis\", \"ica\")) {\n",
    "    theCols = rownames(object$projector)\n",
    "    xcvRefs = scale(object$xRefs, center = object$xScale$center, \n",
    "                    scale = object$xScale$scale)\n",
    "    if (length(theCols) < ncol(xcvRefs)) \n",
    "      xcvRefs = xcvRefs[, theCols, drop = FALSE]\n",
    "  }\n",
    "  xTrgs = as.data.frame(xall[trgs, theCols, drop = FALSE])\n",
    "  if (nrow(xTrgs) == 0) \n",
    "    stop(\"no observations\")\n",
    "  if (object$method == \"gnn\") {\n",
    "    xcvRefs = predict(object$ccaVegan, type = \"lc\", \n",
    "                      rank = \"full\")\n",
    "    xcvRefs = xcvRefs %*% diag(sqrt(object$ccaVegan$CCA$eig/sum(object$ccaVegan$CCA$eig)))\n",
    "    xcvTrgs = scale(xTrgs, center = object$xScale$center, \n",
    "                    scale = object$xScale$scale)\n",
    "    xcvTrgs = predict(object$ccaVegan, newdata = as.data.frame(xcvTrgs), \n",
    "                      type = \"lc\", rank = \"full\")\n",
    "    xcvTrgs = xcvTrgs %*% diag(sqrt(object$ccaVegan$CCA$eig/sum(object$ccaVegan$CCA$eig)))\n",
    "    nVec = ncol(xcvRefs)\n",
    "  }\n",
    "  else if (object$method == \"randomForest\") {\n",
    "    nodes = NULL\n",
    "    predObs = if (is.null(attr(object$ranForest, \"rfRefNodeSort\"))) \n",
    "      rbind(object$xRefs, xTrgs)\n",
    "    else xTrgs\n",
    "    for (i in 1:length(object$ranForest)) {\n",
    "      nodeset = attr(predict(object$ranForest[[i]], predObs, \n",
    "                             proximity = FALSE, nodes = TRUE), \"nodes\")\n",
    "      if (is.null(nodeset)) \n",
    "        stop(\"randomForest did not return nodes\")\n",
    "      colnames(nodeset) = paste(colnames(nodeset), i, sep = \".\")\n",
    "      nodes = if (is.null(nodes)) \n",
    "        nodeset\n",
    "      else cbind(nodes, nodeset)\n",
    "    }\n",
    "    if (is.null(attr(object$ranForest, \"rfRefNodeSort\"))) {\n",
    "      INTrefNodes = as.integer(nodes[rownames(object$xRefs), \n",
    "      ])\n",
    "      INTnrow = as.integer(nrow(object$xRefs))\n",
    "      INTncol = as.integer(ncol(nodes))\n",
    "      INTsort = INTrefNodes\n",
    "      dim(INTsort) = c(INTnrow, INTncol)\n",
    "      INTsort = apply(INTsort, 2, function(x) sort(x, index.return = TRUE, \n",
    "                                                   decreasing = FALSE)$ix - 1)\n",
    "      attributes(INTsort) = NULL\n",
    "      INTsort = as.integer(INTsort)\n",
    "      nodes = nodes[rownames(xTrgs), ]\n",
    "    }\n",
    "    else {\n",
    "      INTrefNodes = attr(object$ranForest, \"rfRefNodeSort\")[[\"INTrefNodes\"]]\n",
    "      INTnrow = attr(object$ranForest, \"rfRefNodeSort\")[[\"INTnrow\"]]\n",
    "      INTncol = attr(object$ranForest, \"rfRefNodeSort\")[[\"INTncol\"]]\n",
    "      INTsort = attr(object$ranForest, \"rfRefNodeSort\")[[\"INTsort\"]]\n",
    "    }\n",
    "  }\n",
    "  else if (object$method == \"random\") {\n",
    "    xcvRefs = data.frame(random = runif(nrow(object$xRefs)), \n",
    "                         row.names = rownames(object$xRefs))\n",
    "    xcvTrgs = data.frame(random = runif(length(trgs)), row.names = trgs)\n",
    "  }\n",
    "  else if (object$method %in% c(\"msn\", \"msn2\", \n",
    "                                \"msnPP\", \"mahalanobis\", \"ica\")) {\n",
    "    xcvRefs = as.matrix(xcvRefs[, theCols, drop = FALSE]) %*% \n",
    "      object$projector\n",
    "    xcvTrgs = scale(xTrgs, center = object$xScale$center, \n",
    "                    scale = object$xScale$scale)\n",
    "    xcvTrgs = as.matrix(xcvTrgs[, theCols, drop = FALSE]) %*% \n",
    "      object$projector\n",
    "  }\n",
    "  else if (object$method == \"euclidean\") {\n",
    "    xcvRefs = scale(object$xRefs, center = object$xScale$center, \n",
    "                    scale = object$xScale$scale)\n",
    "    xcvRefs = as.matrix(xcvRefs[, theCols, drop = FALSE])\n",
    "    xcvTrgs = scale(xTrgs, center = object$xScale$center, \n",
    "                    scale = object$xScale$scale)\n",
    "    xcvTrgs = as.matrix(xcvTrgs[, theCols, drop = FALSE])\n",
    "  }\n",
    "  else if (object$method == \"gower\") {\n",
    "    xcvRefs = object$xRefs[, theCols, drop = FALSE]\n",
    "    xcvTrgs = xTrgs[, theCols, drop = FALSE]\n",
    "  }\n",
    "  else {\n",
    "    xcvRefs = as.matrix(object$xRefs[, theCols, drop = FALSE])\n",
    "    xcvTrgs = as.matrix(xTrgs[, theCols, drop = FALSE])\n",
    "  }\n",
    "  neiDstTrgs = matrix(data = NA, nrow = length(trgs), ncol = object$k)\n",
    "  rownames(neiDstTrgs) = trgs\n",
    "  colnames(neiDstTrgs) = paste(\"Dst.k\", 1:object$k, sep = \"\")\n",
    "  neiIdsTrgs = neiDstTrgs\n",
    "  colnames(neiIdsTrgs) = paste(\"Id.k\", 1:object$k, sep = \"\")\n",
    "  if (object$method %in% c(\"msn\", \"msn2\", \"msnPP\", \n",
    "                           \"mahalanobis\", \"ica\", \"euclidean\", \n",
    "                           \"gnn\", \"raw\")) {\n",
    "    if (ann & nrow(xcvTrgs) > 0) {\n",
    "      k = object$k\n",
    "      ann.out = ann(xcvRefs, xcvTrgs, k, verbose = FALSE)$knnIndexDist\n",
    "      neiDstTrgs[TRUE] = sqrt(ann.out[, (k + 1):ncol(ann.out)])\n",
    "      for (i in 1:k) neiIdsTrgs[, i] = rownames(xcvRefs)[ann.out[, \n",
    "                                                                 i]]\n",
    "      rownames(neiDstTrgs) = rownames(neiIdsTrgs)\n",
    "    }\n",
    "    else {\n",
    "      for (row in rownames(xcvTrgs)) {\n",
    "        d = sqrt(sort(apply(xcvRefs, MARGIN = 1, sumSqDiff, \n",
    "                            xcvTrgs[row, ])))[1:object$k]\n",
    "        neiDstTrgs[row, ] = d\n",
    "        neiIdsTrgs[row, ] = names(d)\n",
    "      }\n",
    "    }\n",
    "  }\n",
    "  else if (object$method == \"gower\") {\n",
    "    gow = gower_topn(x = xcvRefs, y = xcvTrgs, n = k)\n",
    "    for (i in 1:object$k) {\n",
    "      neiDstTrgs[, i] = gow$distance[i, ]\n",
    "      neiIdsTrgs[, i] = rownames(xcvTrgs)[gow$index[i, \n",
    "      ]]\n",
    "    }\n",
    "  }\n",
    "  else if (object$method == \"randomForest\") {\n",
    "    prox = lapply(apply(nodes, 1, as.list), function(x) {\n",
    "      prx = .Call(\"rfoneprox\", INTrefNodes, INTsort, \n",
    "                  INTnrow, INTncol, as.integer(x), vector(\"integer\", \n",
    "                                                          INTnrow))\n",
    "      if (object$k > 1) \n",
    "        px = sort(prx, index.return = TRUE, decreasing = TRUE)$ix[1:object$k]\n",
    "      else px = which.max(prx)\n",
    "      c(prx[px], px)\n",
    "    })\n",
    "    for (i in 1:object$k) {\n",
    "      neiDstTrgs[, i] = unlist(lapply(prox, function(x, \n",
    "                                                     i) (INTncol - x[i])/INTncol, i))\n",
    "      neiIdsTrgs[, i] = unlist(lapply(prox, function(x, \n",
    "                                                     i, k, Rnames) Rnames[x[k + i]], i, object$k, \n",
    "                                      rownames(object$xRefs)))\n",
    "    }\n",
    "  }\n",
    "  else if (object$method == \"random\") {\n",
    "    l = k + 1\n",
    "    d = matrix(unlist(lapply(xcvTrgs[[1]], function(x, xcv, \n",
    "                                                    l) {\n",
    "      sort((xcv - x)^2, index.return = TRUE)$ix[2:l]\n",
    "    }, xcvRefs[[1]], l)), nrow = nrow(xcvTrgs), ncol = k, \n",
    "    byrow = TRUE)\n",
    "    for (ic in 1:ncol(d)) {\n",
    "      neiDstTrgs[, ic] = abs(xcvTrgs[, 1] - xcvRefs[d[, \n",
    "                                                      ic], 1])\n",
    "      neiIdsTrgs[, ic] = rownames(xcvRefs)[d[, ic]]\n",
    "    }\n",
    "  }\n",
    "  else {\n",
    "    stop(\"no code for specified method\")\n",
    "  }\n",
    "  if (length(object$bootstrap) > 1) \n",
    "    neiIdsTrgs[] = sub(\"\\\\.[0-9]$\", \"\", neiIdsTrgs[])\n",
    "  object$obsDropped = obsDropped\n",
    "  object$trgRows = trgs\n",
    "  addX = setdiff(rownames(object$xRefs), rownames(xall))\n",
    "  if (length(addX) > 0) \n",
    "    xall = rbind(xall, object$xRefs[addX, ])\n",
    "  object$xall = xall\n",
    "  object$neiDstTrgs = neiDstTrgs\n",
    "  object$neiIdsTrgs = neiIdsTrgs\n",
    "  noRefs = TRUE\n",
    "  object$neiDstRefs = NULL\n",
    "  object$neiIdsRefs = NULL\n",
    "  object$ann = ann\n",
    "  object\n",
    "}\n",
    "\n",
    "\n",
    "# stats\n",
    "StatModel <- function( obs, est){\n",
    "  xy<-na.omit(cbind(obs,est))\n",
    "  obs<-xy[,1]\n",
    "  est<-xy[,2]\n",
    "  rmse <- sqrt( sum(( est - obs )^2)/length(obs) ) # Root mean square error\n",
    "  bias <- mean( est - obs ) # bias\n",
    "  rmseR <- 100 * sqrt( sum(( est - obs )^2)/length(obs) ) / mean( obs )\n",
    "  biasR <- 100 * mean( est - obs ) / mean( obs )\n",
    "  r <- cor(est,obs)\n",
    "  r2<-summary(lm(obs~est))$r.squared\n",
    "  Stats<-data.frame( Stat=c(\"rmse\",\"rmseR\",\"bias\",\"biasR\",\"r\",\"r2\"),\n",
    "                        Values=round(c(rmse,rmseR,bias,biasR,r,r2),2)) \n",
    "  return(Stats)\n",
    "}\n",
    "\n",
    "\n",
    "\n",
    "# modeling \n",
    "modelingAGB<-function(xvars=x_lope,yvar=y,s_train=50, rep=10,data=lope_grid,strat=T, bin=5){\n",
    "\n",
    "  \n",
    "  modeling<-na.omit(data)\n",
    "  y<-as.numeric(modeling[,yvar])\n",
    "  x<-data.frame(modeling[,xvars])\n",
    "  colnames(x)<-xvars\n",
    "  rownames(x)<-1:nrow(x)\n",
    "  maxV<-max(y)\n",
    "  prediction_df<-NULL\n",
    "  stats_df<-NULL\n",
    "  stats_df2<-NULL\n",
    "  lm.coef<-NULL\n",
    "  n<-nrow(x)\n",
    "  ids<-1:n\n",
    "  models_obj_lm<-list()\n",
    "  models_obj_rf<-list()\n",
    "  models_obj_knn<-list()\n",
    "  models_obj_svm<-list()\n",
    "  models_obj_nnt<-list()\n",
    "  \n",
    "  pb <- txtProgressBar(min = 0, max = rep, style = 3)\n",
    "  \n",
    "  #i=10\n",
    "  i.s=0\n",
    "  #j=1\n",
    "  \n",
    "  for ( j in 1:rep){\n",
    "    i.s<-i.s+1\n",
    "    setTxtProgressBar(pb, i.s)\n",
    "    \n",
    "    set.seed(j)\n",
    "    if ( strat==TRUE){\n",
    "      trainRowNumbers<-stratSample(agb=y,bin=bin, p=s_train/100)\n",
    "    } else {\n",
    "      trainRowNumbers<-sort(sample(ids,round(n*s_train/100), T))\n",
    "    }\n",
    "    \n",
    "    # Step 2: Create the training  dataset\n",
    "    # select % of data to training and testing the models\n",
    "    trainData.x <- x[trainRowNumbers,]\n",
    "    trainData.y <- y[trainRowNumbers]\n",
    "    \n",
    "    yscaled<-(y-mean(y))/sd(y)\n",
    "    trainData.yscaled<-yscaled[trainRowNumbers]\n",
    "    \n",
    "    # Step 3: Create the test dataset\n",
    "    # select % of the data for validation\n",
    "    testData.x <- x[!row.names(x) %in% trainRowNumbers,]\n",
    "    testData.y <- y[-trainRowNumbers]\n",
    "    test_id<-sort(ids[-c(trainRowNumbers)])\n",
    "    \n",
    "    # lm\n",
    "    fit.lm <- lm(trainData.y ~ ., data = trainData.x[,xvars])\n",
    "    models_obj_lm[[j]]<-fit.lm\n",
    "    pred.lm<-predict(fit.lm, newdata=testData.x) #\n",
    "    pred.lm<-cbind(method=rep(\"OLS\",length(pred.lm)), rep=rep(j,length(pred.lm)), id=test_id, pred=pred.lm)\n",
    "    stats.lm<-cbind(method=rep(\"OLS\",6), rep=rep(j,6), StatModel(obs=testData.y,est=as.numeric(paste0(pred.lm[,4]))))\n",
    "    \n",
    "    \n",
    "    # rf\n",
    "    set.seed(j)\n",
    "    fit.rf <- randomForest(y=trainData.y, x=trainData.x[,xvars], ntree=1000)\n",
    "    models_obj_rf[[j]]<-fit.rf\n",
    "    #pred.rf<-predict(fit.rf, newdata=cbind(testData.y,testData.x)) # \n",
    "    pred.rf<-predict(fit.rf, newdata=testData.x[,xvars]) # \n",
    "    pred.rf<-cbind(method=rep(\"RF\",length(pred.rf)), rep=rep(j,length(pred.rf)), id=test_id, pred=pred.rf) \n",
    "    stats.rf<-cbind(method=rep(\"RF\",6), rep=rep(j,6), StatModel(testData.y,as.numeric(pred.rf[,4])))\n",
    "    \n",
    "    \n",
    "    # knn msn\n",
    "    fit.knn.msn <- yai(x=trainData.x[,xvars],y=trainData.y,method=\"msn\", k=1)\n",
    "    varsub_knn.msn<-names(fit.knn.msn$xDrop[fit.knn.msn$xDrop==FALSE])\n",
    "    fit.knn.New.msn <- newtargets2(fit.knn.msn,testData.x[,varsub_knn.msn]) \n",
    "    models_obj_knn[[j]]<-fit.knn.msn\n",
    "    fit.knn.msn.pred<-predict(fit.knn.New.msn)[,1]\n",
    "    pred.knn.msn<-cbind(method=rep(\"kNN.MSN\",length(fit.knn.msn.pred)), rep=rep(j,length(fit.knn.msn.pred)),id=test_id, pred=fit.knn.msn.pred) \n",
    "    stats.knn.msn<-cbind(method=rep(\"kNN.MSN\"), rep=rep(j), StatModel(testData.y,as.numeric(pred.knn.msn[,4])))\n",
    "    \n",
    "    # svm\n",
    "    fit.svm2 <- svm(trainData.y~., data=trainData.x[,xvars])\n",
    "    pred.svm2<-predict(fit.svm2, newdata=testData.x[,xvars])  # \n",
    "    models_obj_svm[[j]]<-fit.svm2\n",
    "    pred.svm2<-cbind(method=rep(\"SVM\",length(pred.svm2)), rep=rep(j,length(pred.svm2)), id=test_id,pred=pred.svm2) \n",
    "    stats.svm2<-cbind(method=rep(\"SVM\"), rep=rep(j), StatModel(testData.y,as.numeric(pred.svm2[,4])))\n",
    "  \n",
    "    \n",
    "    # nnt\n",
    "    fit.nnt<- nnet(trainData.yscaled ~ ., data=trainData.x[,xvars], size = 40,skip=FALSE,linout=TRUE,maxit = 100, MaxNWts = 2000,trace=FALSE)\n",
    "    models_obj_nnt[[j]]<-fit.nnt\n",
    "    pred.nnt<-predict(fit.nnt, newdata=testData.x[,xvars])*sd(y)+mean(y) # \n",
    "    pred.nnt<-cbind(method=rep(\"ANN\",length(pred.nnt)), rep=rep(j,length(pred.nnt)), id=test_id,pred=pred.nnt) \n",
    "    stats.nnt<-cbind(method=rep(\"ANN\",6), rep=rep(j,6), StatModel(testData.y,as.numeric(pred.nnt[,4])))\n",
    "    \n",
    "    \n",
    "    ###\n",
    "    prediction_df<-rbind(prediction_df,\n",
    "                         pred.lm,\n",
    "                         pred.rf,\n",
    "                         pred.knn.msn,\n",
    "                         pred.svm2,\n",
    "                         pred.nnt)\n",
    "    row.names(prediction_df)<-1:nrow(prediction_df)\n",
    "    \n",
    "    stats_df<-rbind(stats_df,\n",
    "                    stats.lm,\n",
    "                    stats.rf,\n",
    "                    stats.knn.msn,\n",
    "                    stats.svm2,\n",
    "                    stats.nnt)\n",
    "    row.names(stats_df)<-1:nrow(stats_df)\n",
    "    \n",
    "    stats_df2<-rbind(stats_df2,cbind(stats.lm[,-1],stats.rf[,4],\n",
    "                                     stats.knn.msn[,4],stats.svm2[,4],stats.nnt[,4]))\n",
    "    row.names(stats_df2)<-1:nrow(stats_df2)\n",
    "  \n",
    "    }\n",
    "  \n",
    "  colnames(stats_df2)<-c(\"rep\",\"stats\",\"lm\",\"rf\",\"knn.msn\",'svm', 'nnt')\n",
    "  \n",
    "  models_obj<-list('lm'=models_obj_lm,'rf'=models_obj_rf,'knn'=models_obj_knn,'svm'=models_obj_svm,'nnt'=models_obj_nnt)\n",
    "  \n",
    "  mean_model_test_dt<-t(tapply(as.numeric(stats_df$Values), list(stats_df$method,stats_df$Stat), mean))[-c(3:4),]\n",
    "  sd_model_test_dt<-t(tapply(as.numeric(stats_df$Values), list(stats_df$method,stats_df$Stat), sd))[-c(3:4),]\n",
    "  \n",
    "  models_stats_testing_summary<-rbind(cbind(stats=row.names(mean_model_test_dt),stat=\"mean\",mean_model_test_dt),cbind(stats=row.names(sd_model_test_dt),stat=\"sd\",sd_model_test_dt))\n",
    "  \n",
    "  out_list<-list(as.data.frame(prediction_df),\n",
    "                   as.data.frame(stats_df),\n",
    "                   as.data.frame(stats_df2),\n",
    "                   as.data.frame(models_stats_testing_summary),\n",
    "                 models_obj)\n",
    "    names(out_list)<-c(\"model_testing_pred\", \"model_testing_stats\",\"model_testing_stats2\",\"model_testing_stats_summary\", 'model_objects')\n",
    "\n",
    "  close(pb)\n",
    "  return(out_list)\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "#----------------------------------------------#\n",
    "# packages\n",
    "#----------------------------------------------#\n",
    "require(pacman)\n",
    "pacman::p_load(ggplot2, randomForest, yaImpute, e1071, nnet,reshape2, fastICA, gridExtra)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table>\n",
       "<thead><tr><th scope=col>ice_agb</th><th scope=col>hh_m</th><th scope=col>hh_sd</th><th scope=col>hv_m</th><th scope=col>hv_sd</th></tr></thead>\n",
       "<tbody>\n",
       "\t<tr><td>402.1522   </td><td>0.1659377  </td><td>0.02466343 </td><td>0.06645742 </td><td>0.006023037</td></tr>\n",
       "\t<tr><td>437.9964   </td><td>0.1833907  </td><td>0.02042613 </td><td>0.07092674 </td><td>0.005671416</td></tr>\n",
       "\t<tr><td>512.2138   </td><td>0.2224556  </td><td>0.03130104 </td><td>0.07474914 </td><td>0.008067441</td></tr>\n",
       "\t<tr><td>371.6710   </td><td>0.2000149  </td><td>0.05551225 </td><td>0.06855195 </td><td>0.017578132</td></tr>\n",
       "\t<tr><td>442.7272   </td><td>0.1723135  </td><td>0.02935668 </td><td>0.06777547 </td><td>0.014859702</td></tr>\n",
       "\t<tr><td>607.5693   </td><td>0.2390938  </td><td>0.03433695 </td><td>0.07693132 </td><td>0.012046756</td></tr>\n",
       "</tbody>\n",
       "</table>\n"
      ],
      "text/latex": [
       "\\begin{tabular}{r|lllll}\n",
       " ice\\_agb & hh\\_m & hh\\_sd & hv\\_m & hv\\_sd\\\\\n",
       "\\hline\n",
       "\t 402.1522    & 0.1659377   & 0.02466343  & 0.06645742  & 0.006023037\\\\\n",
       "\t 437.9964    & 0.1833907   & 0.02042613  & 0.07092674  & 0.005671416\\\\\n",
       "\t 512.2138    & 0.2224556   & 0.03130104  & 0.07474914  & 0.008067441\\\\\n",
       "\t 371.6710    & 0.2000149   & 0.05551225  & 0.06855195  & 0.017578132\\\\\n",
       "\t 442.7272    & 0.1723135   & 0.02935668  & 0.06777547  & 0.014859702\\\\\n",
       "\t 607.5693    & 0.2390938   & 0.03433695  & 0.07693132  & 0.012046756\\\\\n",
       "\\end{tabular}\n"
      ],
      "text/markdown": [
       "\n",
       "| ice_agb | hh_m | hh_sd | hv_m | hv_sd |\n",
       "|---|---|---|---|---|\n",
       "| 402.1522    | 0.1659377   | 0.02466343  | 0.06645742  | 0.006023037 |\n",
       "| 437.9964    | 0.1833907   | 0.02042613  | 0.07092674  | 0.005671416 |\n",
       "| 512.2138    | 0.2224556   | 0.03130104  | 0.07474914  | 0.008067441 |\n",
       "| 371.6710    | 0.2000149   | 0.05551225  | 0.06855195  | 0.017578132 |\n",
       "| 442.7272    | 0.1723135   | 0.02935668  | 0.06777547  | 0.014859702 |\n",
       "| 607.5693    | 0.2390938   | 0.03433695  | 0.07693132  | 0.012046756 |\n",
       "\n"
      ],
      "text/plain": [
       "  ice_agb  hh_m      hh_sd      hv_m       hv_sd      \n",
       "1 402.1522 0.1659377 0.02466343 0.06645742 0.006023037\n",
       "2 437.9964 0.1833907 0.02042613 0.07092674 0.005671416\n",
       "3 512.2138 0.2224556 0.03130104 0.07474914 0.008067441\n",
       "4 371.6710 0.2000149 0.05551225 0.06855195 0.017578132\n",
       "5 442.7272 0.1723135 0.02935668 0.06777547 0.014859702\n",
       "6 607.5693 0.2390938 0.03433695 0.07693132 0.012046756"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#----------------------------------------------#\n",
    "# datasets\n",
    "#----------------------------------------------#\n",
    "df<-read.table(\"~/csilva/modeling_datasets/input_modeling.csv\", sep=\",\", head=T)\n",
    "head(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# parameters\n",
    "s_train=70\n",
    "bin=100\n",
    "xvars<-c(\"hh_m\",\"hh_sd\",\"hv_m\",\"hv_sd\")\n",
    "yvar='ice_agb'\n",
    "data=df\n",
    "rep=30\n",
    "strat=TRUE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  |======================================================================| 100%\n"
     ]
    }
   ],
   "source": [
    "# run \n",
    "agb_modeling_lope<-modelingAGB(yvar=yvar,xvars=xvars,s_train=s_train, rep=rep, data=data,strat=strat, bin=bin)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table>\n",
       "<thead><tr><th scope=col>method</th><th scope=col>rep</th><th scope=col>id</th><th scope=col>pred</th></tr></thead>\n",
       "<tbody>\n",
       "\t<tr><td>OLS             </td><td>1               </td><td>4               </td><td>763.024381190204</td></tr>\n",
       "\t<tr><td>OLS             </td><td>1               </td><td>8               </td><td>729.420853671502</td></tr>\n",
       "\t<tr><td>OLS             </td><td>1               </td><td>9               </td><td>720.500221213984</td></tr>\n",
       "\t<tr><td>OLS             </td><td>1               </td><td>10              </td><td>414.601308592863</td></tr>\n",
       "\t<tr><td>OLS             </td><td>1               </td><td>11              </td><td>652.689225311007</td></tr>\n",
       "\t<tr><td>OLS             </td><td>1               </td><td>12              </td><td>572.110199093587</td></tr>\n",
       "</tbody>\n",
       "</table>\n"
      ],
      "text/latex": [
       "\\begin{tabular}{r|llll}\n",
       " method & rep & id & pred\\\\\n",
       "\\hline\n",
       "\t OLS              & 1                & 4                & 763.024381190204\\\\\n",
       "\t OLS              & 1                & 8                & 729.420853671502\\\\\n",
       "\t OLS              & 1                & 9                & 720.500221213984\\\\\n",
       "\t OLS              & 1                & 10               & 414.601308592863\\\\\n",
       "\t OLS              & 1                & 11               & 652.689225311007\\\\\n",
       "\t OLS              & 1                & 12               & 572.110199093587\\\\\n",
       "\\end{tabular}\n"
      ],
      "text/markdown": [
       "\n",
       "| method | rep | id | pred |\n",
       "|---|---|---|---|\n",
       "| OLS              | 1                | 4                | 763.024381190204 |\n",
       "| OLS              | 1                | 8                | 729.420853671502 |\n",
       "| OLS              | 1                | 9                | 720.500221213984 |\n",
       "| OLS              | 1                | 10               | 414.601308592863 |\n",
       "| OLS              | 1                | 11               | 652.689225311007 |\n",
       "| OLS              | 1                | 12               | 572.110199093587 |\n",
       "\n"
      ],
      "text/plain": [
       "  method rep id pred            \n",
       "1 OLS    1   4  763.024381190204\n",
       "2 OLS    1   8  729.420853671502\n",
       "3 OLS    1   9  720.500221213984\n",
       "4 OLS    1   10 414.601308592863\n",
       "5 OLS    1   11 652.689225311007\n",
       "6 OLS    1   12 572.110199093587"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# predictions - testing dataset\n",
    "head(agb_modeling_lope$model_testing_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table>\n",
       "<thead><tr><th scope=col>method</th><th scope=col>rep</th><th scope=col>Stat</th><th scope=col>Values</th></tr></thead>\n",
       "<tbody>\n",
       "\t<tr><td>OLS   </td><td>1     </td><td>rmse  </td><td>274.41</td></tr>\n",
       "\t<tr><td>OLS   </td><td>1     </td><td>rmseR </td><td>116.05</td></tr>\n",
       "\t<tr><td>OLS   </td><td>1     </td><td>bias  </td><td>210.10</td></tr>\n",
       "\t<tr><td>OLS   </td><td>1     </td><td>biasR </td><td> 88.86</td></tr>\n",
       "\t<tr><td>OLS   </td><td>1     </td><td>r     </td><td>  0.73</td></tr>\n",
       "\t<tr><td>OLS   </td><td>1     </td><td>r2    </td><td>  0.53</td></tr>\n",
       "</tbody>\n",
       "</table>\n"
      ],
      "text/latex": [
       "\\begin{tabular}{r|llll}\n",
       " method & rep & Stat & Values\\\\\n",
       "\\hline\n",
       "\t OLS    & 1      & rmse   & 274.41\\\\\n",
       "\t OLS    & 1      & rmseR  & 116.05\\\\\n",
       "\t OLS    & 1      & bias   & 210.10\\\\\n",
       "\t OLS    & 1      & biasR  &  88.86\\\\\n",
       "\t OLS    & 1      & r      &   0.73\\\\\n",
       "\t OLS    & 1      & r2     &   0.53\\\\\n",
       "\\end{tabular}\n"
      ],
      "text/markdown": [
       "\n",
       "| method | rep | Stat | Values |\n",
       "|---|---|---|---|\n",
       "| OLS    | 1      | rmse   | 274.41 |\n",
       "| OLS    | 1      | rmseR  | 116.05 |\n",
       "| OLS    | 1      | bias   | 210.10 |\n",
       "| OLS    | 1      | biasR  |  88.86 |\n",
       "| OLS    | 1      | r      |   0.73 |\n",
       "| OLS    | 1      | r2     |   0.53 |\n",
       "\n"
      ],
      "text/plain": [
       "  method rep Stat  Values\n",
       "1 OLS    1   rmse  274.41\n",
       "2 OLS    1   rmseR 116.05\n",
       "3 OLS    1   bias  210.10\n",
       "4 OLS    1   biasR  88.86\n",
       "5 OLS    1   r       0.73\n",
       "6 OLS    1   r2      0.53"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<table>\n",
       "<thead><tr><th scope=col>rep</th><th scope=col>stats</th><th scope=col>lm</th><th scope=col>rf</th><th scope=col>knn.msn</th><th scope=col>svm</th><th scope=col>nnt</th></tr></thead>\n",
       "<tbody>\n",
       "\t<tr><td>1     </td><td>rmse  </td><td>274.41</td><td>111.30</td><td>184.60</td><td>245.73</td><td>245.90</td></tr>\n",
       "\t<tr><td>1     </td><td>rmseR </td><td>116.05</td><td> 47.07</td><td> 78.07</td><td>103.92</td><td>104.00</td></tr>\n",
       "\t<tr><td>1     </td><td>bias  </td><td>210.10</td><td> 67.85</td><td> 48.68</td><td>148.67</td><td>119.82</td></tr>\n",
       "\t<tr><td>1     </td><td>biasR </td><td> 88.86</td><td> 28.69</td><td> 20.59</td><td> 62.88</td><td> 50.67</td></tr>\n",
       "\t<tr><td>1     </td><td>r     </td><td>  0.73</td><td>  0.78</td><td>  0.46</td><td>  0.62</td><td>  0.60</td></tr>\n",
       "\t<tr><td>1     </td><td>r2    </td><td>  0.53</td><td>  0.61</td><td>  0.21</td><td>  0.38</td><td>  0.36</td></tr>\n",
       "</tbody>\n",
       "</table>\n"
      ],
      "text/latex": [
       "\\begin{tabular}{r|lllllll}\n",
       " rep & stats & lm & rf & knn.msn & svm & nnt\\\\\n",
       "\\hline\n",
       "\t 1      & rmse   & 274.41 & 111.30 & 184.60 & 245.73 & 245.90\\\\\n",
       "\t 1      & rmseR  & 116.05 &  47.07 &  78.07 & 103.92 & 104.00\\\\\n",
       "\t 1      & bias   & 210.10 &  67.85 &  48.68 & 148.67 & 119.82\\\\\n",
       "\t 1      & biasR  &  88.86 &  28.69 &  20.59 &  62.88 &  50.67\\\\\n",
       "\t 1      & r      &   0.73 &   0.78 &   0.46 &   0.62 &   0.60\\\\\n",
       "\t 1      & r2     &   0.53 &   0.61 &   0.21 &   0.38 &   0.36\\\\\n",
       "\\end{tabular}\n"
      ],
      "text/markdown": [
       "\n",
       "| rep | stats | lm | rf | knn.msn | svm | nnt |\n",
       "|---|---|---|---|---|---|---|\n",
       "| 1      | rmse   | 274.41 | 111.30 | 184.60 | 245.73 | 245.90 |\n",
       "| 1      | rmseR  | 116.05 |  47.07 |  78.07 | 103.92 | 104.00 |\n",
       "| 1      | bias   | 210.10 |  67.85 |  48.68 | 148.67 | 119.82 |\n",
       "| 1      | biasR  |  88.86 |  28.69 |  20.59 |  62.88 |  50.67 |\n",
       "| 1      | r      |   0.73 |   0.78 |   0.46 |   0.62 |   0.60 |\n",
       "| 1      | r2     |   0.53 |   0.61 |   0.21 |   0.38 |   0.36 |\n",
       "\n"
      ],
      "text/plain": [
       "  rep stats lm     rf     knn.msn svm    nnt   \n",
       "1 1   rmse  274.41 111.30 184.60  245.73 245.90\n",
       "2 1   rmseR 116.05  47.07  78.07  103.92 104.00\n",
       "3 1   bias  210.10  67.85  48.68  148.67 119.82\n",
       "4 1   biasR  88.86  28.69  20.59   62.88  50.67\n",
       "5 1   r       0.73   0.78   0.46    0.62   0.60\n",
       "6 1   r2      0.53   0.61   0.21    0.38   0.36"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<table>\n",
       "<thead><tr><th></th><th scope=col>stats</th><th scope=col>stat</th><th scope=col>OLS</th><th scope=col>RF</th><th scope=col>kNN.MSN</th><th scope=col>SVM</th><th scope=col>ANN</th></tr></thead>\n",
       "<tbody>\n",
       "\t<tr><th scope=row>bias</th><td>bias            </td><td>mean            </td><td>199.441666666667</td><td>53.2246666666667</td><td>36.9536666666667</td><td>129.528666666667</td><td>120.233333333333</td></tr>\n",
       "\t<tr><th scope=row>biasR</th><td>biasR           </td><td>mean            </td><td>84.0026666666667</td><td>22.4226666666667</td><td>15.5636666666667</td><td>54.5483333333333</td><td>50.6573333333333</td></tr>\n",
       "\t<tr><th scope=row>rmse</th><td>rmse            </td><td>mean            </td><td>272.326666666667</td><td>105.015666666667</td><td>173.712333333333</td><td>233.958         </td><td>246.390666666667</td></tr>\n",
       "\t<tr><th scope=row>rmseR</th><td>rmseR           </td><td>mean            </td><td>114.700333333333</td><td>44.234          </td><td>73.1643333333333</td><td>98.5396666666667</td><td>103.763         </td></tr>\n",
       "\t<tr><th scope=row>bias.1</th><td>bias            </td><td>sd              </td><td>10.8293509479573</td><td>6.01598888785963</td><td>11.1791241663395</td><td>12.4895240883719</td><td>25.3696775744172</td></tr>\n",
       "\t<tr><th scope=row>biasR.1</th><td>biasR           </td><td>sd              </td><td>4.56612257854504</td><td>2.57521064867662</td><td>4.70641344032421</td><td>5.17746715025349</td><td>10.7642165604804</td></tr>\n",
       "\t<tr><th scope=row>rmse.1</th><td>rmse            </td><td>sd              </td><td>9.25831754036126</td><td>3.76596434811382</td><td>13.6184881138013</td><td>7.99780116333708</td><td>39.8421509540296</td></tr>\n",
       "\t<tr><th scope=row>rmseR.1</th><td>rmseR           </td><td>sd              </td><td>3.86095528944929</td><td>1.66527951469685</td><td>5.71944034116031</td><td>3.35518279817887</td><td>16.6160134955036</td></tr>\n",
       "</tbody>\n",
       "</table>\n"
      ],
      "text/latex": [
       "\\begin{tabular}{r|lllllll}\n",
       "  & stats & stat & OLS & RF & kNN.MSN & SVM & ANN\\\\\n",
       "\\hline\n",
       "\tbias & bias             & mean             & 199.441666666667 & 53.2246666666667 & 36.9536666666667 & 129.528666666667 & 120.233333333333\\\\\n",
       "\tbiasR & biasR            & mean             & 84.0026666666667 & 22.4226666666667 & 15.5636666666667 & 54.5483333333333 & 50.6573333333333\\\\\n",
       "\trmse & rmse             & mean             & 272.326666666667 & 105.015666666667 & 173.712333333333 & 233.958          & 246.390666666667\\\\\n",
       "\trmseR & rmseR            & mean             & 114.700333333333 & 44.234           & 73.1643333333333 & 98.5396666666667 & 103.763         \\\\\n",
       "\tbias.1 & bias             & sd               & 10.8293509479573 & 6.01598888785963 & 11.1791241663395 & 12.4895240883719 & 25.3696775744172\\\\\n",
       "\tbiasR.1 & biasR            & sd               & 4.56612257854504 & 2.57521064867662 & 4.70641344032421 & 5.17746715025349 & 10.7642165604804\\\\\n",
       "\trmse.1 & rmse             & sd               & 9.25831754036126 & 3.76596434811382 & 13.6184881138013 & 7.99780116333708 & 39.8421509540296\\\\\n",
       "\trmseR.1 & rmseR            & sd               & 3.86095528944929 & 1.66527951469685 & 5.71944034116031 & 3.35518279817887 & 16.6160134955036\\\\\n",
       "\\end{tabular}\n"
      ],
      "text/markdown": [
       "\n",
       "| <!--/--> | stats | stat | OLS | RF | kNN.MSN | SVM | ANN |\n",
       "|---|---|---|---|---|---|---|---|\n",
       "| bias | bias             | mean             | 199.441666666667 | 53.2246666666667 | 36.9536666666667 | 129.528666666667 | 120.233333333333 |\n",
       "| biasR | biasR            | mean             | 84.0026666666667 | 22.4226666666667 | 15.5636666666667 | 54.5483333333333 | 50.6573333333333 |\n",
       "| rmse | rmse             | mean             | 272.326666666667 | 105.015666666667 | 173.712333333333 | 233.958          | 246.390666666667 |\n",
       "| rmseR | rmseR            | mean             | 114.700333333333 | 44.234           | 73.1643333333333 | 98.5396666666667 | 103.763          |\n",
       "| bias.1 | bias             | sd               | 10.8293509479573 | 6.01598888785963 | 11.1791241663395 | 12.4895240883719 | 25.3696775744172 |\n",
       "| biasR.1 | biasR            | sd               | 4.56612257854504 | 2.57521064867662 | 4.70641344032421 | 5.17746715025349 | 10.7642165604804 |\n",
       "| rmse.1 | rmse             | sd               | 9.25831754036126 | 3.76596434811382 | 13.6184881138013 | 7.99780116333708 | 39.8421509540296 |\n",
       "| rmseR.1 | rmseR            | sd               | 3.86095528944929 | 1.66527951469685 | 5.71944034116031 | 3.35518279817887 | 16.6160134955036 |\n",
       "\n"
      ],
      "text/plain": [
       "        stats stat OLS              RF               kNN.MSN         \n",
       "bias    bias  mean 199.441666666667 53.2246666666667 36.9536666666667\n",
       "biasR   biasR mean 84.0026666666667 22.4226666666667 15.5636666666667\n",
       "rmse    rmse  mean 272.326666666667 105.015666666667 173.712333333333\n",
       "rmseR   rmseR mean 114.700333333333 44.234           73.1643333333333\n",
       "bias.1  bias  sd   10.8293509479573 6.01598888785963 11.1791241663395\n",
       "biasR.1 biasR sd   4.56612257854504 2.57521064867662 4.70641344032421\n",
       "rmse.1  rmse  sd   9.25831754036126 3.76596434811382 13.6184881138013\n",
       "rmseR.1 rmseR sd   3.86095528944929 1.66527951469685 5.71944034116031\n",
       "        SVM              ANN             \n",
       "bias    129.528666666667 120.233333333333\n",
       "biasR   54.5483333333333 50.6573333333333\n",
       "rmse    233.958          246.390666666667\n",
       "rmseR   98.5396666666667 103.763         \n",
       "bias.1  12.4895240883719 25.3696775744172\n",
       "biasR.1 5.17746715025349 10.7642165604804\n",
       "rmse.1  7.99780116333708 39.8421509540296\n",
       "rmseR.1 3.35518279817887 16.6160134955036"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# model stats - testing dataset\n",
    "head(agb_modeling_lope$model_testing_stats)\n",
    "head(agb_modeling_lope$model_testing_stats2)\n",
    "agb_modeling_lope$model_testing_stats_summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save models as R objects\n",
    "saveRDS(agb_modeling_lope$model_objects, file = \"~/csilva/modeling_datasets/models_r_object.rds\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "#----------------------------------------------#\n",
    "# Visualizing stats over the testing datasets\n",
    "#----------------------------------------------#\n",
    "statsAGB_r2_lope<-agb_modeling_lope$model_testing_stats2[which(agb_modeling_lope$model_testing_stats2$stats==\"r2\"),]\n",
    "statsAGB_biasR_lope<-agb_modeling_lope$model_testing_stats2[which(agb_modeling_lope$model_testing_stats2$stats==\"biasR\"),]\n",
    "statsAGB_rmseR_lope<-agb_modeling_lope$model_testing_stats2[which(agb_modeling_lope$model_testing_stats2$stats==\"rmseR\"),]\n",
    "\n",
    "\n",
    "# plot boxplot for rmseR\n",
    "dfmelt_rmse <- melt(statsAGB_rmseR_lope, measure.vars=3:7)\n",
    "colnames(dfmelt_rmse)[3]<-\"method\"\n",
    "rmse_gg<-ggplot(dfmelt_rmse, aes(x=factor(method), y=value, fill=method))+\n",
    "  geom_boxplot()+\n",
    "  #facet_wrap(~scenario, ncol=5)+#facet_grid(.~variable)+\n",
    "  labs(x=\"\", y=\"RMSE (%)\")+\n",
    "  scale_y_continuous(limits = c(min(dfmelt_rmse$value), max(dfmelt_rmse$value))) + theme(legend.position=\"bottom\")#+ theme(legend.position = \"none\") \n",
    "\n",
    "# plot boxplot for r2\n",
    "dfmelt_r2 <- melt(statsAGB_r2_lope, measure.vars=3:7)\n",
    "colnames(dfmelt_r2)[3]<-\"method\"\n",
    "r2_gg<-ggplot(dfmelt_r2, aes(x=method,  y=value, fill=method))+\n",
    "  geom_boxplot()+\n",
    "  labs(x=\"\", y=expression(\"\"~ R^2 ~\"\"))+\n",
    "  scale_y_continuous(limits = c(min(dfmelt_r2$value), max(dfmelt_r2$value)))+ theme(legend.position = \"none\")\n",
    "\n",
    "# plot boxplot for bias\n",
    "dfmelt_bias <- melt(statsAGB_biasR_lope, measure.vars=3:7)\n",
    "colnames(dfmelt_bias)[3]<-\"method\"\n",
    "bias_gg<-ggplot(dfmelt_bias, aes(x=method, y=value, fill=method))+\n",
    "  geom_boxplot()+\n",
    "  labs(x=\"\", y=\"MD (%)\")+\n",
    "  scale_y_continuous(limits = c(min(dfmelt_bias$value), max(dfmelt_bias$value)))+ theme(legend.position = \"none\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAA8AAAAFoCAIAAAAXZAVmAAAACXBIWXMAABJ0AAASdAHeZh94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\nP+lOAn9JM9QWAAAAAElFTkSuQmCC",
      "text/plain": [
       "plot without title"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# combine all boxplot figures\n",
    "options(repr.plot.width=8, repr.plot.height=3)\n",
    "grid.arrange(r2_gg,rmse_gg+ theme(legend.position=\"none\"),bias_gg, get_legend(rmse_gg), ncol=3, nrow = 2, \n",
    "             layout_matrix = rbind(c(1,2,3), c(5,4,6)),\n",
    "             widths = rep(5,3), heights = c(2,0.1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "R",
   "language": "R",
   "name": "ir"
  },
  "language_info": {
   "codemirror_mode": "r",
   "file_extension": ".r",
   "mimetype": "text/x-r-source",
   "name": "R",
   "pygments_lexer": "r",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
