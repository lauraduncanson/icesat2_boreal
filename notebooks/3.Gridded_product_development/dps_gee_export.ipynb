{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "134e71b5-9b53-47cd-a14b-c1c4f5fba92b",
   "metadata": {},
   "source": [
    "# DPS the export of Google Earth Engine assets to MAAP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7de2ce36-ba9b-4cc6-a564-2870ef776cd1",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import ee\n",
    "import numpy as np\n",
    "import geopandas as gpd\n",
    "import pandas as pd\n",
    "import shapely\n",
    "import glob\n",
    "import os\n",
    "from shapely.geometry import Polygon\n",
    "from shapely.geometry import box\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import rasterio as rio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d27b0756-24f2-42d4-ae65-4f58c809703d",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<p>To authorize access needed by Earth Engine, open the following\n",
       "        URL in a web browser and follow the instructions:</p>\n",
       "        <p><a href=https://code.earthengine.google.com/client-auth?scopes=https%3A//www.googleapis.com/auth/earthengine%20https%3A//www.googleapis.com/auth/devstorage.full_control&request_id=Fz5SQu6THyaesqPiw-Lo8NNRjX35rpSdU6Ne889CY5U&tc=08YgHzeCs3IlskKJOg3K1aTm2Q0ZurSAZ6dg2hlL8Y4&cc=IWD-NBoxMtuUIjoGYBilAA5vbLyYA3ILyxqTaqn792Y>https://code.earthengine.google.com/client-auth?scopes=https%3A//www.googleapis.com/auth/earthengine%20https%3A//www.googleapis.com/auth/devstorage.full_control&request_id=Fz5SQu6THyaesqPiw-Lo8NNRjX35rpSdU6Ne889CY5U&tc=08YgHzeCs3IlskKJOg3K1aTm2Q0ZurSAZ6dg2hlL8Y4&cc=IWD-NBoxMtuUIjoGYBilAA5vbLyYA3ILyxqTaqn792Y</a></p>\n",
       "        <p>The authorization workflow will generate a code, which you should paste in the box below.</p>\n",
       "        "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Enter verification code:  4/1Adeu5BUFhHW_VJ9duMcJoLciH30AuZ63vUqbYwkUzpN5rf05ZjvJ9Ma7z3c\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Successfully saved authorization token.\n"
     ]
    }
   ],
   "source": [
    "ee.Authenticate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "23267b0e-9d5e-49e6-aeff-68ce8cceac8e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "!cp $HOME/.config/earthengine/credentials /$HOME/shared-buckets/nathanmthomas/GEE/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e75492d1-7330-4b15-8022-1a45ec95a6f9",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "creds_file = 'https://maap-ops-workspace.s3.amazonaws.com/nathanmthomas/GEE/credentials'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9dc791c9-3983-4507-80ac-21b22415dbc8",
   "metadata": {},
   "source": [
    "## Steps to commit, build DPS registration yaml, register DPS algorithm from yaml\n",
    "### Commit with Tag for running\n",
    "1) Add version name as a *tag_name* of `EXPORT_GEE_v1` or whatever is appropriate - both to this notebook and algorithm config yaml\n",
    "\n",
    "2) follow git instructions (every time!!):  \n",
    " - git add changes  \n",
    " - git commit -m 'message'  \n",
    " - git tag -f `EXPORT_GEE_v1`    \n",
    " - git push  \n",
    " - git push origin -f `EXPORT_GEE_v1`  \n",
    "        # --push to gitlab no longer needed --   \n",
    "        # git push dps    \n",
    "        # git push dps -f `EXPORT_GEE_v1`    \n",
    "\n",
    "3) if it looks weird check git log to make sure tag is at same place as origin and dps"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce010981-79b0-4bbe-90e0-f881bf2f3e3c",
   "metadata": {},
   "source": [
    "### Build DPS Registration yaml  \n",
    "- use MAAP Register Algorithm tool  \n",
    "- refer to `code/icesat2_boreal/dps/registered/do_export_gee_to_maap.yml` for existing template  \n",
    "- update reg yaml repository url to the github url (gitlab no longer needed) \n",
    "- update `above_env.yml` and `build_command_main.sh` to include all pinned versions of packages - to ensure stability of env for this alg  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9bb0a0ed-5875-4049-b7be-5e005a7b9453",
   "metadata": {},
   "source": [
    "# Register algorithm"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0df7662-b8a6-4cf5-a525-2092d65de346",
   "metadata": {},
   "source": [
    "### Use Registration yaml: Register DPS algorithm\n",
    " - We need to register the DPS algorithm before proceeding to the chunks below..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "id": "d1dd19a1-fc8d-473f-b650-3d2460d7736f",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'{\"code\": 200, \"message\": {\"id\": \"1042d2d1484db380c5bcd3640e1929f9e1f4c309\", \"short_id\": \"1042d2d1\", \"created_at\": \"2023-07-19T21:12:02.000+00:00\", \"parent_ids\": [\"d4dde57d3c81d02acdf1634a9a5308fea33cc542\"], \"title\": \"Registering algorithm: do_HLS_stack_3-1-2\", \"message\": \"Registering algorithm: do_HLS_stack_3-1-2\", \"author_name\": \"root\", \"author_email\": \"root@a69d8486d28b\", \"authored_date\": \"2023-07-19T21:12:02.000+00:00\", \"committer_name\": \"root\", \"committer_email\": \"root@a69d8486d28b\", \"committed_date\": \"2023-07-19T21:12:02.000+00:00\", \"trailers\": {}, \"web_url\": \"https://repo.maap-project.org/root/register-job-hysds-v4/-/commit/1042d2d1484db380c5bcd3640e1929f9e1f4c309\", \"stats\": {\"additions\": 0, \"deletions\": 0, \"total\": 0}, \"status\": \"pending\", \"project_id\": 3, \"last_pipeline\": {\"id\": 515, \"iid\": 59, \"project_id\": 3, \"sha\": \"1042d2d1484db380c5bcd3640e1929f9e1f4c309\", \"ref\": \"main\", \"status\": \"pending\", \"source\": \"push\", \"created_at\": \"2023-07-19T21:12:03.205Z\", \"updated_at\": \"2023-07-19T21:12:03.542Z\", \"web_url\": \"https://repo.maap-project.org/root/register-job-hysds-v4/-/pipelines/515\"}, \"job_web_url\": \"https://repo.maap-project.org/root/register-job-hysds-v4/-/jobs/678\", \"job_log_url\": \"https://repo.maap-project.org/root/register-job-hysds-v4/-/jobs/678/raw\"}}\\n'"
      ]
     },
     "execution_count": 152,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "maap.register_algorithm_from_yaml_file(\"/projects/code/icesat2_boreal/dps/registered/do_export_gee_to_maap.yml\").text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd58b017-38aa-4098-a6e6-29168ff3d2e1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 310,
   "id": "5fb1100d-48dc-4c15-90ce-8727b0e27330",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# MAAP algorithm version name\n",
    "MAAP_VERSION = \"EXPORT_GEE_v1\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 311,
   "id": "44ba70a8-935d-44be-adae-ce3fb3b02201",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# of input tiles for DPS: 192\n",
      "DPS run #: 1\t| tile num: 27100\t| submit status: Accepted\t| job id: 7a975ff5-8a83-4cfe-a77e-90177b45cdc3\n",
      "DPS run #: 5\t| tile num: 2739\t| submit status: Accepted\t| job id: 1c824be6-5256-43f5-bdde-7c8b77fb8a9d\n",
      "DPS run #: 10\t| tile num: 3239\t| submit status: Accepted\t| job id: 990d3003-af89-44b5-ae3f-0ad18cd7f472\n",
      "DPS run #: 50\t| tile num: 2735\t| submit status: Accepted\t| job id: 94016890-b884-411b-a444-2a8426903565\n",
      "DPS run #: 100\t| tile num: 567\t| submit status: Accepted\t| job id: 95705d70-32d2-46f0-886d-17db3267acf0\n",
      "DPS run #: 192\t| tile num: 353\t| submit status: Accepted\t| job id: 76205ff7-ea68-4009-a308-f78d072d5f3b\n",
      "Current time:\t202308101721\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 192 entries, 0 to 0\n",
      "Data columns (total 10 columns):\n",
      " #   Column         Non-Null Count  Dtype         \n",
      "---  ------         --------------  -----         \n",
      " 0   dps_num        192 non-null    int64         \n",
      " 1   tile_num       192 non-null    int64         \n",
      " 2   submit_time    192 non-null    datetime64[ns]\n",
      " 3   dbs_job_hour   192 non-null    int64         \n",
      " 4   algo_id        192 non-null    object        \n",
      " 5   user           192 non-null    object        \n",
      " 6   worker_type    192 non-null    object        \n",
      " 7   job_id         192 non-null    object        \n",
      " 8   submit_status  192 non-null    object        \n",
      " 9   run_name       192 non-null    object        \n",
      "dtypes: datetime64[ns](1), int64(3), object(6)\n",
      "memory usage: 16.5+ KB\n",
      "CPU times: user 11.5 s, sys: 441 ms, total: 12 s\n",
      "Wall time: 16min 32s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "submit_results_df_list = []\n",
    "len_input_list = len(DPS_INPUT_TILE_NUM_LIST)\n",
    "print(f\"# of input tiles for DPS: {len_input_list}\")\n",
    "\n",
    "for i, INPUT_TILE_NUM in enumerate(DPS_INPUT_TILE_NUM_LIST):\n",
    "\n",
    "    DPS_num = i+1\n",
    "    IDENTIFIER = IDENTIFIER \n",
    "    ALGO_ID = \"do_HLS_stack_3-1-2\"\n",
    "    USER = 'montesano'\n",
    "    WORKER_TYPE = 'maap-dps-worker-32gb'\n",
    "    \n",
    "    in_param_dict = {\n",
    "                         'in_tile_fn': 'https://maap-ops-workspace.s3.amazonaws.com/shared/nathanmthomas/boreal_tiles_v003.gpkg',\n",
    "                         'in_tile_num': INPUT_TILE_NUM,\n",
    "                         'in_tile_layer': 'boreal_tiles_v003',\n",
    "                         'sat_api': 'https://cmr.earthdata.nasa.gov/stac/LPCLOUD',\n",
    "                        #'sat_api': 'https://landsatlook.usgs.gov/sat-api',\n",
    "                         'tile_buffer_m': 0,\n",
    "                         'start_year': YEAR_START,\n",
    "                         'end_year': YEAR_STOP,\n",
    "                         'start_month_day': SEASON_START,\n",
    "                         'end_month_day': SEASON_STOP,\n",
    "                         'max_cloud': MAX_CLOUDS,\n",
    "                         'composite_type': 'HLS',\n",
    "                         'shape': 3000,\n",
    "                         'hls_product': 'H30'\n",
    "        }\n",
    "        \n",
    "    submit_result = maap.submitJob(\n",
    "                                    identifier=IDENTIFIER,\n",
    "                                    algo_id=ALGO_ID,\n",
    "                                    version=MAAP_VERSION, # \"HLS_stack_2023_v1\"\n",
    "                                    username=USER,\n",
    "                                    queue=WORKER_TYPE,\n",
    "                                    # Args that match yaml\n",
    "                                    **in_param_dict\n",
    "        )\n",
    "    \n",
    "    # Build a dataframe of submission details\n",
    "    submit_result_df = pd.DataFrame( \n",
    "        {\n",
    "                'dps_num':[DPS_num],\n",
    "                'tile_num':[INPUT_TILE_NUM],\n",
    "                'submit_time':[datetime.datetime.now()],\n",
    "                'dbs_job_hour': [datetime.datetime.now().hour],\n",
    "                'algo_id': [ALGO_ID],\n",
    "                'user': [USER],\n",
    "                'worker_type': [WORKER_TYPE],\n",
    "                'job_id': [submit_result.id],\n",
    "                'submit_status': [submit_result.retrieve_status()],\n",
    "            \n",
    "        } \n",
    "    )\n",
    "    \n",
    "    # Append to a list of data frames of submission results\n",
    "    submit_results_df_list.append(submit_result_df)\n",
    "    \n",
    "    if DPS_num in [1, 5, 10, 50, 100, 250, 500, 750, 1000, 1500, 2000, 2500, 3000, 3500, 4000, 4500, 5000, 7000, 9000, 11000, 13000, 15000, 17000, 19000, 21000, 24000, len_input_list]:\n",
    "        print(f\"DPS run #: {DPS_num}\\t| tile num: {INPUT_TILE_NUM}\\t| submit status: {submit_result.retrieve_status()}\\t| job id: {submit_result.id}\") \n",
    "        \n",
    "# Build a final submission results df and save\n",
    "submit_results_df = pd.concat(submit_results_df_list)\n",
    "submit_results_df['run_name'] = RUN_NAME\n",
    "nowtime = pd.Timestamp.now().strftime('%Y%m%d%H%M')\n",
    "print(f\"Current time:\\t{nowtime}\")\n",
    "submit_results_df.to_csv(f'/projects/my-public-bucket/dps_submission_results/DPS_{ALGO_ID}_{RUN_NAME}_submission_results_{len_input_list}_{nowtime}.csv')\n",
    "submit_results_df.info()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
