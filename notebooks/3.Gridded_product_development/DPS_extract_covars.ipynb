{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "cababab9-aa54-4c0b-9fb3-65428a01ba63",
   "metadata": {},
   "source": [
    "# DPS to extract raster covars to ATL08 geodataframes\n",
    "Paul Montesano, PhD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "10858e2f-be5d-4190-bb5e-94a51efd4b91",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from maap.maap import MAAP\n",
    "maap = MAAP()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "fd2c7b01-6dd7-4662-85f9-dfcb27aae933",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "ICESAT2_BOREAL_REPO_PATH = '/projects/code/icesat2_boreal'               #'/projects/icesat2_boreal' # /projects/Developer/icesat2_boreal/lib\n",
    "ICESAT2_BOREAL_LIB_PATH = ICESAT2_BOREAL_REPO_PATH + '/lib'\n",
    "sys.path.append(ICESAT2_BOREAL_LIB_PATH)\n",
    "#!pip install -U -r $ICESAT2_BOREAL_REPO_PATH/dps/requirements_main.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1a9d6414-571b-4e65-826e-17bd12289b02",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NASA MAAP\n",
      "Importing packages complete.\n"
     ]
    }
   ],
   "source": [
    "import geopandas as gpd\n",
    "import pandas as pd\n",
    "import os\n",
    "import json\n",
    "import collections\n",
    "import numpy as np\n",
    "import sys\n",
    "import s3fs\n",
    "import matplotlib.pyplot as plt\n",
    "sys.path.append(ICESAT2_BOREAL_LIB_PATH)\n",
    "import maplib_folium\n",
    "import ExtractUtils\n",
    "from folium import TileLayer\n",
    "print(\"Importing packages complete.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a6ce701f-ec19-4c15-b0db-4a34a342bd31",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<module 'mosaiclib' from '/projects/code/icesat2_boreal/lib/mosaiclib.py'>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import importlib\n",
    "import mosaiclib\n",
    "importlib.reload(mosaiclib)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "677f9cfc-ee6b-44f5-beb9-7be002906e26",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from mosaiclib import *"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c411f06f-b499-4a96-8279-1406a7085ab6",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Use MAAP Registration call in notebook chunk to register DPS algorithm\n",
    " - We need to register a DPS algorithm called `run_extract_covars` before proceeding to the chunks below..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "id": "1f5ff082-5119-40f9-874b-3c257b76bee8",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'{\"code\": 200, \"message\": {\"id\": \"27320fd65bcf65b12d6badf40ebd3a3559d3367f\", \"short_id\": \"27320fd6\", \"created_at\": \"2024-02-17T21:03:04.000+00:00\", \"parent_ids\": [\"9f13ea03043f86f6cd4cd57c76b0fecbcc5b1f56\"], \"title\": \"Registering algorithm: run_tile_atl08\", \"message\": \"Registering algorithm: run_tile_atl08\", \"author_name\": \"root\", \"author_email\": \"root@156a1941fa17\", \"authored_date\": \"2024-02-17T21:03:04.000+00:00\", \"committer_name\": \"root\", \"committer_email\": \"root@156a1941fa17\", \"committed_date\": \"2024-02-17T21:03:04.000+00:00\", \"trailers\": {}, \"web_url\": \"https://repo.maap-project.org/root/register-job-hysds-v4/-/commit/27320fd65bcf65b12d6badf40ebd3a3559d3367f\", \"stats\": {\"additions\": 2, \"deletions\": 2, \"total\": 4}, \"status\": \"pending\", \"project_id\": 3, \"last_pipeline\": {\"id\": 12191, \"iid\": 811, \"project_id\": 3, \"sha\": \"27320fd65bcf65b12d6badf40ebd3a3559d3367f\", \"ref\": \"main\", \"status\": \"pending\", \"source\": \"push\", \"created_at\": \"2024-02-17T21:03:05.393Z\", \"updated_at\": \"2024-02-17T21:03:05.787Z\", \"web_url\": \"https://repo.maap-project.org/root/register-job-hysds-v4/-/pipelines/12191\"}, \"job_web_url\": \"https://repo.maap-project.org/root/register-job-hysds-v4/-/jobs/12457\", \"job_log_url\": \"https://repo.maap-project.org/root/register-job-hysds-v4/-/jobs/12457/raw\"}}\\n'"
      ]
     },
     "execution_count": 193,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "maap.register_algorithm_from_yaml_file(\"/projects/code/icesat2_boreal/dps/registered/run_extract_covars.yml\").text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "165b6a2d-ba30-4896-9146-fdc3b1ee43f4",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "s3 = s3fs.S3FileSystem(anon=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "cdc210b9-8fa4-4e7b-8ed8-c40e4b54fc03",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'s3://maap-ops-workspace/montesano/data/atl08.v006/030m/atl08_006_030m_2020_2020_06_09_filt_00127.parquet'"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "DPS_FILE_LIST = [\"s3://\"+f for f in s3.glob(\"s3://maap-ops-workspace/montesano/data/atl08.v006/030m/*.parquet\")]\n",
    "DPS_FILE_LIST[100]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "9c7f15c6-7514-43e3-a45d-67c156d378d6",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'in_tile_num': '',\n",
       " 'tindex_fn_list': ['s3://maap-ops-workspace/shared/montesano/DPS_tile_lists/run_build_stack_topo/build_stack_v2023_2/CopernicusGLO30/Topo_tindex_master.csv',\n",
       "  's3://maap-ops-workspace/shared/montesano/DPS_tile_lists/HLS/HLS_stack_2023_v1/HLS_H30_2020/HLS_tindex_master.csv',\n",
       "  's3://maap-ops-workspace/shared/montesano/DPS_tile_lists/run_build_stack/build_stack_v2023_2/build_stack_S1/SAR_S1_2020/S1_tindex_master.csv']}"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "in_param_dict = {\n",
    "    's3_atl08_gdf_fn': '',\n",
    "    'tindex_fn_list': [TOPO_TINDEX_FN_DICT['c2020updated'], HLS_TINDEX_FN_DICT['2020'], SAR_TINDEX_FN_DICT['2020'] ]\n",
    " }\n",
    "in_param_dict"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aff8f58e-4494-4833-9403-1e461abf1db9",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Run a DPS job across the list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "e60dc132-55f6-4ebd-82d3-d95573928e73",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "IDENTIFIER = '2020'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "275b3e4c-134c-4e84-8e49-9a5d6d2025f8",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# MAAP algorithm version name (same as the repo TAG)\n",
    "MAAP_VERSION = \"extract_covars\" "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "c4eaa881-20d8-40d9-bc38-c6bdd90bc4f7",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "ALGO_ID = \"run_extract_covars\"\n",
    "USER = 'montesano'\n",
    "WORKER_TYPE = 'maap-dps-worker-8gb'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "2afe2261-03b6-439f-8cae-2b88f89cbc15",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# of input tiles for DPS: 4\n",
      "DPS run #: 1\t| tile num: 41807\t| submit status: success\t| job id: 938b3ea6-1381-49b0-9a66-745767e68e06\n",
      "DPS run #: 4\t| tile num: 3916\t| submit status: success\t| job id: e6b305da-2b85-4952-8d53-9d0c5252c07e\n",
      "Current time:\t202402181737\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 4 entries, 0 to 0\n",
      "Data columns (total 10 columns):\n",
      " #   Column         Non-Null Count  Dtype \n",
      "---  ------         --------------  ----- \n",
      " 0   dps_num        4 non-null      int64 \n",
      " 1   tile_num       4 non-null      int64 \n",
      " 2   submit_time    4 non-null      object\n",
      " 3   dbs_job_hour   4 non-null      int64 \n",
      " 4   algo_id        4 non-null      object\n",
      " 5   user           4 non-null      object\n",
      " 6   worker_type    4 non-null      object\n",
      " 7   job_id         4 non-null      object\n",
      " 8   submit_status  4 non-null      object\n",
      " 9   run_name       4 non-null      object\n",
      "dtypes: int64(3), object(7)\n",
      "memory usage: 352.0+ bytes\n",
      "CPU times: user 86.8 ms, sys: 11.3 ms, total: 98.2 ms\n",
      "Wall time: 665 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "submit_results_df_list = []\n",
    "len_input_list = len(DPS_FILE_LIST)\n",
    "print(f\"# of input tiles for DPS: {len_input_list}\")\n",
    "\n",
    "for i, INPUT_FILE in enumerate(DPS_FILE_LIST):\n",
    "\n",
    "    DPS_num = i+1\n",
    "    \n",
    "    in_param_dict['s3_atl08_gdf_fn'] = INPUT_FILE\n",
    "    INPUT_TILE_NUM = int(INPUT_FILE.split('_')[-1].split('.')[0])\n",
    "    \n",
    "    submit_result = maap.submitJob(\n",
    "                                    identifier=IDENTIFIER,\n",
    "                                    algo_id=ALGO_ID,\n",
    "                                    version=MAAP_VERSION, \n",
    "                                    username=USER,\n",
    "                                    queue=WORKER_TYPE,\n",
    "                                    # Args that match yaml\n",
    "                                    **in_param_dict\n",
    "        )\n",
    "    \n",
    "    # Build a dataframe of submission details\n",
    "    submit_result_df = pd.DataFrame( \n",
    "        {\n",
    "                'dps_num':[DPS_num],\n",
    "                'tile_num':[INPUT_TILE_NUM],\n",
    "                'submit_time':[datetime.datetime.now().strftime('%Y-%m-%d-%H-%M-%s')],\n",
    "                'dbs_job_hour': [datetime.datetime.now().hour],\n",
    "                'algo_id': [ALGO_ID],\n",
    "                'user': [USER],\n",
    "                'worker_type': [WORKER_TYPE],\n",
    "                'job_id': [submit_result.id],\n",
    "                'submit_status': [submit_result.status],\n",
    "            \n",
    "        } \n",
    "    )\n",
    "    \n",
    "    # Append to a list of data frames of submission results\n",
    "    submit_results_df_list.append(submit_result_df)\n",
    "    \n",
    "    if DPS_num in [1, 5, 10, 50, 100, 250, 500, 750, 1000, 1500, 2000, 2500, 3000, 3500, 4000, 4500, 5000, 7000, 9000, 11000, 13000, 15000, 17000, 19000, 21000, 24000, len_input_list]:\n",
    "        print(f\"DPS run #: {DPS_num}\\t| tile num: {INPUT_TILE_NUM}\\t| submit status: {submit_result.status}\\t| job id: {submit_result.id}\") \n",
    "        \n",
    "# Build a final submission results df and save\n",
    "submit_results_df = pd.concat(submit_results_df_list)\n",
    "submit_results_df['run_name'] = IDENTIFIER\n",
    "nowtime = pd.Timestamp.now().strftime('%Y%m%d%H%M')\n",
    "print(f\"Current time:\\t{nowtime}\")\n",
    "submit_results_df.to_csv(f'/projects/my-public-bucket/dps_submission_results/DPS_{ALGO_ID}_{IDENTIFIER}_submission_results_{len_input_list}_{nowtime}.csv')\n",
    "submit_results_df.info()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
