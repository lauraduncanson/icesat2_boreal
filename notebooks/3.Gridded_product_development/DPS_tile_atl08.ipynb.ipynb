{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "located-praise",
   "metadata": {},
   "outputs": [],
   "source": [
    "from maap.maap import MAAP\n",
    "maap = MAAP(maap_host='api.ops.maap-project.org')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "baking-there",
   "metadata": {},
   "source": [
    "# Launch DPS for tile_atl08.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "rational-begin",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/projects/.local/lib/python3.7/site-packages/geopandas/_compat.py:110: UserWarning: The Shapely GEOS version (3.8.0-CAPI-1.13.1 ) is incompatible with the GEOS version PyGEOS was compiled with (3.9.1-CAPI-1.14.2). Conversions between both will be slow.\n",
      "  shapely_geos_version, geos_capi_version_string\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting xmltodict\n",
      "  Using cached xmltodict-0.12.0-py2.py3-none-any.whl (9.2 kB)\n",
      "Installing collected packages: xmltodict\n",
      "Successfully installed xmltodict-0.12.0\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import geopandas\n",
    "import pandas as pd\n",
    "import glob\n",
    "import datetime\n",
    "!pip install xmltodict\n",
    "import xmltodict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "spare-madness",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_stack_fn(stack_list_fn, in_tile_num):\n",
    "    # Find most recent topo/Landsat stack path for tile in list of stack paths from *tindex_master.csv\n",
    "    all_stacks_df = pd.read_csv(stack_list_fn)\n",
    "    stack_for_tile = all_stacks_df[all_stacks_df['location'].str.contains(\"_\"+str(in_tile_num))]\n",
    "    [print(i) for i in stack_for_tile.path.to_list()]\n",
    "    stack_for_tile_fn = stack_for_tile.path.to_list()[0]\n",
    "    if len(stack_for_tile)==0:\n",
    "        stack_for_tile_fn = None\n",
    "    return(stack_for_tile_fn)\n",
    "\n",
    "# nmt added: code that returns df of landsat locations and tile number\n",
    "# This is basically CountOutput.py\n",
    "def get_stack_df(dps_dir, TYPE, dps_year):\n",
    "    \n",
    "    if \"Landsat\" in TYPE:\n",
    "        root = f\"/projects/my-private-bucket/dps_output/do_landsat_stack_3-1-2_ubuntu/ops/{dps_year}/\"\n",
    "        ends_with_str = \"_dps.tif\"\n",
    "    if \"Topo\" in TYPE:\n",
    "        root = f\"/projects/my-private-bucket/dps_output/do_topo_stack_3-1-5_ubuntu/ops/{dps_year}/\"\n",
    "        ends_with_str = \"_stack.tif\"\n",
    "    if \"ATL08\" in TYPE:\n",
    "        root = f\"/projects/my-private-bucket/dps_output/run_extract_ubuntu/ops/{dps_year}/\"\n",
    "        ends_with_str = \"0m.csv\"\n",
    "            \n",
    "    df = pd.DataFrame(columns=['location', 'tile_num'])\n",
    "\n",
    "    for dir, subdir, files in os.walk(root):\n",
    "        for fname in files:\n",
    "            if fname.endswith(ends_with_str): \n",
    "                 \n",
    "                tile_num = fname.split('_')[1]\n",
    "                   \n",
    "                if \"ATL08\" in TYPE:\n",
    "                    df = df.append({'location':os.path.join(dir+\"/\", fname)},ignore_index=True)\n",
    "                else:\n",
    "                    df = df.append({'location':os.path.join(dir+\"/\", fname), 'tile_num':tile_num},ignore_index=True)\n",
    "        \n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "promotional-bridges",
   "metadata": {},
   "source": [
    "#### Set the names of the data frames to create"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "injured-emphasis",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Topo and Landsat tindex_master csvs from build_tindex_master.py\n",
    "topo_tindex    = \"/projects/my-public-bucket/DPS_tile_lists/Topo_tindex_master.csv\"\n",
    "landsat_tindex = \"/projects/my-public-bucket/DPS_tile_lists/Landsat_tindex_master.csv\"\n",
    "HLS_tindex     = \"/projects/my-public-bucket/DPS_tile_lists/HLS_tindex_master.csv\"\n",
    "\n",
    "# Model-ready subset of tiles for which Topo and Landsat coincide\n",
    "model_ready_tiles_topo = \"/projects/my-public-bucket/DPS_tile_lists/model_ready_tiles_topo_paths.csv\"\n",
    "model_ready_tiles_landsat = \"/projects/my-public-bucket/DPS_tile_lists/model_ready_tiles_landsat_paths.csv\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bridal-pontiac",
   "metadata": {},
   "source": [
    "## Make the data frames from build_tindex_master.py csvs for Topo and Landsat tiles\n",
    "python lib/build_tindex_master.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "former-rates",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading existing...\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>local_path</th>\n",
       "      <th>tile_num</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>/projects/my-private-bucket/dps_output/do_topo...</td>\n",
       "      <td>421</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>/projects/my-private-bucket/dps_output/do_topo...</td>\n",
       "      <td>455</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>/projects/my-private-bucket/dps_output/do_topo...</td>\n",
       "      <td>456</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>/projects/my-private-bucket/dps_output/do_topo...</td>\n",
       "      <td>491</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>/projects/my-private-bucket/dps_output/do_topo...</td>\n",
       "      <td>492</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0                                         local_path  tile_num\n",
       "0           0  /projects/my-private-bucket/dps_output/do_topo...       421\n",
       "1           1  /projects/my-private-bucket/dps_output/do_topo...       455\n",
       "2           2  /projects/my-private-bucket/dps_output/do_topo...       456\n",
       "3           3  /projects/my-private-bucket/dps_output/do_topo...       491\n",
       "4           4  /projects/my-private-bucket/dps_output/do_topo...       492"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "if os.path.isfile(landsat_tindex) and os.path.isfile(topo_tindex):\n",
    "    print('Reading existing...')\n",
    "    ls8_df = pd.read_csv(landsat_tindex)\n",
    "    topo_df = pd.read_csv(topo_tindex)\n",
    "else:\n",
    "    s3_stem = 'https://s3.console.aws.amazon.com/s3/buckets/maap-ops-workspace/nathanmthomas'\n",
    "    local_stem = '/projects/my-private-bucket'\n",
    "\n",
    "    ls8_root =  s3_stem + '/dps_output/do_landsat_stack_3-1-2_ubuntu'\n",
    "    topo_root = s3_stem + '/dps_output/do_topo_stack_3-1-5_ubuntu'\n",
    "    \n",
    "    ls8_df = get_stack_df(ls8_root, \"Landsat\")\n",
    "    topo_df = get_stack_df(topo_root, \"Topo\")\n",
    "topo_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "crazy-september",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'https://s3.console.aws.amazon.com/s3/buckets/maap-ops-workspace/nathanmthomas/dps_output/do_topo_stack_3-1-5_ubuntu/ops/2021/07/23/23/32/27/934649/Copernicus_3457_covars_cog_topo_stack.tif'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "topo_df = pd.read_csv(topo_tindex)\n",
    "topo_df[topo_df.tile_num == 3457].local_path.tolist()[0].replace('/projects/my-private-bucket', 'https://s3.console.aws.amazon.com/s3/buckets/maap-ops-workspace/nathanmthomas')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dying-calibration",
   "metadata": {},
   "source": [
    "## Get tile ids for which both Topo and Landsat stacks exist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "adequate-temperature",
   "metadata": {},
   "outputs": [],
   "source": [
    "# added by nmt: get filenames of co-incident landsat and topo\n",
    "if False:\n",
    "    topo_sub_df = pd.DataFrame(columns=['local_path','tile_num'])\n",
    "    ls8_sub_df = pd.DataFrame(columns=['local_path','tile_num'])\n",
    "\n",
    "    for i in range(len(ls8_df['tile_num'])):\n",
    "        ls_tile_num = ls8_df['tile_num'][i]\n",
    "        for j in range(len(topo_df['tile_num'])):\n",
    "            topo_tile_num = topo_df['tile_num'][j]\n",
    "            if ls_tile_num == topo_tile_num:\n",
    "                # Only need to choose one, but we'll do 2 and then check\n",
    "                ls8_sub_df = ls8_sub_df.append({'local_path':ls8_df['local_path'][i],'tile_num':ls8_df['tile_num'][i].astype(int)}, ignore_index=True)\n",
    "                topo_sub_df = topo_sub_df.append({'local_path':topo_df['local_path'][j],'tile_num':topo_df['tile_num'][j].astype(int)}, ignore_index=True)\n",
    "\n",
    "    #ls8_sub_df['tile_num'] = ls8_sub_df['tile_num'].astype(float, errors = 'raise')\n",
    "    print(ls8_sub_df.head())\n",
    "    print(topo_sub_df.head())\n",
    "    print(len(ls8_sub_df),len(topo_sub_df))\n",
    "\n",
    "    topo_sub_df.to_csv( model_ready_tiles_topo, index=False, encoding='utf-8-sig')\n",
    "    ls8_sub_df.to_csv( model_ready_tiles_landsat, index=False, encoding='utf-8-sig')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "featured-investor",
   "metadata": {},
   "source": [
    "#### Now you have a set of tile ids for which both Landsat and Topo stacks exist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "acute-range",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4465"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "topo_sub_df = pd.read_csv(\"/projects/my-public-bucket/DPS_tile_lists/model_ready_tiles_topo_paths.csv\")\n",
    "INPUT_TILE_NUM_LIST = topo_sub_df['tile_num'].values.astype(int).tolist()\n",
    "len(INPUT_TILE_NUM_LIST)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "confused-netscape",
   "metadata": {},
   "source": [
    "##### Test: get a subset of tile ids for test tiles (Norway and others in NA)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "grateful-planning",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "153"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "DO_EXPERIMENT = True\n",
    "\n",
    "NORWAY_TILE_LIST = pd.read_csv('/projects/shared-buckets/lduncanson/misc_files/norway_tiles.csv').layer.tolist()\n",
    "    \n",
    "DELTA_TILE_LIST = [3365,3366,3367,3458,3459,3460,3353,3354,3355] + [3361, 3362]\n",
    "BONA_TILE_LIST  = [3270,3271,3272, 3456,3457,  3363,3364,3365] + [3268, 3269]\n",
    "HEALY_TILE_LIST = [ 3551,3552,3553,3645,3646,3647] + [3648, 3649, 3555, 3554]\n",
    "\n",
    "#DELTA_TILE_LIST = [3365,3366,3367,3458,3460,3353,3354,3355,3549]\n",
    "#BONA_TILE_LIST  = [3270,3271,3272,3364,3456,3457,3458,3364,3365]\n",
    "#HEALY_TILE_LIST = [3456,3457,3458,3551,3552, 3553,3645,3646,3647]\n",
    "INPUT_EXPERIMENT_TILE_NUM_LIST = NORWAY_TILE_LIST + DELTA_TILE_LIST + BONA_TILE_LIST + HEALY_TILE_LIST\n",
    "ALASKA_TILE_LIST =  list(range(3268,3272+1))+\\\n",
    "                    list(range(3361,3366+1))+\\\n",
    "                    list(range(3454,3459+1))+\\\n",
    "                    list(range(3549,3555+1))+\\\n",
    "                    list(range(3643,3648+1))\n",
    "\n",
    "INPUT_EXPERIMENT_TILE_NUM_LIST = NORWAY_TILE_LIST + ALASKA_TILE_LIST\n",
    "len(INPUT_EXPERIMENT_TILE_NUM_LIST)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "hundred-merchant",
   "metadata": {},
   "source": [
    "#### Read in the latest tindex and compare with a previous set of completed tiles to see which ones still need to be run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "id": "reduced-angel",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/projects/.local/lib/python3.7/site-packages/geopandas/_compat.py:110: UserWarning: The Shapely GEOS version (3.8.0-CAPI-1.13.1 ) is incompatible with the GEOS version PyGEOS was compiled with (3.9.1-CAPI-1.14.2). Conversions between both will be slow.\n",
      "  shapely_geos_version, geos_capi_version_string\n",
      "\n",
      "Building a list of tiles:\n",
      "MAAP version:\t\tmaster\n",
      "Type:\t\tATL08_filt\n",
      "Year:\t\t2022\n",
      "Month:\t\trun_LC_height_thresholds_v2\n",
      "Days:\t\t1-31\n",
      "\n",
      "Output dir:  /projects/my-private-bucket/dps_output/run_tile_atl08_ubuntu/master/2022/run_LC_height_thresholds_v2\n",
      "                                             s3_path  ...                                               file\n",
      "0  s3://maap-ops-workspace/lduncanson/dps_output/...  ...  atl08_005_30m_filt_topo_landsat_20220322_0013.csv\n",
      "2  s3://maap-ops-workspace/lduncanson/dps_output/...  ...  atl08_005_30m_filt_topo_landsat_20220322_0012.csv\n",
      "4  s3://maap-ops-workspace/lduncanson/dps_output/...  ...  atl08_005_30m_filt_topo_landsat_20220322_0020.csv\n",
      "6  s3://maap-ops-workspace/lduncanson/dps_output/...  ...  atl08_005_30m_filt_topo_landsat_20220322_0011.csv\n",
      "8  s3://maap-ops-workspace/lduncanson/dps_output/...  ...  atl08_005_30m_filt_topo_landsat_20220322_0018.csv\n",
      "\n",
      "[5 rows x 3 columns]\n",
      "# of duplicate tiles: 0\n",
      "Final # of tiles: 137\n",
      "df shape :                                              s3_path  ... tile_num\n",
      "0  s3://maap-ops-workspace/lduncanson/dps_output/...  ...     0013\n",
      "2  s3://maap-ops-workspace/lduncanson/dps_output/...  ...     0012\n",
      "4  s3://maap-ops-workspace/lduncanson/dps_output/...  ...     0020\n",
      "6  s3://maap-ops-workspace/lduncanson/dps_output/...  ...     0011\n",
      "8  s3://maap-ops-workspace/lduncanson/dps_output/...  ...     0018\n",
      "\n",
      "[5 rows x 4 columns]\n",
      "Writing tindex master csv: /projects/my-private-bucket/dps_output/run_tile_atl08_ubuntu/master/2022/run_LC_height_thresholds_v2/ATL08_filt_tindex_master.csv\n",
      "Tiles completed: 137\n",
      "Tiles missing: 16\n",
      "16\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "#tindex_master_fn = '/projects/my-private-bucket/dps_output/run_tile_atl08_ubuntu/master/2022/run_no_LC_height_thresholds/ATL08_filt_tindex_master.csv'\n",
    "NAME_TEST_SUBDIR = 'run_LC_height_thresholds_v2'\n",
    "tindex_master_DIR = f'/projects/my-private-bucket/dps_output/run_tile_atl08_ubuntu/master/2022/{NAME_TEST_SUBDIR}'\n",
    "!python /projects/icesat2_boreal/lib/build_tindex_master.py -t ATL08_filt -y 2022 -m $NAME_TEST_SUBDIR -o $tindex_master_DIR\n",
    "\n",
    "tindex_master_fn = os.path.join(tindex_master_DIR, 'ATL08_filt_tindex_master.csv')\n",
    "tiles_completed = pd.read_csv(tindex_master_fn)\n",
    "\n",
    "print(f'Tiles completed: {len(tiles_completed)}')\n",
    "tile_nums_missing = np.setdiff1d(DPS_INPUT_TILE_NUM_LIST, tiles_completed.tile_num)\n",
    "print(f'Tiles missing: {len(tile_nums_missing)}')\n",
    "INPUT_EXPERIMENT_TILE_NUM_LIST = tile_nums_missing.tolist()\n",
    "print(len(INPUT_EXPERIMENT_TILE_NUM_LIST))\n",
    "\n",
    "DO_EXPERIMENT = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "satisfactory-copying",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "153"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(INPUT_EXPERIMENT_TILE_NUM_LIST)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "functioning-corrections",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "46166"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tindex_master_fn = f'/projects/shared-buckets/lduncanson/DPS_tile_lists/ATL08_tindex_master.csv'\n",
    "tiles = pd.read_csv(tindex_master_fn)\n",
    "len(tiles)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "three-magic",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# tiles for no LC:\t133\n",
      "# tiles for LC:\t\t133\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'np' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-11-3557a2ca1c37>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"# tiles for no LC:\\t{len(tiles_completed_no_LC)}\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"# tiles for LC:\\t\\t{len(tiles_completed_LC)}\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0mtile_nums_missing_no_LC\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msetdiff1d\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mINPUT_TEST_TILE_NUM_LIST\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtiles_completed_no_LC\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtile_num\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m \u001b[0mtile_nums_missing_LC\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msetdiff1d\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mINPUT_TEST_TILE_NUM_LIST\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtiles_completed_LC\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtile_num\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0mtile_nums_missing_no_LC\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mINPUT_TEST_TILE_NUM_LIST\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtiles_completed_no_LC\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtile_num\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'np' is not defined"
     ]
    }
   ],
   "source": [
    "tiles_completed_no_LC = pd.read_csv('/projects/my-private-bucket/dps_output/run_tile_atl08_ubuntu/master/2022/run_no_LC_height_thresholds/ATL08_filt_tindex_master.csv')\n",
    "tiles_completed_LC = pd.read_csv('/projects/my-private-bucket/dps_output/run_tile_atl08_ubuntu/master/2022/run_LC_height_thresholds/ATL08_filt_tindex_master.csv')\n",
    "print(f\"# tiles for no LC:\\t{len(tiles_completed_no_LC)}\")\n",
    "print(f\"# tiles for LC:\\t\\t{len(tiles_completed_LC)}\")\n",
    "tile_nums_missing_no_LC = np.setdiff1d(INPUT_TEST_TILE_NUM_LIST, tiles_completed_no_LC.tile_num)\n",
    "tile_nums_missing_LC = np.setdiff1d(INPUT_TEST_TILE_NUM_LIST, tiles_completed_LC.tile_num)\n",
    "tile_nums_missing_no_LC = set(INPUT_TEST_TILE_NUM_LIST) - set(tiles_completed_no_LC.tile_num)\n",
    "tile_nums_missing_LC = set(INPUT_TEST_TILE_NUM_LIST) - set(tiles_completed_LC.tile_num)\n",
    "print(f\"tiles missing for no LC:\\t{tile_nums_missing_no_LC}\")\n",
    "print(f\"tiles missing for LC:\\t\\t{tile_nums_missing_LC}\")\n",
    "\n",
    "#print(f\"tiles for no LC:\\t{tiles_completed_no_LC.tile_num}\")\n",
    "#print(f\"tiles for LC:\\t\\t{tiles_completed_LC.tile_num}\")\n",
    "\n",
    "# The missing tiles common to both runs probably wont process b/c they have no ATL08 over land, or no corresponding Landsat or Topo tiles.\n",
    "# Those missing that are different in each set need to be run\n",
    "DPS_INPUT_TILE_NUM_LIST_no_LC = list(set(tiles_completed_LC.tile_num) - set(tiles_completed_no_LC.tile_num))\n",
    "DPS_INPUT_TILE_NUM_LIST_LC = list(set(tiles_completed_no_LC.tile_num) - set(tiles_completed_LC.tile_num))\n",
    "print(f\"Tiles still needed for no LC run: {DPS_INPUT_TILE_NUM_LIST_no_LC}\")\n",
    "print(f\"Tiles still needed for LC run: {DPS_INPUT_TILE_NUM_LIST_LC}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "id": "premier-celebrity",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/projects/.local/lib/python3.7/site-packages/geopandas/_compat.py:110: UserWarning: The Shapely GEOS version (3.8.0-CAPI-1.13.1 ) is incompatible with the GEOS version PyGEOS was compiled with (3.9.1-CAPI-1.14.2). Conversions between both will be slow.\n",
      "  shapely_geos_version, geos_capi_version_string\n",
      "\n",
      "Building a list of tiles:  ATL08_filt\n",
      "\n",
      "Output dir:  /projects/my-private-bucket/dps_output/run_tile_atl08_ubuntu/master/2022/run_LC_height_thresholds\n",
      "                                              s3_path  ...                                               file\n",
      "0   s3://maap-ops-workspace/lduncanson/dps_output/...  ...  atl08_005_30m_filt_topo_landsat_20220312_0043.csv\n",
      "2   s3://maap-ops-workspace/lduncanson/dps_output/...  ...  atl08_005_30m_filt_topo_landsat_20220312_0054.csv\n",
      "5   s3://maap-ops-workspace/lduncanson/dps_output/...  ...  atl08_005_30m_filt_topo_landsat_20220312_0065.csv\n",
      "7   s3://maap-ops-workspace/lduncanson/dps_output/...  ...  atl08_005_30m_filt_topo_landsat_20220312_0030.csv\n",
      "10  s3://maap-ops-workspace/lduncanson/dps_output/...  ...  atl08_005_30m_filt_topo_landsat_20220312_0042.csv\n",
      "\n",
      "[5 rows x 3 columns]\n",
      "# of duplicate tiles: 23\n",
      "Final # of tiles: 133\n",
      "df shape :                                               s3_path  ... tile_num\n",
      "0   s3://maap-ops-workspace/lduncanson/dps_output/...  ...     0043\n",
      "2   s3://maap-ops-workspace/lduncanson/dps_output/...  ...     0054\n",
      "5   s3://maap-ops-workspace/lduncanson/dps_output/...  ...     0065\n",
      "7   s3://maap-ops-workspace/lduncanson/dps_output/...  ...     0030\n",
      "10  s3://maap-ops-workspace/lduncanson/dps_output/...  ...     0042\n",
      "\n",
      "[5 rows x 4 columns]\n",
      "Writing tindex master csv: /projects/my-private-bucket/dps_output/run_tile_atl08_ubuntu/master/2022/run_LC_height_thresholds/ATL08_filt_tindex_master.csv\n"
     ]
    }
   ],
   "source": [
    "month_dir_str = 'run_LC_height_thresholds'\n",
    "index_out_dir = os.path.join('/projects/my-private-bucket/dps_output/run_tile_atl08_ubuntu/master/2022', month_dir_str)\n",
    "!python /projects/icesat2_boreal/lib/build_tindex_master.py -t ATL08_filt -y 2022 -m $month_dir_str -o $index_out_dir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "historic-cosmetic",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running DPS on the FULL list of EXPERIMENT input\n",
      "List length: 153\n"
     ]
    }
   ],
   "source": [
    "TEST_DPS  = False\n",
    "\n",
    "if TEST_DPS:\n",
    "    DPS_INPUT_TILE_NUM_LIST = INPUT_TEST_TILE_NUM_LIST\n",
    "    \n",
    "    if True:\n",
    "        #!python /projects/icesat2_boreal/lib/build_tindex_master_v2.py -t ATL08_filt -y 2022 -m $month_dir_str -o $index_out_dir\n",
    "        t = pd.read_csv(os.path.join(index_out_dir,'ATL08_filt_tindex_master.csv'))\n",
    "        COMPLETED_TILES = t.tile_num.to_list()\n",
    "        NEED_TILES = list(set(DPS_INPUT_TILE_NUM_LIST) - set(COMPLETED_TILES))\n",
    "\n",
    "        print(NEED_TILES)\n",
    "        DPS_INPUT_TILE_NUM_LIST = NEED_TILES\n",
    "    \n",
    "else:\n",
    "    if DO_EXPERIMENT:\n",
    "        print('Running DPS on the FULL list of EXPERIMENT input')\n",
    "        DPS_INPUT_TILE_NUM_LIST = INPUT_EXPERIMENT_TILE_NUM_LIST\n",
    "    else:\n",
    "        print('Running DPS on the FULL list of input')\n",
    "        DPS_INPUT_TILE_NUM_LIST = INPUT_TILE_NUM_LIST\n",
    "    \n",
    "print(f\"List length: {len(DPS_INPUT_TILE_NUM_LIST)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "serious-offering",
   "metadata": {},
   "source": [
    "## Customize the DPS run (choose params, set up the params dictionary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "senior-productivity",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set a default params dict\n",
    "in_param_dict = {\n",
    "                        'in_tile_num': '',\n",
    "                        'in_tile_fn': 'https://maap-ops-workspace.s3.amazonaws.com/shared/nathanmthomas/boreal_tiles_v003.gpkg',\n",
    "                        'in_tile_layer': 'boreal_tiles_v003',\n",
    "                        'csv_list_fn': 's3://maap-ops-workspace/shared/lduncanson/DPS_tile_lists/ATL08_tindex_master.csv',\n",
    "                        'topo_stack_list_fn': 's3://maap-ops-workspace/shared/nathanmthomas/DPS_tile_lists/Topo_tindex_master.csv',\n",
    "                        'landsat_stack_list_fn': 's3://maap-ops-workspace/shared/nathanmthomas/DPS_tile_lists/Landsat_tindex_master.csv',\n",
    "                        'landsat_cols_list': 'Blue Green Red NIR SWIR NDVI SAVI MSAVI NDMI EVI NBR NBR2 TCB TCG TCW ValidMask Xgeo Ygeo', \n",
    "                        'years_list': '2020',\n",
    "                        'user_stacks': 'nathanmthomas',\n",
    "                        'user_atl08': 'lduncanson',\n",
    "                        'thresh_sol_el': 0,\n",
    "                        'v_ATL08': 5,\n",
    "                        'minmonth': 6,\n",
    "                        'maxmonth': 9,\n",
    "                        'LC_filter': False\n",
    "    }\n",
    "\n",
    "# Norway test 01 --> run_no_LC_height_thresholds_v2\n",
    "# Just include sol_el so we can use sol_el < 5\n",
    "in_param_dict_norway01 = in_param_dict\n",
    "in_param_dict_norway01['years_list']    = '2019 2020 2021'\n",
    "in_param_dict_norway01['thresh_sol_el'] = 5\n",
    "in_param_dict_norway01['minmonth']      = 4\n",
    "in_param_dict_norway01['maxmonth']      = 10\n",
    "in_param_dict_norway01['LC_filter']     = False\n",
    "\n",
    "# Norway test 02 --> run_LC_height_thresholds_v2\n",
    "# Use v005 ATL08, which will apply lc-based thresholds, extend to all months\n",
    "# NOTE!! make sure you manually update to use the correct filter in tile_atl08.py\n",
    "in_param_dict_norway02 = in_param_dict\n",
    "in_param_dict_norway02['years_list']    = '2019 2020 2021'\n",
    "in_param_dict_norway02['thresh_sol_el'] = 5\n",
    "in_param_dict_norway02['minmonth']      = 4\n",
    "in_param_dict_norway02['maxmonth']      = 10\n",
    "in_param_dict_norway02['LC_filter']     = True\n",
    "\n",
    "# Norway test 03 --> run_LC_height_thresholds_HLS\n",
    "# same as test 02, but with HLS composites from 2019 - 2021\n",
    "# NOTE: HLS composites have SWIR2 JulianDate yearDate\n",
    "in_param_dict_norway03 = in_param_dict\n",
    "in_param_dict_norway03['landsat_stack_list_fn'] = 's3://maap-ops-workspace/shared/nathanmthomas/DPS_tile_lists/HLS_tindex_master.csv'\n",
    "in_param_dict_norway03['landsat_cols_list']     = 'Blue Green Red NIR SWIR SWIR2 NDVI SAVI MSAVI NDMI EVI NBR NBR2 TCB TCG TCW ValidMask Xgeo Ygeo JulianDate yearDate'\n",
    "in_param_dict_norway03['years_list']            = '2019 2020 2021'\n",
    "in_param_dict_norway03['thresh_sol_el']         = 5\n",
    "in_param_dict_norway03['minmonth']              = 4\n",
    "in_param_dict_norway03['maxmonth']              = 10\n",
    "in_param_dict_norway03['LC_filter']             = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "artistic-cheese",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'in_tile_num': '',\n",
       " 'in_tile_fn': 'https://maap-ops-workspace.s3.amazonaws.com/shared/nathanmthomas/boreal_tiles_v003.gpkg',\n",
       " 'in_tile_layer': 'boreal_tiles_v003',\n",
       " 'csv_list_fn': 's3://maap-ops-workspace/shared/lduncanson/DPS_tile_lists/ATL08_tindex_master.csv',\n",
       " 'topo_stack_list_fn': 's3://maap-ops-workspace/shared/nathanmthomas/DPS_tile_lists/Topo_tindex_master.csv',\n",
       " 'landsat_stack_list_fn': 's3://maap-ops-workspace/shared/nathanmthomas/DPS_tile_lists/HLS_tindex_master.csv',\n",
       " 'landsat_cols_list': 'Blue Green Red NIR SWIR SWIR2 NDVI SAVI MSAVI NDMI EVI NBR NBR2 TCB TCG TCW ValidMask Xgeo Ygeo JulianDate yearDate',\n",
       " 'years_list': '2019 2020 2021',\n",
       " 'user_stacks': 'nathanmthomas',\n",
       " 'user_atl08': 'lduncanson',\n",
       " 'thresh_sol_el': 5,\n",
       " 'v_ATL08': 5,\n",
       " 'minmonth': 4,\n",
       " 'maxmonth': 10,\n",
       " 'LC_filter': True}"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "in_param_dict = in_param_dict_norway03\n",
    "in_param_dict"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "suited-burlington",
   "metadata": {},
   "source": [
    "## Run a DPS job across the list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "laden-accuracy",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# of input tiles for DPS: 153\n",
      "DPS run #: 1\t| tile num: 131\t| submit status: success\t| job id: d24767f8-c73c-4f12-adda-3926cdd6cc54\n",
      "DPS run #: 25\t| tile num: 151\t| submit status: success\t| job id: ec788068-498a-4240-bc19-6fbad723cd84\n",
      "DPS run #: 50\t| tile num: 301\t| submit status: success\t| job id: 6e1d0e64-de2a-40bd-a019-3b35ae87c0c0\n",
      "DPS run #: 100\t| tile num: 354\t| submit status: success\t| job id: 1f786e45-691a-43bd-ad71-b29dfa781c17\n",
      "DPS run #: 153\t| tile num: 3648\t| submit status: success\t| job id: 2e13e554-a5ee-4da5-967b-d5ff4de28db6\n",
      "Current time:\t202203291816\n",
      "/projects/my-public-bucket/DPS_run_tile_atl08_submission_results_153_202203291816.csv\n",
      "CPU times: user 1.74 s, sys: 162 ms, total: 1.91 s\n",
      "Wall time: 36.5 s\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>status</th>\n",
       "      <th>http_status_code</th>\n",
       "      <th>job_id</th>\n",
       "      <th>dps_num</th>\n",
       "      <th>tile_num</th>\n",
       "      <th>submit_time</th>\n",
       "      <th>dbs_job_hour</th>\n",
       "      <th>algo_id</th>\n",
       "      <th>user</th>\n",
       "      <th>worker_type</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>success</td>\n",
       "      <td>200</td>\n",
       "      <td>d24767f8-c73c-4f12-adda-3926cdd6cc54</td>\n",
       "      <td>1</td>\n",
       "      <td>131</td>\n",
       "      <td>2022-03-29 18:15:36.419619</td>\n",
       "      <td>18</td>\n",
       "      <td>run_tile_atl08_ubuntu</td>\n",
       "      <td>lduncanson</td>\n",
       "      <td>maap-dps-worker-16gb</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>success</td>\n",
       "      <td>200</td>\n",
       "      <td>b997d8a0-3cfc-4446-b088-77ba35e9837c</td>\n",
       "      <td>2</td>\n",
       "      <td>132</td>\n",
       "      <td>2022-03-29 18:15:36.525031</td>\n",
       "      <td>18</td>\n",
       "      <td>run_tile_atl08_ubuntu</td>\n",
       "      <td>lduncanson</td>\n",
       "      <td>maap-dps-worker-16gb</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>success</td>\n",
       "      <td>200</td>\n",
       "      <td>4a5a70ee-d1c9-4dc6-b608-9acc22317003</td>\n",
       "      <td>3</td>\n",
       "      <td>133</td>\n",
       "      <td>2022-03-29 18:15:36.634964</td>\n",
       "      <td>18</td>\n",
       "      <td>run_tile_atl08_ubuntu</td>\n",
       "      <td>lduncanson</td>\n",
       "      <td>maap-dps-worker-16gb</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>success</td>\n",
       "      <td>200</td>\n",
       "      <td>ab3798b4-1e99-4b71-98b2-84b1dafae681</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>2022-03-29 18:15:36.869841</td>\n",
       "      <td>18</td>\n",
       "      <td>run_tile_atl08_ubuntu</td>\n",
       "      <td>lduncanson</td>\n",
       "      <td>maap-dps-worker-16gb</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>success</td>\n",
       "      <td>200</td>\n",
       "      <td>6a8bf3f0-a149-4bf6-941f-9ee44fa00482</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>2022-03-29 18:15:37.099964</td>\n",
       "      <td>18</td>\n",
       "      <td>run_tile_atl08_ubuntu</td>\n",
       "      <td>lduncanson</td>\n",
       "      <td>maap-dps-worker-16gb</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>success</td>\n",
       "      <td>200</td>\n",
       "      <td>848329da-c06d-49eb-954f-739903942909</td>\n",
       "      <td>149</td>\n",
       "      <td>3644</td>\n",
       "      <td>2022-03-29 18:16:11.663888</td>\n",
       "      <td>18</td>\n",
       "      <td>run_tile_atl08_ubuntu</td>\n",
       "      <td>lduncanson</td>\n",
       "      <td>maap-dps-worker-16gb</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>success</td>\n",
       "      <td>200</td>\n",
       "      <td>9bfac526-dd55-4928-afec-575567af3b9d</td>\n",
       "      <td>150</td>\n",
       "      <td>3645</td>\n",
       "      <td>2022-03-29 18:16:11.888976</td>\n",
       "      <td>18</td>\n",
       "      <td>run_tile_atl08_ubuntu</td>\n",
       "      <td>lduncanson</td>\n",
       "      <td>maap-dps-worker-16gb</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>success</td>\n",
       "      <td>200</td>\n",
       "      <td>b437ded6-0576-4d9e-821d-0786448bfacb</td>\n",
       "      <td>151</td>\n",
       "      <td>3646</td>\n",
       "      <td>2022-03-29 18:16:12.114767</td>\n",
       "      <td>18</td>\n",
       "      <td>run_tile_atl08_ubuntu</td>\n",
       "      <td>lduncanson</td>\n",
       "      <td>maap-dps-worker-16gb</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>success</td>\n",
       "      <td>200</td>\n",
       "      <td>ed6b090b-995e-43c3-abcc-98f8de09c0ad</td>\n",
       "      <td>152</td>\n",
       "      <td>3647</td>\n",
       "      <td>2022-03-29 18:16:12.376203</td>\n",
       "      <td>18</td>\n",
       "      <td>run_tile_atl08_ubuntu</td>\n",
       "      <td>lduncanson</td>\n",
       "      <td>maap-dps-worker-16gb</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>success</td>\n",
       "      <td>200</td>\n",
       "      <td>2e13e554-a5ee-4da5-967b-d5ff4de28db6</td>\n",
       "      <td>153</td>\n",
       "      <td>3648</td>\n",
       "      <td>2022-03-29 18:16:12.567238</td>\n",
       "      <td>18</td>\n",
       "      <td>run_tile_atl08_ubuntu</td>\n",
       "      <td>lduncanson</td>\n",
       "      <td>maap-dps-worker-16gb</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>153 rows × 10 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     status  http_status_code                                job_id  dps_num  \\\n",
       "0   success               200  d24767f8-c73c-4f12-adda-3926cdd6cc54        1   \n",
       "0   success               200  b997d8a0-3cfc-4446-b088-77ba35e9837c        2   \n",
       "0   success               200  4a5a70ee-d1c9-4dc6-b608-9acc22317003        3   \n",
       "0   success               200  ab3798b4-1e99-4b71-98b2-84b1dafae681        4   \n",
       "0   success               200  6a8bf3f0-a149-4bf6-941f-9ee44fa00482        5   \n",
       "..      ...               ...                                   ...      ...   \n",
       "0   success               200  848329da-c06d-49eb-954f-739903942909      149   \n",
       "0   success               200  9bfac526-dd55-4928-afec-575567af3b9d      150   \n",
       "0   success               200  b437ded6-0576-4d9e-821d-0786448bfacb      151   \n",
       "0   success               200  ed6b090b-995e-43c3-abcc-98f8de09c0ad      152   \n",
       "0   success               200  2e13e554-a5ee-4da5-967b-d5ff4de28db6      153   \n",
       "\n",
       "    tile_num                submit_time  dbs_job_hour                algo_id  \\\n",
       "0        131 2022-03-29 18:15:36.419619            18  run_tile_atl08_ubuntu   \n",
       "0        132 2022-03-29 18:15:36.525031            18  run_tile_atl08_ubuntu   \n",
       "0        133 2022-03-29 18:15:36.634964            18  run_tile_atl08_ubuntu   \n",
       "0          4 2022-03-29 18:15:36.869841            18  run_tile_atl08_ubuntu   \n",
       "0          5 2022-03-29 18:15:37.099964            18  run_tile_atl08_ubuntu   \n",
       "..       ...                        ...           ...                    ...   \n",
       "0       3644 2022-03-29 18:16:11.663888            18  run_tile_atl08_ubuntu   \n",
       "0       3645 2022-03-29 18:16:11.888976            18  run_tile_atl08_ubuntu   \n",
       "0       3646 2022-03-29 18:16:12.114767            18  run_tile_atl08_ubuntu   \n",
       "0       3647 2022-03-29 18:16:12.376203            18  run_tile_atl08_ubuntu   \n",
       "0       3648 2022-03-29 18:16:12.567238            18  run_tile_atl08_ubuntu   \n",
       "\n",
       "          user           worker_type  \n",
       "0   lduncanson  maap-dps-worker-16gb  \n",
       "0   lduncanson  maap-dps-worker-16gb  \n",
       "0   lduncanson  maap-dps-worker-16gb  \n",
       "0   lduncanson  maap-dps-worker-16gb  \n",
       "0   lduncanson  maap-dps-worker-16gb  \n",
       "..         ...                   ...  \n",
       "0   lduncanson  maap-dps-worker-16gb  \n",
       "0   lduncanson  maap-dps-worker-16gb  \n",
       "0   lduncanson  maap-dps-worker-16gb  \n",
       "0   lduncanson  maap-dps-worker-16gb  \n",
       "0   lduncanson  maap-dps-worker-16gb  \n",
       "\n",
       "[153 rows x 10 columns]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "submit_results_df_list = []\n",
    "len_input_list = len(DPS_INPUT_TILE_NUM_LIST)\n",
    "print(f\"# of input tiles for DPS: {len_input_list}\")\n",
    "\n",
    "for i, INPUT_TILE_NUM in enumerate(DPS_INPUT_TILE_NUM_LIST):\n",
    "\n",
    "    DPS_num = i+1\n",
    "    IDENTIFIER = 'run_tile_atl08'\n",
    "    ALGO_ID = f'{IDENTIFIER}_ubuntu'\n",
    "    USER = 'lduncanson'\n",
    "    WORKER_TYPE = 'maap-dps-worker-16gb'\n",
    "    \n",
    "    in_param_dict['in_tile_num'] = INPUT_TILE_NUM\n",
    "    \n",
    "    submit_result = maap.submitJob(\n",
    "            identifier=IDENTIFIER,\n",
    "            algo_id=ALGO_ID,\n",
    "            version='master',\n",
    "            username=USER, # username needs to be the same as whoever created the workspace\n",
    "            queue=WORKER_TYPE,\n",
    "            **in_param_dict\n",
    "        )\n",
    "    \n",
    "    # Build a dataframe of submission details\n",
    "    submit_result['dps_num'] = DPS_num\n",
    "    submit_result['tile_num'] = INPUT_TILE_NUM\n",
    "    submit_result['submit_time'] = datetime.datetime.now()\n",
    "    submit_result['dbs_job_hour'] =datetime.datetime.now().hour\n",
    "    submit_result['algo_id'] = ALGO_ID\n",
    "    submit_result['user'] = USER\n",
    "    submit_result['worker_type'] = WORKER_TYPE\n",
    "\n",
    "    # Append to a list of data frames of submission results\n",
    "    submit_results_df_list.append(pd.DataFrame([submit_result]))\n",
    "    \n",
    "    if DPS_num in [1, 25, 50, 100, 500, 1000, 1500, 2000, 3000, 5000, 7000, 9000, 11000, 13000, 15000, 17000, 19000, 21000, 24000, len_input_list]:\n",
    "        print(f\"DPS run #: {DPS_num}\\t| tile num: {INPUT_TILE_NUM}\\t| submit status: {submit_result['status']}\\t| job id: {submit_result['job_id']}\") \n",
    "\n",
    "# Build a final submission results df and save\n",
    "submit_results_df = pd.concat(submit_results_df_list)\n",
    "nowtime = pd.Timestamp.now().strftime('%Y%m%d%H%M')\n",
    "print(f\"Current time:\\t{nowtime}\")\n",
    "OUT_SUBMISSION_CSV_FN = f'/projects/my-public-bucket/DPS_{IDENTIFIER}_submission_results_{len_input_list}_{nowtime}.csv'\n",
    "submit_results_df.to_csv(OUT_SUBMISSION_CSV_FN)\n",
    "print(OUT_SUBMISSION_CSV_FN)\n",
    "submit_results_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "inside-romania",
   "metadata": {},
   "source": [
    "After almost any DPS job, you have to assess what succeeded and failed. This involves:\n",
    "1. building a table of job status based on job ids captured in the job_results_df from the DPS run chunk (this takes 40 mins for ~47k jobs) --> this tells you how many jobs failed\n",
    "2. merging the job status table with the job results df --> this tells you which specific granules (or tile nums) failed\n",
    "3. building another input list of granules for a follow-up DPS\n",
    "## Assess DPS results\n",
    "Build a table of job status based on job id - how many jobs failed?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "intended-henry",
   "metadata": {},
   "outputs": [],
   "source": [
    "def BUILD_TABLE_JOBSTATUS(submit_results_df):\n",
    "    import xmltodict\n",
    "    job_status_df = pd.concat([pd.DataFrame(xmltodict.parse(maap.getJobStatus(job_id).content)).transpose() for job_id in submit_results_df.job_id.to_list()])\n",
    "    job_status_df = submit_results_df.merge(job_status_df, how='left', left_on='job_id',  right_on='wps:JobID')\n",
    "    return job_status_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "welsh-velvet",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Count total jobs:\t153\n",
      "Count pending jobs:\t0\n",
      "Count running jobs:\t0\n",
      "Count succeeded jobs:\t136\n",
      "Count failed jobs:\t17\n",
      "% of failed jobs:\t11.110000000000001\n",
      "CPU times: user 1.63 s, sys: 123 ms, total: 1.75 s\n",
      "Wall time: 4.68 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "z = BUILD_TABLE_JOBSTATUS(submit_results_df)\n",
    "\n",
    "print(f'Count total jobs:\\t{len(z)}')\n",
    "print(f\"Count pending jobs:\\t{z[z['wps:Status'] =='Accepted'].shape[0]}\")\n",
    "print(f\"Count running jobs:\\t{z[z['wps:Status'] =='Running'].shape[0]}\")\n",
    "print(f\"Count succeeded jobs:\\t{z[z['wps:Status'] =='Succeeded'].shape[0]}\")\n",
    "print(f\"Count failed jobs:\\t{z[z['wps:Status'] =='Failed'].shape[0]}\")\n",
    "print(f\"% of failed jobs:\\t{round(z[z['wps:Status'] =='Failed'].shape[0] / ( z[z['wps:Status'] =='Failed'].shape[0] + z[z['wps:Status'] =='Succeeded'].shape[0] ), 4) * 100}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "connected-northeast",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "OrderedDict([('wps:Result',\n",
       "              OrderedDict([('@xmlns:ows', 'http://www.opengis.net/ows/2.0'),\n",
       "                           ('@xmlns:schemaLocation',\n",
       "                            'http://schemas.opengis.net/wps/2.0/wps.xsd'),\n",
       "                           ('@xmlns:wps', 'http://www.opengis.net/wps/2.0'),\n",
       "                           ('@xmlns:xsi',\n",
       "                            'http://www.w3.org/2001/XMLSchema-instance'),\n",
       "                           ('wps:JobID',\n",
       "                            'fd103a8d-83b1-41d7-b795-f2f328f16269'),\n",
       "                           ('wps:Output',\n",
       "                            OrderedDict([('@id',\n",
       "                                          'output-2022-03-22T19:20:58.003202'),\n",
       "                                         ('wps:Data',\n",
       "                                          ['http://maap-ops-workspace.s3-website-us-west-2.amazonaws.com/lduncanson/dps_output/run_tile_atl08_ubuntu/master/2022/03/22/19/20/58/003202',\n",
       "                                           's3://s3.us-west-2.amazonaws.com:80/maap-ops-workspace/lduncanson/dps_output/run_tile_atl08_ubuntu/master/2022/03/22/19/20/58/003202',\n",
       "                                           'https://s3.console.aws.amazon.com/s3/buckets/maap-ops-workspace/lduncanson/dps_output/run_tile_atl08_ubuntu/master/2022/03/22/19/20/58/003202/?region=us-east-1&tab=overview'])]))]))])"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xmltodict.parse(maap.getJobResult(z[z['wps:Status'] =='Succeeded'].iloc[0].job_id).content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "charitable-montreal",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "OrderedDict([('wps:Result',\n",
       "              OrderedDict([('@xmlns:ows', 'http://www.opengis.net/ows/2.0'),\n",
       "                           ('@xmlns:schemaLocation',\n",
       "                            'http://schemas.opengis.net/wps/2.0/wps.xsd'),\n",
       "                           ('@xmlns:wps', 'http://www.opengis.net/wps/2.0'),\n",
       "                           ('@xmlns:xsi',\n",
       "                            'http://www.w3.org/2001/XMLSchema-instance'),\n",
       "                           ('wps:JobID',\n",
       "                            '9e3ec766-af50-4d54-9412-2d966c141a3d'),\n",
       "                           ('wps:Output',\n",
       "                            OrderedDict([('@id', 'traceback'),\n",
       "                                         ('wps:Data',\n",
       "                                          'Traceback (most recent call last):\\n  File \"/home/ops/verdi/ops/hysds-0.3.11/hysds/job_worker.py\", line 1126, in run_job\\n    raise RuntimeError(\"Got non-zero exit code: {}\".format(status))\\nRuntimeError: Got non-zero exit code: 143')]))]))])"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xmltodict.parse(maap.getJobResult(z[z['wps:Status'] =='Failed'].iloc[0].job_id).content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "unsigned-soccer",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/projects/.local/lib/python3.7/site-packages/geopandas/_compat.py:110: UserWarning: The Shapely GEOS version (3.8.0-CAPI-1.13.1 ) is incompatible with the GEOS version PyGEOS was compiled with (3.9.1-CAPI-1.14.2). Conversions between both will be slow.\n",
      "  shapely_geos_version, geos_capi_version_string\n",
      "\n",
      "Building a list of tiles:\n",
      "MAAP version:\t\tmaster\n",
      "Type:\t\tATL08_filt\n",
      "Year:\t\t2022\n",
      "Month:\t\t03\n",
      "Days:\t\t1-31\n",
      "\n",
      "Output dir:  /projects/my-private-bucket/dps_output/run_tile_atl08_ubuntu/master/2022/03\n",
      "                                             s3_path  ...                                               file\n",
      "0  s3://maap-ops-workspace/lduncanson/dps_output/...  ...  atl08_005_30m_filt_topo_landsat_20220329_0004.csv\n",
      "2  s3://maap-ops-workspace/lduncanson/dps_output/...  ...  atl08_005_30m_filt_topo_landsat_20220329_0133.csv\n",
      "4  s3://maap-ops-workspace/lduncanson/dps_output/...  ...  atl08_005_30m_filt_topo_landsat_20220329_0131.csv\n",
      "6  s3://maap-ops-workspace/lduncanson/dps_output/...  ...  atl08_005_30m_filt_topo_landsat_20220329_0132.csv\n",
      "8  s3://maap-ops-workspace/lduncanson/dps_output/...  ...  atl08_005_30m_filt_topo_landsat_20220329_0009.csv\n",
      "\n",
      "[5 rows x 3 columns]\n",
      "# of duplicate tiles: 0\n",
      "Final # of tiles: 128\n",
      "df shape :                                              s3_path  ... tile_num\n",
      "0  s3://maap-ops-workspace/lduncanson/dps_output/...  ...     0004\n",
      "2  s3://maap-ops-workspace/lduncanson/dps_output/...  ...     0133\n",
      "4  s3://maap-ops-workspace/lduncanson/dps_output/...  ...     0131\n",
      "6  s3://maap-ops-workspace/lduncanson/dps_output/...  ...     0132\n",
      "8  s3://maap-ops-workspace/lduncanson/dps_output/...  ...     0009\n",
      "\n",
      "[5 rows x 4 columns]\n",
      "Writing tindex master csv: /projects/my-private-bucket/dps_output/run_tile_atl08_ubuntu/master/2022/03/ATL08_filt_tindex_master.csv\n"
     ]
    }
   ],
   "source": [
    "!python /projects/icesat2_boreal/lib/build_tindex_master.py -t ATL08_filt -y 2022 -m 03 -o /projects/my-private-bucket/dps_output/run_tile_atl08_ubuntu/master/2022/03"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "level-sussex",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[387, 388, 5, 6, 7, 10, 14, 16, 275, 21, 25, 27, 28, 29, 416, 37, 38, 296, 26025, 299, 300, 301, 48, 177, 50, 178, 60, 198, 3270, 72, 326, 327, 328, 26574, 354, 355, 356, 357, 247]\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "id": "derived-designer",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-LC_filter True --extract_covars --do_30m --do_dps -years_list 2019 2020 2021 -o /projects/my-public-bucket/atl08_filt_covar_tiles -in_tile_num 131 -in_tile_fn /projects/shared-buckets/nathanmthomas/boreal_tiles_v003.gpkg -in_tile_layer boreal_tiles_v003 -in_tile_id_col tile_num -csv_list_fn /projects/shared-buckets/lduncanson/DPS_tile_lists/ATL08_tindex_master.csv -topo_stack_list_fn /projects/shared-buckets/nathanmthomas/DPS_tile_lists/Topo_tindex_master.csv -landsat_stack_list_fn /projects/shared-buckets/nathanmthomas/DPS_tile_lists/Landsat_tindex_master.csv -user_stacks nathanmthomas -user_atl08 lduncanson -thresh_sol_el 5 -v_ATL08 5 -minmonth 4 -maxmonth 10\n",
      "/projects/.local/lib/python3.7/site-packages/geopandas/_compat.py:110: UserWarning: The Shapely GEOS version (3.8.0-CAPI-1.13.1 ) is incompatible with the GEOS version PyGEOS was compiled with (3.9.1-CAPI-1.14.2). Conversions between both will be slow.\n",
      "  shapely_geos_version, geos_capi_version_string\n",
      "\n",
      "Land cover filtering set to: True\n",
      "\n",
      "Working on tile:\t 131\n",
      "From layer:\t\t boreal_tiles_v003\n",
      "In vector file:\t\t /projects/shared-buckets/nathanmthomas/boreal_tiles_v003.gpkg\n",
      "ATL08 version:\t\t 5\n",
      "Season start:\t\t 04-01\n",
      "Season end:\t\t 10-31\n",
      "Years:\t\t\t [2019, 2020, 2021]\n",
      "ATL08 bin length:\t 30m\n",
      "\n",
      "Doing MAAP query by tile bounds to find all intersecting ATL08 \n",
      "\tTILE_NUM: 131 (13.542284675000083,63.85506319420587,16.20544971460586,64.97513449757871)\n",
      "\tSearching MAAP for granules using these parameters: \n",
      "\t[{'short_name': 'ATL08', 'version': '005', 'bounding_box': '13.542284675000083,63.85506319420587,16.20544971460586,64.97513449757871', 'limit': 10000, 'temporal': '2019-04-01T00:00:00Z,2019-10-31T23:59:59Z'}, {'short_name': 'ATL08', 'version': '005', 'bounding_box': '13.542284675000083,63.85506319420587,16.20544971460586,64.97513449757871', 'limit': 10000, 'temporal': '2020-04-01T00:00:00Z,2020-10-31T23:59:59Z'}, {'short_name': 'ATL08', 'version': '005', 'bounding_box': '13.542284675000083,63.85506319420587,16.20544971460586,64.97513449757871', 'limit': 10000, 'temporal': '2021-04-01T00:00:00Z,2021-10-31T23:59:59Z'}]\n",
      "\t\t# ATL08 for tile 131: 195\n",
      "\n",
      "This is either a DPS job (for which the CSV has an s3 path, or the CSV exists locally.)\n",
      "\n",
      "Reading existing list of ATL08 CSVs: /projects/shared-buckets/lduncanson/DPS_tile_lists/ATL08_tindex_master.csv\n",
      "\tDoing 30m ATL08 data?  True\n",
      "\tFind ATL08 CSVs you expect for a tile based on the h5 granule search...\n",
      "\t\t# of all ATL08 granules for tile: 195\n",
      "\t\t# of all_atl08_csvs: 46166\n",
      "\t# of ATL08 CSV found for tile 131: 158\n",
      "\t# of ATL08 CSV NOT found for tile 131: 37\n",
      "Creating pandas data frame...\n",
      "\n",
      "Filtering by tile: 131\n",
      "[13.542284675000083, 16.20544971460586, 63.85506319420587, 64.97513449757871]\n",
      "Bounds clipped 67410 obs. down to 8432 obs.\n",
      "Bounds clipped 33050 obs. down to 1581 obs.\n",
      "Bounds clipped 39560 obs. down to 0 obs.\n",
      "Bounds clipped 50324 obs. down to 3208 obs.\n",
      "Bounds clipped 95567 obs. down to 11660 obs.\n",
      "Bounds clipped 111142 obs. down to 2070 obs.\n",
      "Bounds clipped 105092 obs. down to 811 obs.\n",
      "Bounds clipped 110665 obs. down to 8897 obs.\n",
      "Bounds clipped 8143 obs. down to 0 obs.\n",
      "Bounds clipped 34114 obs. down to 0 obs.\n",
      "Bounds clipped 47439 obs. down to 666 obs.\n",
      "^C\n",
      "Traceback (most recent call last):\n",
      "  File \"/projects/icesat2_boreal/lib/tile_atl08.py\", line 386, in <module>\n",
      "    main()\n",
      "  File \"/projects/icesat2_boreal/lib/tile_atl08.py\", line 308, in main\n",
      "    atl08 = pd.concat([  FilterUtils.filter_atl08_bounds_clip(pd.read_csv(f), tile['geom_4326']) for f in all_atl08_csvs_FOUND ], sort=False, ignore_index=True)\n",
      "  File \"/projects/icesat2_boreal/lib/tile_atl08.py\", line 308, in <listcomp>\n",
      "    atl08 = pd.concat([  FilterUtils.filter_atl08_bounds_clip(pd.read_csv(f), tile['geom_4326']) for f in all_atl08_csvs_FOUND ], sort=False, ignore_index=True)\n",
      "  File \"/projects/.local/lib/python3.7/site-packages/pandas/io/parsers.py\", line 610, in read_csv\n",
      "    return _read(filepath_or_buffer, kwds)\n",
      "  File \"/projects/.local/lib/python3.7/site-packages/pandas/io/parsers.py\", line 468, in _read\n",
      "    return parser.read(nrows)\n",
      "  File \"/projects/.local/lib/python3.7/site-packages/pandas/io/parsers.py\", line 1057, in read\n",
      "    index, columns, col_dict = self._engine.read(nrows)\n",
      "  File \"/projects/.local/lib/python3.7/site-packages/pandas/io/parsers.py\", line 2061, in read\n",
      "    data = self._reader.read(nrows)\n",
      "  File \"pandas/_libs/parsers.pyx\", line 756, in pandas._libs.parsers.TextReader.read\n",
      "  File \"pandas/_libs/parsers.pyx\", line 771, in pandas._libs.parsers.TextReader._read_low_memory\n",
      "  File \"pandas/_libs/parsers.pyx\", line 827, in pandas._libs.parsers.TextReader._read_rows\n",
      "  File \"pandas/_libs/parsers.pyx\", line 814, in pandas._libs.parsers.TextReader._tokenize_rows\n",
      "  File \"pandas/_libs/parsers.pyx\", line 1943, in pandas._libs.parsers.raise_parser_error\n",
      "  File \"/projects/.local/lib/python3.7/site-packages/s3fs/core.py\", line 1938, in _fetch_range\n",
      "    req_kw=self.req_kw,\n",
      "  File \"/projects/.local/lib/python3.7/site-packages/s3fs/core.py\", line 2081, in _fetch_range\n",
      "    return sync(fs.loop, resp[\"Body\"].read)\n",
      "  File \"/projects/.local/lib/python3.7/site-packages/fsspec/asyn.py\", line 59, in sync\n",
      "    if event.wait(1):\n",
      "  File \"/opt/conda/lib/python3.7/threading.py\", line 552, in wait\n",
      "    signaled = self._cond.wait(timeout)\n",
      "  File \"/opt/conda/lib/python3.7/threading.py\", line 300, in wait\n",
      "    gotit = waiter.acquire(True, timeout)\n",
      "KeyboardInterrupt\n",
      "CPU times: user 480 ms, sys: 165 ms, total: 645 ms\n",
      "Wall time: 38.3 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "TILE_NUM = 131 #NEED_TILES[6]\n",
    "args = f\"\\\n",
    "-LC_filter True \\\n",
    "--extract_covars \\\n",
    "--do_30m \\\n",
    "--do_dps \\\n",
    "-years_list 2019 2020 2021 \\\n",
    "-o /projects/my-public-bucket/atl08_filt_covar_tiles \\\n",
    "-in_tile_num {TILE_NUM} \\\n",
    "-in_tile_fn /projects/shared-buckets/nathanmthomas/boreal_tiles_v003.gpkg \\\n",
    "-in_tile_layer boreal_tiles_v003 \\\n",
    "-in_tile_id_col tile_num \\\n",
    "-csv_list_fn /projects/shared-buckets/lduncanson/DPS_tile_lists/ATL08_tindex_master.csv \\\n",
    "-topo_stack_list_fn /projects/shared-buckets/nathanmthomas/DPS_tile_lists/Topo_tindex_master.csv \\\n",
    "-landsat_stack_list_fn /projects/shared-buckets/nathanmthomas/DPS_tile_lists/Landsat_tindex_master.csv \\\n",
    "-user_stacks nathanmthomas \\\n",
    "-user_atl08 lduncanson \\\n",
    "-thresh_sol_el 5 \\\n",
    "-v_ATL08 5 -minmonth 4 -maxmonth 10\"\n",
    "print(args)\n",
    "!python /projects/icesat2_boreal/lib/tile_atl08.py $args"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
