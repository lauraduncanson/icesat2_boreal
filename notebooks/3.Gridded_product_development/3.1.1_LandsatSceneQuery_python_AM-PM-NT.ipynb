{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Identify Landsat Scenes for Covariate\n",
    "\n",
    "Using the USGS STAC based sat-api, query Landsat 8 scences for a given aoi (analysis tile), over time window of interest, with additional quality filters. Save the resulting query to a geojson catalog file for use in the next step Greenest Pixel Compositing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/projects/.local/lib/python3.7/site-packages/geopandas/_compat.py:110: UserWarning: The Shapely GEOS version (3.8.0-CAPI-1.13.1 ) is incompatible with the GEOS version PyGEOS was compiled with (3.8.1-CAPI-1.13.3). Conversions between both will be slow.\n",
      "  shapely_geos_version, geos_capi_version_string\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import json\n",
    "import requests\n",
    "import datetime\n",
    "\n",
    "from CovariateUtils import get_index_tile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Search for imagery\n",
    "# https://github.com/developmentseed/example-jupyter-notebooks/blob/landsat-search/notebooks/Landsat8-Search/L8-USGS-satapi.ipynb\n",
    "\n",
    "\n",
    "sat_api_url = \"https://landsatlook.usgs.gov/sat-api\"\n",
    "\n",
    "def query_satapi(query):\n",
    "    headers = {\n",
    "            \"Content-Type\": \"application/json\",\n",
    "            \"Accept-Encoding\": \"gzip\",\n",
    "            \"Accept\": \"application/geo+json\",\n",
    "        }\n",
    "\n",
    "    url = f\"{sat_api_url}/stac/search\"\n",
    "    data = requests.post(url, headers=headers, json=query).json()\n",
    "    \n",
    "    return data\n",
    "\n",
    "def query_year(year, bbox, min_cloud, max_cloud):\n",
    "    '''Given the year, finds the number of scenes matching the query and returns it.'''\n",
    "    date_min = '-'.join([str(year), \"06-01\"])\n",
    "    date_max = '-'.join([str(year), \"09-15\"])\n",
    "    start_date = datetime.datetime.strptime(date_min, \"%Y-%m-%d\")\n",
    "    end_date = datetime.datetime.strptime(date_max, \"%Y-%m-%d\") \n",
    "    start = start_date.strftime(\"%Y-%m-%dT00:00:00Z\")\n",
    "    end = end_date.strftime(\"%Y-%m-%dT23:59:59Z\")\n",
    "    \n",
    "    query = {\n",
    "    \"time\": f\"{start}/{end}\",\n",
    "    \"bbox\":bbox,\n",
    "    \"query\": {\n",
    "        \"collections\": [\"landsat-c2l2-sr\"],\n",
    "        \"platform\": {\"in\": [\"LANDSAT_8\"]},\n",
    "        \"eo:cloud_cover\": {\"gte\": min_cloud, \"lt\": max_cloud},\n",
    "        \"landsat:collection_category\":{\"in\": [\"T1\"]}\n",
    "    },\n",
    "    \"limit\": 20 # We limit to 500 items per Page (requests) to make sure sat-api doesn't fail to return big features collection\n",
    "    }\n",
    "    \n",
    "    data = query_satapi(query)\n",
    "    \n",
    "    # you can't trouble shoot if you don't return the actual results\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "geojson_path_albers = \"/projects/shared-buckets/alexdevseed/boreal_tiles.gpkg\"\n",
    "layer = \"boreal_tiles_albers\"\n",
    "tile_n = 30543\n",
    "\n",
    "tile_id = get_index_tile(geojson_path_albers, tile_n, buffer=0, layer = layer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[4, 7, 12, 7, 4, 6]\n"
     ]
    }
   ],
   "source": [
    "# Accessing imagery\n",
    "# Select an area of interest\n",
    "#bbox_list = [[-105,45,-100,50], [-101,45,-100,46]] # Not Boreal Enough\n",
    "bbox_list = [tile_id['bbox_4326']]\n",
    "min_cloud = 0\n",
    "max_cloud = 20\n",
    "years = range(2015,2020 + 1)\n",
    "for bbox in bbox_list:\n",
    "    # Geojson of total scenes - Change to list of scenes\n",
    "    response_by_year = [query_year(year, bbox, min_cloud, max_cloud ) for year in years]\n",
    "    scene_totals = [each['meta']['found'] for each in response_by_year]\n",
    "    print(scene_totals)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "ename": "OSError",
     "evalue": "[Errno 30] Read-only file system: '/projects/shared-buckets/alexdevseed/landsat8/sample2/response-30543-2015.json'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mOSError\u001b[0m                                   Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-8-99f6550bca58>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0myr\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0myears\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m     \u001b[0mcatalog\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msave_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34mf'response-{tile_n}-{years[yr]}.json'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m     \u001b[0;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcatalog\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'w'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mjsonfile\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m         \u001b[0mjson\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdump\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresponse_by_year\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0myr\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mjsonfile\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m         \u001b[0mcatalogs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcatalog\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mOSError\u001b[0m: [Errno 30] Read-only file system: '/projects/shared-buckets/alexdevseed/landsat8/sample2/response-30543-2015.json'"
     ]
    }
   ],
   "source": [
    "# Take the search over several years, write the geojson response for each\n",
    "## TODO: need unique catalog names that indicate bbox tile, and time range used.\n",
    "save_path = '/projects/shared-buckets/alexdevseed/landsat8/sample2'\n",
    "if (not os.path.isdir(save_path)): os.mkdir(save_path)\n",
    "catalogs = []\n",
    "for yr in range(0,len(years)):\n",
    "    catalog = os.path.join(save_path, f'response-{tile_n}-{years[yr]}.json')\n",
    "    with open(catalog, 'w') as jsonfile:\n",
    "        json.dump(response_by_year[yr], jsonfile)\n",
    "        catalogs.append(catalog)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "ename": "ClientError",
     "evalue": "An error occurred (403) when calling the HeadObject operation: Forbidden",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mClientError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-16-ee5e588ae3cc>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[0msamplehttp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"https://maap-ops-dataset.s3.amazonaws.com/maap-users/alexdevseed/landsat8/sample2/locals3-30543-2018.json\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m \u001b[0msamples3\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'\"s3://maap-ops-dataset/maap-users/alexdevseed/landsat8/sample2/locals3-30543-2018.json'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 20\u001b[0;31m \u001b[0mtest\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_json\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msamples3\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'/projects/tmp'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-16-ee5e588ae3cc>\u001b[0m in \u001b[0;36mget_json\u001b[0;34m(s3path, output_dir)\u001b[0m\n\u001b[1;32m     10\u001b[0m     \u001b[0mbucket_name\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0ms3path\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"/\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m     \u001b[0ms3_key\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"/\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msamples3\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"/\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 12\u001b[0;31m     \u001b[0ms3\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mBucket\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbucket_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdownload_file\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ms3_key\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutput_file\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     13\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput_file\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/boto3-1.17.30-py3.7.egg/boto3/s3/inject.py\u001b[0m in \u001b[0;36mbucket_download_file\u001b[0;34m(self, Key, Filename, ExtraArgs, Callback, Config)\u001b[0m\n\u001b[1;32m    244\u001b[0m     return self.meta.client.download_file(\n\u001b[1;32m    245\u001b[0m         \u001b[0mBucket\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mKey\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mKey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mFilename\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mFilename\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 246\u001b[0;31m         ExtraArgs=ExtraArgs, Callback=Callback, Config=Config)\n\u001b[0m\u001b[1;32m    247\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    248\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/boto3-1.17.30-py3.7.egg/boto3/s3/inject.py\u001b[0m in \u001b[0;36mdownload_file\u001b[0;34m(self, Bucket, Key, Filename, ExtraArgs, Callback, Config)\u001b[0m\n\u001b[1;32m    170\u001b[0m         return transfer.download_file(\n\u001b[1;32m    171\u001b[0m             \u001b[0mbucket\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mBucket\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mKey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfilename\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mFilename\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 172\u001b[0;31m             extra_args=ExtraArgs, callback=Callback)\n\u001b[0m\u001b[1;32m    173\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    174\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/boto3-1.17.30-py3.7.egg/boto3/s3/transfer.py\u001b[0m in \u001b[0;36mdownload_file\u001b[0;34m(self, bucket, key, filename, extra_args, callback)\u001b[0m\n\u001b[1;32m    305\u001b[0m             bucket, key, filename, extra_args, subscribers)\n\u001b[1;32m    306\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 307\u001b[0;31m             \u001b[0mfuture\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    308\u001b[0m         \u001b[0;31m# This is for backwards compatibility where when retries are\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    309\u001b[0m         \u001b[0;31m# exceeded we need to throw the same error from boto3 instead of\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/s3transfer-0.3.4-py3.7.egg/s3transfer/futures.py\u001b[0m in \u001b[0;36mresult\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    104\u001b[0m             \u001b[0;31m# however if a KeyboardInterrupt is raised we want want to exit\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    105\u001b[0m             \u001b[0;31m# out of this and propogate the exception.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 106\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_coordinator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    107\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mKeyboardInterrupt\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    108\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcancel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/s3transfer-0.3.4-py3.7.egg/s3transfer/futures.py\u001b[0m in \u001b[0;36mresult\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    263\u001b[0m         \u001b[0;31m# final result.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    264\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_exception\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 265\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_exception\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    266\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_result\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    267\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/s3transfer-0.3.4-py3.7.egg/s3transfer/tasks.py\u001b[0m in \u001b[0;36m_main\u001b[0;34m(self, transfer_future, **kwargs)\u001b[0m\n\u001b[1;32m    253\u001b[0m             \u001b[0;31m# Call the submit method to start submitting tasks to execute the\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    254\u001b[0m             \u001b[0;31m# transfer.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 255\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_submit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtransfer_future\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtransfer_future\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    256\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mBaseException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    257\u001b[0m             \u001b[0;31m# If there was an exception raised during the submission of task\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/s3transfer-0.3.4-py3.7.egg/s3transfer/download.py\u001b[0m in \u001b[0;36m_submit\u001b[0;34m(self, client, config, osutil, request_executor, io_executor, transfer_future, bandwidth_limiter)\u001b[0m\n\u001b[1;32m    341\u001b[0m                 \u001b[0mBucket\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtransfer_future\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmeta\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcall_args\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbucket\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    342\u001b[0m                 \u001b[0mKey\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtransfer_future\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmeta\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcall_args\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 343\u001b[0;31m                 \u001b[0;34m**\u001b[0m\u001b[0mtransfer_future\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmeta\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcall_args\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mextra_args\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    344\u001b[0m             )\n\u001b[1;32m    345\u001b[0m             transfer_future.meta.provide_transfer_size(\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/botocore-1.20.30-py3.7.egg/botocore/client.py\u001b[0m in \u001b[0;36m_api_call\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    355\u001b[0m                     \"%s() only accepts keyword arguments.\" % py_operation_name)\n\u001b[1;32m    356\u001b[0m             \u001b[0;31m# The \"self\" in this scope is referring to the BaseClient.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 357\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_api_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moperation_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    358\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    359\u001b[0m         \u001b[0m_api_call\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__name__\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpy_operation_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/botocore-1.20.30-py3.7.egg/botocore/client.py\u001b[0m in \u001b[0;36m_make_api_call\u001b[0;34m(self, operation_name, api_params)\u001b[0m\n\u001b[1;32m    674\u001b[0m             \u001b[0merror_code\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mparsed_response\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Error\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Code\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    675\u001b[0m             \u001b[0merror_class\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexceptions\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrom_code\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0merror_code\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 676\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0merror_class\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparsed_response\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moperation_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    677\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    678\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mparsed_response\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mClientError\u001b[0m: An error occurred (403) when calling the HeadObject operation: Forbidden"
     ]
    }
   ],
   "source": [
    "import boto3\n",
    "def get_json(s3path, output_dir):\n",
    "    '''\n",
    "    Download a json from S3 to the output directory\n",
    "    '''\n",
    "    aws_session = boto3.session.Session()\n",
    "    s3 = aws_session.resource('s3')\n",
    "    output_file = os.path.join(output_dir, os.path.basename(s3path))\n",
    "    #TODO split the bucket name from the s3 path\n",
    "    bucket_name = s3path.split(\"/\")[2]\n",
    "    s3_key = \"/\".join(samples3.split(\"/\")[3:])\n",
    "    s3.Bucket(bucket_name).download_file(s3_key, output_file)\n",
    "    \n",
    "    with open(output_file) as f:\n",
    "        catalog = json.load(f) \n",
    "    return catalog\n",
    "\n",
    "samplehttp = \"https://maap-ops-dataset.s3.amazonaws.com/maap-users/alexdevseed/landsat8/sample2/locals3-30543-2018.json\"\n",
    "samples3 = '\"s3://maap-ops-dataset/maap-users/alexdevseed/landsat8/sample2/locals3-30543-2018.json'\n",
    "test = get_json(samples3, '/projects/tmp')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exploring Results as Spatial layer\n",
    "\n",
    "The return from the api is a valid geojson per page. You can directly plot this on a map (e.g. folium). Below is an expirement to convert to geopandas, however only the 'properties' key is maintained as an attribute, which isn't going to work since we also need the 'assests'. TODO: Need to flatten the json before loading to geopandas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "## TODO: change to conda install -c conda-forge\n",
    "%pip install -q folium\n",
    "%pip install -q geopandas\n",
    "%pip install -q shapely"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import geopandas as gpd\n",
    "import folium\n",
    "import shapely as shp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Silly but it's easier to write the json to file and read back in right now to get a valid geopandas frame.\n",
    "# Dilemna reading geojson with geopandas only pull the \"properties\" in as attributes\n",
    "#with open(f'response-{yr}.json', 'w') as jsonfile:\n",
    "#    json.dump(response, jsonfile)\n",
    "\n",
    "#scenes_poly1 = gpd.read_file('response.json')\n",
    "#scenes_poly1.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "geometry\n",
      "datetime\n",
      "eo:cloud_cover\n",
      "view:sun_azimuth\n",
      "view:sun_elevation\n",
      "platform\n",
      "instruments\n",
      "view:off_nadir\n",
      "landsat:cloud_cover_land\n",
      "landsat:wrs_type\n",
      "landsat:wrs_path\n",
      "landsat:wrs_row\n",
      "landsat:scene_id\n",
      "landsat:collection_category\n",
      "landsat:collection_number\n",
      "landsat:correction\n",
      "proj:epsg\n",
      "proj:shape\n",
      "proj:transform\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>geometry</th>\n",
       "      <th>datetime</th>\n",
       "      <th>eo:cloud_cover</th>\n",
       "      <th>view:sun_azimuth</th>\n",
       "      <th>view:sun_elevation</th>\n",
       "      <th>platform</th>\n",
       "      <th>instruments</th>\n",
       "      <th>view:off_nadir</th>\n",
       "      <th>landsat:cloud_cover_land</th>\n",
       "      <th>landsat:wrs_type</th>\n",
       "      <th>landsat:wrs_path</th>\n",
       "      <th>landsat:wrs_row</th>\n",
       "      <th>landsat:scene_id</th>\n",
       "      <th>landsat:collection_category</th>\n",
       "      <th>landsat:collection_number</th>\n",
       "      <th>landsat:correction</th>\n",
       "      <th>proj:epsg</th>\n",
       "      <th>proj:shape</th>\n",
       "      <th>proj:transform</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>POLYGON ((-117.90855 52.75991, -118.62326 51.0...</td>\n",
       "      <td>2020-09-10T18:42:19.025128Z</td>\n",
       "      <td>3.36</td>\n",
       "      <td>159.224638</td>\n",
       "      <td>41.108349</td>\n",
       "      <td>LANDSAT_8</td>\n",
       "      <td>[OLI, TIRS]</td>\n",
       "      <td>0</td>\n",
       "      <td>3.36</td>\n",
       "      <td>2</td>\n",
       "      <td>044</td>\n",
       "      <td>024</td>\n",
       "      <td>LC80440242020254LGN00</td>\n",
       "      <td>T1</td>\n",
       "      <td>02</td>\n",
       "      <td>L2SP</td>\n",
       "      <td>32611</td>\n",
       "      <td>[8021, 7921]</td>\n",
       "      <td>[30, 0, 384285, 0, -30, 5846715]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>POLYGON ((-118.49411 51.34454, -119.17569 49.6...</td>\n",
       "      <td>2020-08-25T18:42:36.040695Z</td>\n",
       "      <td>12.54</td>\n",
       "      <td>154.152875</td>\n",
       "      <td>47.615272</td>\n",
       "      <td>LANDSAT_8</td>\n",
       "      <td>[OLI, TIRS]</td>\n",
       "      <td>0</td>\n",
       "      <td>12.54</td>\n",
       "      <td>2</td>\n",
       "      <td>044</td>\n",
       "      <td>025</td>\n",
       "      <td>LC80440252020238LGN00</td>\n",
       "      <td>T1</td>\n",
       "      <td>02</td>\n",
       "      <td>L2SP</td>\n",
       "      <td>32611</td>\n",
       "      <td>[8021, 7931]</td>\n",
       "      <td>[30, 0, 340785, 0, -30, 5689815]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>POLYGON ((-116.94429 51.34515, -117.62484 49.6...</td>\n",
       "      <td>2020-08-18T18:36:21.560496Z</td>\n",
       "      <td>5.57</td>\n",
       "      <td>152.456053</td>\n",
       "      <td>49.743891</td>\n",
       "      <td>LANDSAT_8</td>\n",
       "      <td>[OLI, TIRS]</td>\n",
       "      <td>0</td>\n",
       "      <td>5.57</td>\n",
       "      <td>2</td>\n",
       "      <td>043</td>\n",
       "      <td>025</td>\n",
       "      <td>LC80430252020231LGN00</td>\n",
       "      <td>T1</td>\n",
       "      <td>02</td>\n",
       "      <td>L2SP</td>\n",
       "      <td>32611</td>\n",
       "      <td>[7941, 7831]</td>\n",
       "      <td>[30, 0, 452985, 0, -30, 5688915]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>POLYGON ((-116.34411 52.76023, -117.05765 51.0...</td>\n",
       "      <td>2020-08-18T18:35:57.673692Z</td>\n",
       "      <td>5.78</td>\n",
       "      <td>153.937001</td>\n",
       "      <td>48.631092</td>\n",
       "      <td>LANDSAT_8</td>\n",
       "      <td>[OLI, TIRS]</td>\n",
       "      <td>0</td>\n",
       "      <td>5.78</td>\n",
       "      <td>2</td>\n",
       "      <td>043</td>\n",
       "      <td>024</td>\n",
       "      <td>LC80430242020231LGN00</td>\n",
       "      <td>T1</td>\n",
       "      <td>02</td>\n",
       "      <td>L2SP</td>\n",
       "      <td>32611</td>\n",
       "      <td>[7921, 7821]</td>\n",
       "      <td>[30, 0, 493785, 0, -30, 5846415]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>POLYGON ((-116.94300 51.34515, -117.62359 49.6...</td>\n",
       "      <td>2020-08-02T18:36:16.128698Z</td>\n",
       "      <td>6.58</td>\n",
       "      <td>148.999814</td>\n",
       "      <td>54.014274</td>\n",
       "      <td>LANDSAT_8</td>\n",
       "      <td>[OLI, TIRS]</td>\n",
       "      <td>0</td>\n",
       "      <td>6.58</td>\n",
       "      <td>2</td>\n",
       "      <td>043</td>\n",
       "      <td>025</td>\n",
       "      <td>LC80430252020215LGN00</td>\n",
       "      <td>T1</td>\n",
       "      <td>02</td>\n",
       "      <td>L2SP</td>\n",
       "      <td>32611</td>\n",
       "      <td>[7941, 7841]</td>\n",
       "      <td>[30, 0, 452685, 0, -30, 5688915]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            geometry  \\\n",
       "0  POLYGON ((-117.90855 52.75991, -118.62326 51.0...   \n",
       "1  POLYGON ((-118.49411 51.34454, -119.17569 49.6...   \n",
       "2  POLYGON ((-116.94429 51.34515, -117.62484 49.6...   \n",
       "3  POLYGON ((-116.34411 52.76023, -117.05765 51.0...   \n",
       "4  POLYGON ((-116.94300 51.34515, -117.62359 49.6...   \n",
       "\n",
       "                      datetime  eo:cloud_cover  view:sun_azimuth  \\\n",
       "0  2020-09-10T18:42:19.025128Z            3.36        159.224638   \n",
       "1  2020-08-25T18:42:36.040695Z           12.54        154.152875   \n",
       "2  2020-08-18T18:36:21.560496Z            5.57        152.456053   \n",
       "3  2020-08-18T18:35:57.673692Z            5.78        153.937001   \n",
       "4  2020-08-02T18:36:16.128698Z            6.58        148.999814   \n",
       "\n",
       "   view:sun_elevation   platform  instruments  view:off_nadir  \\\n",
       "0           41.108349  LANDSAT_8  [OLI, TIRS]               0   \n",
       "1           47.615272  LANDSAT_8  [OLI, TIRS]               0   \n",
       "2           49.743891  LANDSAT_8  [OLI, TIRS]               0   \n",
       "3           48.631092  LANDSAT_8  [OLI, TIRS]               0   \n",
       "4           54.014274  LANDSAT_8  [OLI, TIRS]               0   \n",
       "\n",
       "   landsat:cloud_cover_land landsat:wrs_type landsat:wrs_path landsat:wrs_row  \\\n",
       "0                      3.36                2              044             024   \n",
       "1                     12.54                2              044             025   \n",
       "2                      5.57                2              043             025   \n",
       "3                      5.78                2              043             024   \n",
       "4                      6.58                2              043             025   \n",
       "\n",
       "        landsat:scene_id landsat:collection_category  \\\n",
       "0  LC80440242020254LGN00                          T1   \n",
       "1  LC80440252020238LGN00                          T1   \n",
       "2  LC80430252020231LGN00                          T1   \n",
       "3  LC80430242020231LGN00                          T1   \n",
       "4  LC80430252020215LGN00                          T1   \n",
       "\n",
       "  landsat:collection_number landsat:correction  proj:epsg    proj:shape  \\\n",
       "0                        02               L2SP      32611  [8021, 7921]   \n",
       "1                        02               L2SP      32611  [8021, 7931]   \n",
       "2                        02               L2SP      32611  [7941, 7831]   \n",
       "3                        02               L2SP      32611  [7921, 7821]   \n",
       "4                        02               L2SP      32611  [7941, 7841]   \n",
       "\n",
       "                     proj:transform  \n",
       "0  [30, 0, 384285, 0, -30, 5846715]  \n",
       "1  [30, 0, 340785, 0, -30, 5689815]  \n",
       "2  [30, 0, 452985, 0, -30, 5688915]  \n",
       "3  [30, 0, 493785, 0, -30, 5846415]  \n",
       "4  [30, 0, 452685, 0, -30, 5688915]  "
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# This works but you have to manually set the crs\n",
    "yr = 5\n",
    "scenes_poly = gpd.GeoDataFrame.from_features(response_by_year[yr], crs='epsg:4326')\n",
    "for col in scenes_poly.columns: print(col)\n",
    "\n",
    "scenes_poly.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "list index out of range",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-17-fcf2e0133398>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m#sc_bbox = scenes_poly.total_bounds #scene boundaries is not as useful as the original bbox to query\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;31m# TODO: loop over years to check that the bbox is covered, n < 8 in 1 year testing has less than full coverage.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0msc_bbox\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbbox_list\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0msc_bbox_polygon\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mshp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgeometry\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbox\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msc_bbox\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msc_bbox\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msc_bbox\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msc_bbox\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mcenter\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msc_bbox_polygon\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcentroid\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mIndexError\u001b[0m: list index out of range"
     ]
    }
   ],
   "source": [
    "#sc_bbox = scenes_poly.total_bounds #scene boundaries is not as useful as the original bbox to query\n",
    "# TODO: loop over years to check that the bbox is covered, n < 8 in 1 year testing has less than full coverage.\n",
    "sc_bbox = bbox_list[1]\n",
    "sc_bbox_polygon = shp.geometry.box(sc_bbox[0], sc_bbox[1], sc_bbox[2], sc_bbox[3])\n",
    "center = sc_bbox_polygon.centroid\n",
    "\n",
    "m = folium.Map(\n",
    "    location=[center.y,center.x],\n",
    "    tiles=\"cartodbpositron\",\n",
    "    zoom_start=6,\n",
    ")\n",
    "\n",
    "bbox_style = {'fillColor': '#ff0000', 'color': '#ff0000'}\n",
    "\n",
    "folium.GeoJson(scenes_poly, name=\"geojson\").add_to(m)\n",
    "folium.GeoJson(sc_bbox_polygon,\n",
    "               name=\"bbox\",\n",
    "               style_function=lambda x:bbox_style).add_to(m)\n",
    "\n",
    "m"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cache the results\n",
    "\n",
    "> Note: For testing purposes, a local copy of a sample bbox was downloaded. In the real analysis the DPS jobs will read data as needed directly from USGS buckets. This code is here simply to demonstrate how it can be done.\n",
    "\n",
    "TODO move data reading to next step.\n",
    "\n",
    "1. Cache the json from the query (save as files)\n",
    "1. Loop over a few of them, and download the source\n",
    "1. Write a new copy of the json with internal ADE urls to the same files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "import boto3\n",
    "import botocore\n",
    "\n",
    "aws_session2 = boto3.session.Session(\n",
    "    aws_access_key_id=aws_access_key_id,\n",
    "    aws_secret_access_key=aws_secret_access_key,\n",
    ")\n",
    "s3 = aws_session2.resource('s3')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read the json file catalog\n",
    "def write_local_data_and_catalog(catalog, bands):\n",
    "    '''Given path to a response json from a sat-api query, make a copy changing urls to local paths'''\n",
    "    with open(catalog) as f:\n",
    "        asset_catalog = json.load(f)\n",
    "        for feature in asset_catalog['features']:\n",
    "            new_dir = os.path.join(save_path, feature['id'])\n",
    "            if (not os.path.isdir(new_dir)): os.mkdir(new_dir)\n",
    "            #download the assests\n",
    "            for band in bands:\n",
    "                try:\n",
    "                    key = feature['assets'][f'SR_{band}.TIF']['href'].replace('https://landsatlook.usgs.gov/data/', '')\n",
    "                    output_file = os.path.join(new_dir, os.path.basename(key))\n",
    "                    #print(key)\n",
    "                    ## Uncomment next line to actually download the data as a local sample\n",
    "                    #s3.Bucket('usgs-landsat').download_file(key, output_file, ExtraArgs={'RequestPayer':'requester'})\n",
    "                    feature['assets'][f'SR_{band}.TIF']['href'] = output_file\n",
    "                except botocore.exceptions.ClientError as e:\n",
    "                    if e.response['Error']['Code'] == \"404\":\n",
    "                        print(\"The object does not exist.\")\n",
    "                    else:\n",
    "                        raise\n",
    "        # save and updated catalog with local paths\n",
    "        local_catalog = catalog.replace('response', 'locals3')\n",
    "        with open(local_catalog,'w') as jsonfile:\n",
    "            json.dump(asset_catalog, jsonfile)\n",
    "        \n",
    "        return local_catalog"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# if not catalogs then read file names from save_path response-{yr}.json\n",
    "bands = [''.join([\"B\",str(item)])for item in range(2,8,1)]\n",
    "local_catalogs = [write_local_data_and_catalog(catalog, bands) for catalog in catalogs]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/projects/alexdevseed/landsat8/sample2/local-2015.json'"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "write_local_data_and_catalog(catalogs[0], bands)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "#write a maap s3 based catalog\n",
    "def write_local_data_and_catalog_s3(catalog, bands):\n",
    "    '''Given path to a response json from a sat-api query, make a copy changing urls to local paths'''\n",
    "    with open(catalog) as f:\n",
    "        asset_catalog = json.load(f)\n",
    "        for feature in asset_catalog['features']:\n",
    "            #new_dir = os.path.join(save_path, feature['id'])\n",
    "            #if (not os.path.isdir(new_dir)): os.mkdir(new_dir)\n",
    "            #download the assests\n",
    "            for band in bands:\n",
    "                try:\n",
    "                    key = feature['assets'][f'SR_{band}.TIF']['href'].replace(\n",
    "                        'https://landsatlook.usgs.gov/data/',\n",
    "                        '')\n",
    "                    output_file = os.path.join(\n",
    "                        f's3://maap-ops-dataset/alexdevseed/landsat8/sample2/{feature[\"id\"]}/'\n",
    "                        , os.path.basename(key))\n",
    "                    #print(key)\n",
    "                    ## Uncomment next line to actually download the data as a local sample\n",
    "                    #s3.Bucket('usgs-landsat').download_file(key, output_file, ExtraArgs={'RequestPayer':'requester'})\n",
    "                    feature['assets'][f'SR_{band}.TIF']['href'] = output_file\n",
    "                except botocore.exceptions.ClientError as e:\n",
    "                    if e.response['Error']['Code'] == \"404\":\n",
    "                        print(\"The object does not exist.\")\n",
    "                    else:\n",
    "                        raise\n",
    "        # save and updated catalog with local paths\n",
    "        local_catalog = catalog.replace('response', 'locals3')\n",
    "        with open(local_catalog,'w') as jsonfile:\n",
    "            json.dump(asset_catalog, jsonfile)\n",
    "        \n",
    "        return local_catalog"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# if not catalogs then read file names from save_path response-{yr}.json\n",
    "bands = [''.join([\"B\",str(item)])for item in range(2,7,1)]\n",
    "local_catalogs = [write_local_data_and_catalog_s3(catalog, bands) for catalog in catalogs]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "outputPrepend"
    ]
   },
   "outputs": [],
   "source": [
    "## Retrieving Pixels\n",
    "bands = [2,3,4,5,6]\n",
    "bbox = bbox_list[1]\n",
    "# TODO: \n",
    "# Loop over each scene\n",
    "response = response_by_year[1]\n",
    "# Each season should actually be it's own DPS job\n",
    "for item in response['features']:\n",
    "    # for each scene Loop over bands 2,3,4,5,6 (assets)\n",
    "    for band in bands:\n",
    "        # For each scene, read subset set by bounding box\n",
    "        asset = item['assets'][f'SR_B{band}.TIF']['href']\n",
    "        # Convert to S3 url for use with requester pays\n",
    "        cog = asset.replace('https://landsatlook.usgs.gov/data/', 's3://usgs-landsat/')\n",
    "        print(cog) \n",
    "        # Since the source files are per band, the 1st band in a given file is default\n",
    "        # Bound Box reprojected on the fly to the native projection of the asset\n",
    "        #subset, crs, transform = extract_subset(cog, bbox, 1)\n",
    "\n",
    "    # stack the bands into the same array with n layers (z direction)?\n",
    "    # optional: calculate indexes based on the bands and store as additional layers\n",
    "    # save cog to disk (could be a kea or Zarr(xarray))\n",
    "# after looping, make a VRT of cogs so it can be treated as a single file ?\n",
    "\n",
    "# Questions, \n",
    "# 1. should the tiling scheme be LonLat 1 degree, the end Equal area projection, or utm zone based? take bbox reproject to LonLat for the query\n",
    "# 2. do we need the QA band or can we do that separate, the only limitation on cogs is that the storage type needs to be identical in all bands. Kea or Zarr could accomodate, or if the pixels are cloud filtered before saving the stack then a COG is ok."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'driver': 'GTiff', 'dtype': 'uint16', 'nodata': 0.0, 'width': 7831, 'height': 7921, 'count': 1, 'crs': CRS.from_epsg(32611), 'transform': Affine(30.0, 0.0, 492885.0,\n",
      "       0.0, -30.0, 5846415.0), 'blockxsize': 256, 'blockysize': 256, 'tiled': True, 'compress': 'deflate', 'interleave': 'band'}\n"
     ]
    }
   ],
   "source": [
    "import boto3\n",
    "from rasterio.session import AWSSession\n",
    "import rasterio as rio\n",
    "aws_session = AWSSession(boto3.Session())\n",
    "with rio.Env(aws_session):\n",
    "    with rio.open('s3://maap-ops-dataset/alexdevseed/landsat8/sample2/LC08_L2SP_043024_20160604_20200906_02_T1/LC08_L2SP_043024_20160604_20200906_02_T1_SR_B4.TIF', 'r') as src:\n",
    "        print(src.profile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'stuffLC08_L2SP_044024_20150812_20200909_02_T1'"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test = \"LC08_L2SP_044024_20150812_20200909_02_T1_SR\"\n",
    "f'stuff{test[:-3]}'"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
