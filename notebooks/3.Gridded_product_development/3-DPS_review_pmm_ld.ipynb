{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0a4a23dc",
   "metadata": {},
   "source": [
    "# Review DPS outputs\n",
    "Make a mosaic of DPS outputs.\n",
    "\n",
    "1. make a list of the DPS output paths with build_tindex.master.py\n",
    "2. Identify duplicate tiles\n",
    "3. Identify matching tiles; merge tindex.master with the original index tile file\n",
    "4. make mosaicjson\n",
    "5. View DPS results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "af495175",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/projects/.local/lib/python3.7/site-packages/geopandas/_compat.py:110: UserWarning: The Shapely GEOS version (3.8.0-CAPI-1.13.1 ) is incompatible with the GEOS version PyGEOS was compiled with (3.9.1-CAPI-1.14.2). Conversions between both will be slow.\n",
      "  shapely_geos_version, geos_capi_version_string\n"
     ]
    }
   ],
   "source": [
    "import geopandas\n",
    "import pandas as pd\n",
    "import os\n",
    "import json\n",
    "import collections\n",
    "import numpy as np\n",
    "import sys\n",
    "sys.path.append('/projects/icesat2_boreal/lib')\n",
    "sys.path.append('/projects/Developer/icesat2_boreal/lib')\n",
    "import maplib_folium\n",
    "def local_to_s3(url, user = 'nathanmthomas', type='public'):\n",
    "    ''' A Function to convert local paths to s3 urls'''\n",
    "    if type is 'public':\n",
    "        replacement_str = f's3://maap-ops-workspace/shared/{user}'\n",
    "    else:\n",
    "        replacement_str = f's3://maap-ops-workspace/{user}'\n",
    "    return url.replace(f'/projects/my-{type}-bucket', replacement_str)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c502d7ef",
   "metadata": {},
   "source": [
    "# Choose a DPS data type; get its tile index master file\n",
    "Get a filename of the master list DPS output tiles returned with _build_tindexmaster.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "29a842b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "DPS_DATA_TYPE = 'ATL08_filt' #\"Topo\" \"Landsat\" \"ATL08\" \"ATL08_filt\" \"AGB\"\n",
    "DPS_DATA_USER = 'nathanmthomas' #'nathanmthomas' 'lduncanson'\n",
    "tindex_master_fn = f'/projects/shared-buckets/{DPS_DATA_USER}/DPS_tile_lists/{DPS_DATA_TYPE}_tindex_master.csv'\n",
    "####---TMP---#####\n",
    "tindex_master_fn = '/projects/my-private-bucket/dps_output/run_tile_atl08_ubuntu/master/2022/run_LC_height_thresholds_v2/ATL08_filt_tindex_master.csv'\n",
    "#tindex_master_fn = f'/projects/shared-buckets/{DPS_DATA_USER}/Topo/{DPS_DATA_TYPE}_tindex_master.csv'\n",
    "####\n",
    "\n",
    "#tindex_master_fn = '/projects/my-private-bucket/dps_output/run_tile_atl08_ubuntu/master/2022/run_LC_height_thresholds/ATL08_filt_tindex_master.csv'\n",
    "\n",
    "#Get other tile index master files\n",
    "\n",
    "ATL08_filt_sample_tindex_master_fn = f'/projects/shared-buckets/lduncanson/DPS_tile_lists/ATL08_filt_sample_tindex_master.csv'\n",
    "#ATL08_filt_tindex_master_fn = '/projects/test_dps/ATL08_filt_tindex_master.csv'#'s3://maap-ops-workspace/shared/lduncanson/DPS_tile_lists/ATL08_filt_tindex_master.csv'\n",
    "ATL08_filt_tindex_master_fn = 's3://maap-ops-workspace/shared/lduncanson/DPS_tile_lists/ATL08_filt_tindex_master.csv'\n",
    "Topo_tindex_master_fn = f'/projects/shared-buckets/nathanmthomas/DPS_tile_lists/Topo_tindex_master.csv'\n",
    "\n",
    "Topo_tindex_master =   pd.read_csv(Topo_tindex_master_fn)\n",
    "ATL08_filt_tindex_master =   pd.read_csv(ATL08_filt_tindex_master_fn)\n",
    "ATL08_filt_sample_tindex_master = pd.read_csv(ATL08_filt_sample_tindex_master_fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4520ba0f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Building master tile index for: ATL08_filt\n",
      "python: can't open file '/projects/icesat2_boreal/lib/build_tindex_master_v2.py': [Errno 2] No such file or directory\n"
     ]
    }
   ],
   "source": [
    "UPDATE_TINDEX = False\n",
    "\n",
    "if not os.path.isfile(tindex_master_fn):\n",
    "     UPDATE_TINDEX = True\n",
    "else:\n",
    "    print('Using existing tindex')\n",
    "    print(tindex_master_fn)\n",
    "\n",
    "    \n",
    "if UPDATE_TINDEX:\n",
    "    print(f\"Building master tile index for: {DPS_DATA_TYPE}\")\n",
    "    dps_month = 'run_LC_height_thresholds'\n",
    "    d_min = 1\n",
    "    #os.system(f\"python /projects/icesat2_boreal/lib/build_tindex_master.py --type {DPS_DATA_TYPE} -m {dps_month} -d_min {d_min}\")\n",
    "    !python /projects/icesat2_boreal/lib/build_tindex_master_v2.py --type $DPS_DATA_TYPE -m $dps_month -d_min $d_min\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ded3da3c",
   "metadata": {},
   "source": [
    "### Get the tiles needed for the data of interest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c2d7229e",
   "metadata": {},
   "outputs": [
    {
     "ename": "OSError",
     "evalue": "[Errno 107] Transport endpoint is not connected: '/projects/my-private-bucket/dps_output/run_tile_atl08_ubuntu/master/2022/run_LC_height_thresholds_v2/ATL08_filt_tindex_master.csv'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mOSError\u001b[0m                                   Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-4-bb6c0c148fa3>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# Build up a dataframe from the list of dps output files\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mtindex_master\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtindex_master_fn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mDPS_DATA_TYPE\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'Landsat'\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mDPS_DATA_TYPE\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'HLS'\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mDPS_DATA_TYPE\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'Topo'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0mDPS_DATA_USER\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'nathanmthomas'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.7/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36mread_csv\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, squeeze, prefix, mangle_dupe_cols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, dialect, error_bad_lines, warn_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options)\u001b[0m\n\u001b[1;32m    608\u001b[0m     \u001b[0mkwds\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkwds_defaults\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    609\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 610\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_read\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    611\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    612\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.7/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    460\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    461\u001b[0m     \u001b[0;31m# Create the parser.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 462\u001b[0;31m     \u001b[0mparser\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTextFileReader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    463\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    464\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mchunksize\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0miterator\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.7/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[1;32m    817\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"has_index_names\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"has_index_names\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    818\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 819\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_engine\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mengine\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    820\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    821\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.7/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m_make_engine\u001b[0;34m(self, engine)\u001b[0m\n\u001b[1;32m   1048\u001b[0m             )\n\u001b[1;32m   1049\u001b[0m         \u001b[0;31m# error: Too many arguments for \"ParserBase\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1050\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mmapping\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mengine\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[call-arg]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1051\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1052\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_failover_to_python\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.7/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, src, **kwds)\u001b[0m\n\u001b[1;32m   1865\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1866\u001b[0m         \u001b[0;31m# open handles\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1867\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_open_handles\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msrc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1868\u001b[0m         \u001b[0;32massert\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhandles\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1869\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mkey\u001b[0m \u001b[0;32min\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m\"storage_options\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"encoding\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"memory_map\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"compression\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.7/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m_open_handles\u001b[0;34m(self, src, kwds)\u001b[0m\n\u001b[1;32m   1366\u001b[0m             \u001b[0mcompression\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"compression\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1367\u001b[0m             \u001b[0mmemory_map\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"memory_map\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1368\u001b[0;31m             \u001b[0mstorage_options\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"storage_options\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1369\u001b[0m         )\n\u001b[1;32m   1370\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.7/site-packages/pandas/io/common.py\u001b[0m in \u001b[0;36mget_handle\u001b[0;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[1;32m    645\u001b[0m                 \u001b[0mencoding\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mioargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mencoding\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    646\u001b[0m                 \u001b[0merrors\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0merrors\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 647\u001b[0;31m                 \u001b[0mnewline\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    648\u001b[0m             )\n\u001b[1;32m    649\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mOSError\u001b[0m: [Errno 107] Transport endpoint is not connected: '/projects/my-private-bucket/dps_output/run_tile_atl08_ubuntu/master/2022/run_LC_height_thresholds_v2/ATL08_filt_tindex_master.csv'"
     ]
    }
   ],
   "source": [
    "# Build up a dataframe from the list of dps output files\n",
    "tindex_master = pd.read_csv(tindex_master_fn)\n",
    "\n",
    "if DPS_DATA_TYPE == 'Landsat' or DPS_DATA_TYPE == 'HLS' or DPS_DATA_TYPE == 'Topo':\n",
    "    DPS_DATA_USER = 'nathanmthomas'\n",
    "    \n",
    "tindex_master['s3'] = [local_to_s3(local_path, user=DPS_DATA_USER, type = 'private') for local_path in tindex_master['local_path']]\n",
    "print(f\"# of expected {DPS_DATA_TYPE} tiles:\\t\\t\\t\\t\\t\\t{len(tindex_master)}\")\n",
    "\n",
    "# Wherever there is a 90k Topo tile, there should be data...\n",
    "# Get all covar tiles that should account for the set of output we want\n",
    "tiles_covars = pd.read_csv(Topo_tindex_master_fn).tile_num\n",
    "print(f\"# of expected covar (from Topo) tiles:\\t\\t\\t\\t\\t{len(tiles_covars)}\")\n",
    "\n",
    "# Get all boreal tiles\n",
    "boreal_tile_index_path = '/projects/shared-buckets/nathanmthomas/boreal_tiles_v003.gpkg' \n",
    "boreal_tile_index = geopandas.read_file(boreal_tile_index_path)\n",
    "#boreal_tile_index.astype({'layer':'int'})\n",
    "#boreal_tile_index.rename(columns={\"layer\":\"tile_num\"}, inplace=True)\n",
    "boreal_tile_index[\"tile_num\"] = boreal_tile_index[\"tile_num\"].astype(int)\n",
    "\n",
    "bad_tiles = [3540,3634,3728,3823,3916,4004] #Dropping the tiles near antimeridian that reproject poorly.\n",
    "# For some reason, doing this causes 'MosaicJSON.from_features()' to fail...(below)\n",
    "if True:\n",
    "    # Remove bad tiles\n",
    "    boreal_tile_index = boreal_tile_index[~boreal_tile_index['tile_num'].isin(bad_tiles)]\n",
    "    \n",
    "    \n",
    "select_needs = [3360,2994,3190,2840,3012,3014,3017,2932,1261,1263,1264,988,978,794, 380,378,411,821,861,\n",
    "                812,765,764,1308,1302,1469,1406,2495,2883,2965,3321,3509,3510,3327,3335,2976,2906,2907,2894,2814,4253,4293,4403,4440,4408,4372,4477,3986]\n",
    "tile_matches_select_needs = boreal_tile_index.merge(ATL08_filt_tindex_master[ATL08_filt_tindex_master['tile_num'].isin(select_needs)], how='right', on='tile_num')\n",
    "print(f\"# of {DPS_DATA_TYPE} tiles needed (compared with {os.path.basename(ATL08_filt_tindex_master_fn)}):\\t{len(tile_matches_select_needs)}\")\n",
    "\n",
    "print(f\"# of total tiles supposedly needed (from {os.path.basename(boreal_tile_index_path)}):\\t{len(boreal_tile_index)}\")\n",
    "\n",
    "if len(tile_matches_select_needs)<100:\n",
    "    print([t for t in tile_matches_select_needs.tile_num])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35c3e396",
   "metadata": {},
   "source": [
    "### Identify duplicate tiles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0642bcc9",
   "metadata": {},
   "outputs": [],
   "source": [
    "duplicate_tiles = [item for item, count in collections.Counter(tindex_master[\"tile_num\"]).items() if count > 1]\n",
    "print(duplicate_tiles)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf29ba26",
   "metadata": {},
   "source": [
    "### Identify completed, missing, failed, & duplicate tiles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb6d662a",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Tile status report for {DPS_DATA_TYPE} from {tindex_master_fn}:\")\n",
    "# For the tindex_master, convert it into vector tiles that show the tiles we have\n",
    "# Select the rows we have results for\n",
    "tile_index_matches = boreal_tile_index.merge(tindex_master[~tindex_master['tile_num'].isin(bad_tiles)][['tile_num','s3_path','local_path']], how='left', on='tile_num')\n",
    "#tile_matches_atl08_filt_samples = boreal_tile_index.merge(ATL08_filt_sample_tindex_master[~ATL08_filt_sample_tindex_master['tile_num'].isin(bad_tiles)], how='right', on='tile_num')\n",
    "print(f'\\t# tiles matched:\\t\\t{len(tile_index_matches)}')\n",
    "\n",
    "# Use the Topo tiles (COVAR set) to get the diff of what tiles we have and what we want\n",
    "# MISSING TILES = DIFF(tiles_we_want, tiles_we_have)\n",
    "#tile_nums_missing = np.setdiff1d(tiles_covars, tile_index_matches.tile_num)\n",
    "tile_nums_missing_list = list(set(tiles_covars) - set(tile_index_matches.tile_num))\n",
    "tile_nums_missing_list = list(set(tile_index_matches.tile_num) - set(tiles_covars))\n",
    "# The ATL08 tiles we have may not exactly match the set of COVAR tiles we have\n",
    "# Use the set of ATL08 tiles we have, crossed with the tiles we're missing (based on COVAR set), to get tiles we're missing that we should definitely proces (b/c we have both COVAR and ATL08 tiles for them)\n",
    "#tile_index_missing = boreal_tile_index.merge(boreal_tile_index[boreal_tile_index['tile_num'].isin(tile_nums_missing_list)], how='right', on='tile_num')\n",
    "#tile_index_missing = boreal_tile_index.merge(tindex_master[tindex_master['tile_num'].isin(tile_nums_missing_list)], how='inner', on='tile_num')\n",
    "tile_index_missing = boreal_tile_index[boreal_tile_index['tile_num'].isin(tile_nums_missing_list)]\n",
    "\n",
    "print(f'\\t# tiles missing:\\t\\t{len(tile_index_missing)}')\n",
    "tile_index_missing.to_file(f'/projects/my-public-bucket/DPS_tile_lists/Need_{DPS_DATA_TYPE}_tindex_master.gpkg', driver='GPKG')\n",
    "#print(tile_index_missing.head())\n",
    "\n",
    "# Meh, this doesnt give us fails\n",
    "#tile_matches_failed = boreal_tile_index.merge(Topo_tindex_master[Topo_tindex_master['tile_num'].isin(tile_nums_missing)], how='right', on='tile_num')\n",
    "#print(f'Missing b/c failed: \\t{len(tile_matches_failed)}')\n",
    "\n",
    "# Duplicates are also removed in build_tindex_master\n",
    "tile_matches_duplicates = boreal_tile_index.merge(tiles_covars[tiles_covars.isin(duplicate_tiles)], how='right', on='tile_num')\n",
    "print(f'\\t# tiles duplicated: \\t\\t{len(tile_matches_duplicates)}')\n",
    "\n",
    "# Drop duplicates\n",
    "tile_index_matches = tile_index_matches.drop_duplicates(subset=['tile_num'], keep='last')\n",
    "print(f\"Missing tiles:\\t{tile_nums_missing_list}\")\n",
    "print(f\"Bad tiles:\\t{bad_tiles}\")\n",
    "\n",
    "ax = tile_index_matches.plot(color='black')\n",
    "tile_index_missing.plot(column='tile_group', ax=ax)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74695af6",
   "metadata": {},
   "outputs": [],
   "source": [
    "if 's3_path' in tile_index_matches.columns:\n",
    "    tile_index_matches['s3'] = tile_index_matches['s3_path']\n",
    "    \n",
    "tile_index_matches = tile_index_matches[tile_index_matches['s3'].notna()]\n",
    "tile_index_matches.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba0e360f",
   "metadata": {},
   "source": [
    "## Build a MosaicJSON"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aea78af1",
   "metadata": {},
   "source": [
    "##### Build tile geojsons needed for mosaic jsons"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e917483",
   "metadata": {},
   "outputs": [],
   "source": [
    "tile_matches_geojson_string = tile_index_matches.to_crs(\"EPSG:4326\").to_json()\n",
    "tile_matches_geojson = json.loads(tile_matches_geojson_string)\n",
    "#Write copy to disk for debug\n",
    "tile_matches_geojson_fn = f's3://maap-ops-workspace/shared/{DPS_DATA_USER}/DPS_tile_lists/{DPS_DATA_TYPE}_tindex_master.json' \n",
    "tile_index_matches.to_file(tile_matches_geojson_fn, driver='GeoJSON')\n",
    "\n",
    "if len(tile_index_missing) > 0:\n",
    "    tile_index_missing_geojson_string = tile_index_missing.to_crs(\"EPSG:4326\").to_json()\n",
    "    tile_index_missing_geojson = json.loads(tile_index_missing_geojson_string)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b44bd96",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install pystac"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75149877",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Dict\n",
    "\n",
    "from cogeo_mosaic.mosaic import MosaicJSON\n",
    "from cogeo_mosaic.backends import MosaicBackend\n",
    "\n",
    "def get_accessor(feature: Dict):\n",
    "    \"\"\"Return specific feature identifier.\"\"\"\n",
    "    return feature[\"properties\"][\"s3\"]\n",
    "\n",
    "out_mosaic_json_fn = f's3://maap-ops-workspace/shared/{DPS_DATA_USER}/DPS_tile_lists/{DPS_DATA_TYPE}_tindex_master_mosaic.json' \n",
    "#out_mosaic_json_fn = f's3://maap-ops-workspace/shared/alexdevseed/DPS_tile_lists/{DPS_DATA_TYPE}_tindex_master_mosaic.json' \n",
    "\n",
    "print(f\"Building {out_mosaic_json_fn}\")\n",
    "mosaicdata = MosaicJSON.from_features(tile_matches_geojson.get('features'), minzoom=6, maxzoom=18, accessor=get_accessor)\n",
    "\n",
    "with MosaicBackend(out_mosaic_json_fn, mosaic_def=mosaicdata) as mosaic:\n",
    "    mosaic.write(overwrite=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b5391ad",
   "metadata": {},
   "source": [
    "## View the Results with Folium"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ea511b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from folium import Map, TileLayer, GeoJson, LayerControl, Icon, Marker, features, Figure, CircleMarker\n",
    "from folium import plugins\n",
    "\n",
    "# Setup the mosaic tiling\n",
    "tiler_base = \"https://jqsd6bqdsf.execute-api.us-west-2.amazonaws.com/\" #titiler.maap-project.org\n",
    "tiler_mosaic =  \"\".join([tiler_base, \"mosaicjson/tiles/{z}/{x}/{y}\"])\n",
    "\n",
    "import branca.colormap as cm\n",
    "import matplotlib.cm\n",
    "pal_height_cmap = cm.LinearColormap(colors = ['black','#636363','#fc8d59','#fee08b','#ffffbf','#d9ef8b','#91cf60','#1a9850'], vmin=0, vmax=10)\n",
    "pal_height_cmap.caption = 'Vegetation height from  ATL08 @ 30 m (h_can; rh98)'\n",
    "#pal_height_cmap\n",
    "\n",
    "dem_tiles_index_path = '/projects/shared-buckets/nathanmthomas/dem30m_tiles.geojson'\n",
    "dem_tiles_index = geopandas.read_file(dem_tiles_index_path)\n",
    "dem_tiles_index['tile_num'] = dem_tiles_index.index\n",
    "dem_tiles_index.to_file('/projects/my-public-bucket/dem30m_tiles_v2.geojson')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5eea22c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "maplib_folium.MAP_DPS_RESULTS(tiler_mosaic, DPS_DATA_TYPE, boreal_tile_index, tile_index_matches, tile_index_missing, \n",
    "                              mosaic_json_dict = {\n",
    "                                        'agb_mosaic_json_s3_fn':    's3://maap-ops-workspace/shared/lduncanson/DPS_tile_lists/AGB_tindex_master_mosaic.json',\n",
    "                                        'topo_mosaic_json_s3_fn':   's3://maap-ops-workspace/shared/nathanmthomas/DPS_tile_lists/Topo_tindex_master_mosaic.json',\n",
    "                                        'mscomp_mosaic_json_s3_fn': 's3://maap-ops-workspace/shared/nathanmthomas/DPS_tile_lists/HLS_tindex_master_mosaic.json'\n",
    "                                    },\n",
    "                             MS_BANDMAX=1,\n",
    "                             MS_BANDNUM=7,\n",
    "                             MS_BANDCOLORBAR='plasma'\n",
    "                             )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "639b7916",
   "metadata": {},
   "outputs": [],
   "source": [
    "maplib_folium.MAP_DPS_RESULTS(tiler_mosaic, DPS_DATA_TYPE, dem_tiles_index, tile_index_matches, tile_index_missing)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b6bc7d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "maplib_folium.map_tile_n_obs(tindex_master_fn='s3://maap-ops-workspace/shared/lduncanson/DPS_tile_lists/ATL08_filt_tindex_master.csv', \n",
    "                   map_name = '# of filtered ATL08 obs. from night & day', max_n_obs=15000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ceef31f",
   "metadata": {},
   "outputs": [],
   "source": [
    "maplib_folium.map_tile_n_obs(tindex_master_fn='s3://maap-ops-workspace/shared/lduncanson/DPS_tile_lists/ATL08_filt_sample_tindex_master.csv', \n",
    "                   map_name = '# of samples of filtered ATL08 obs. from night', max_n_obs=250)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8cbaba7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a2bc2fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "maplib_folium.map_tile_atl08(2804, DO_NIGHT=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
