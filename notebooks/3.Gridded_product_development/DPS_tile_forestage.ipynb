{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ea7bcf9f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from maap.maap import MAAP\n",
    "maap = MAAP(maap_host='api.maap-project.org')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "330e3ace",
   "metadata": {},
   "source": [
    "# Launch DPS for `tile_forestage.py`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5c541eee",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NASA MAAP\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import geopandas as gpd\n",
    "import pandas as pd\n",
    "import glob\n",
    "import datetime\n",
    "\n",
    "import sys\n",
    "sys.path.append('/projects/code/icesat2_boreal/lib')\n",
    "import ExtractUtils"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3dcb10ef-b19d-45dd-92b6-2144822256ad",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Steps to commit, build DPS registration yaml, register DPS algorithm from yaml\n",
    "### Commit with Tag for running\n",
    "1) Tag the version of the repo that works to run your alg. Use a *tag* of `build_stack_v2024_1` or whatever is appropriate (eg, for AGB runs maybe do `boreal_agb_2023_v1` for consistency?)\n",
    "  - to maintain sanity, use this GitHub *tag* also as the `algorithm_version` that you need to supply to your algorithm config yaml  \n",
    "2) think now about how you want your output organized:  \n",
    "  - remember, the output will be like: `dps_output/<algorithm name>/<algorithm_version>/<IDENTIFIER>`  \n",
    "  - note: identifier for biomass runs should be `AGB_2020` , for height `HT_2020`  \n",
    "  - if different types of `AGB_2020` runs (eg like is you are testing different sets of parameters associated with model dev/application you can keep the results separate from one run to the next, delivering the output into different subdirs, by modifying this IDENTIFIER like this: `AGB_2020/run_param_set01`     \n",
    "    \n",
    "  \n",
    "3) follow git instructions (every time!!):  \n",
    " - git add changes  \n",
    " - git commit -m 'message'  \n",
    " - git tag -f `tile_standage_v1`    \n",
    " - git push  \n",
    " - git push origin -f `tile_standage_v1`  \n",
    "\n",
    "3) if it looks weird check git log to make sure tag is at same place as origin and dps"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ba0b895-6891-4003-a625-7bd4c49869cb",
   "metadata": {},
   "source": [
    "### Use MAAP Registration call in notebook chunk to register DPS algorithm\n",
    " - We need to register a DPS algorithm called `run_build_stack_LC` before proceeding to the chunks below..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7810c9e6-5dc8-4969-b1f4-beb3d06e9d96",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "maap.register_algorithm_from_yaml_file(\"/projects/code/icesat2_boreal/dps/registered/run_tile_forestage.yml\").text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "d6cb0ec4-f54b-40ab-8b80-b0d46524342f",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tile_num</th>\n",
       "      <th>tile_version</th>\n",
       "      <th>tile_group</th>\n",
       "      <th>map_version</th>\n",
       "      <th>geometry</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>version 1</td>\n",
       "      <td>eurasia west</td>\n",
       "      <td>none</td>\n",
       "      <td>POLYGON ((-2151478.000 9423304.000, -2061478.0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>version 1</td>\n",
       "      <td>eurasia west</td>\n",
       "      <td>none</td>\n",
       "      <td>POLYGON ((-2061478.000 9423304.000, -1971478.0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>version 1</td>\n",
       "      <td>eurasia west</td>\n",
       "      <td>none</td>\n",
       "      <td>POLYGON ((-1971478.000 9423304.000, -1881478.0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>version 1</td>\n",
       "      <td>eurasia west</td>\n",
       "      <td>none</td>\n",
       "      <td>POLYGON ((-2241478.000 9333304.000, -2151478.0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>version 1</td>\n",
       "      <td>eurasia west</td>\n",
       "      <td>none</td>\n",
       "      <td>POLYGON ((-2151478.000 9333304.000, -2061478.0...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   tile_num tile_version    tile_group map_version  \\\n",
       "0         1    version 1  eurasia west        none   \n",
       "1         2    version 1  eurasia west        none   \n",
       "2         3    version 1  eurasia west        none   \n",
       "3         4    version 1  eurasia west        none   \n",
       "4         5    version 1  eurasia west        none   \n",
       "\n",
       "                                            geometry  \n",
       "0  POLYGON ((-2151478.000 9423304.000, -2061478.0...  \n",
       "1  POLYGON ((-2061478.000 9423304.000, -1971478.0...  \n",
       "2  POLYGON ((-1971478.000 9423304.000, -1881478.0...  \n",
       "3  POLYGON ((-2241478.000 9333304.000, -2151478.0...  \n",
       "4  POLYGON ((-2151478.000 9333304.000, -2061478.0...  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Boreal Tiles \n",
    "boreal_tiles_model_ready_fn = 'https://maap-ops-workspace.s3.amazonaws.com/shared/montesano/databank/boreal_tiles_v004.gpkg'\n",
    "boreal_tiles = gpd.read_file(boreal_tiles_model_ready_fn)\n",
    "m = boreal_tiles.explore(color='red')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "836409b4",
   "metadata": {},
   "source": [
    "# Build a DPS list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 246,
   "id": "819c19c8-5da2-417b-8489-6a21e903e460",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5197\n"
     ]
    }
   ],
   "source": [
    "DPS_INPUT_TILE_NUM_LIST = boreal_tiles['tile_num'].to_list()\n",
    "print(len(DPS_INPUT_TILE_NUM_LIST))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "8857874a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "RUN_MISSING_TILES = True\n",
    "MISSING_TILES = list(range(3448, 3468)) + list(range(3355,3375)) + list(range(3543, 3563)) \n",
    "if RUN_MISSING_TILES:\n",
    "    DPS_INPUT_TILE_NUM_LIST = MISSING_TILES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "cc5082d9",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "60"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(DPS_INPUT_TILE_NUM_LIST)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0fea3b7",
   "metadata": {},
   "source": [
    "#### Note: make sure the `in_params_dict` coincides with the args of `tile_forestage.py`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "65681b96",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "in_params_dict = {\n",
    "            'in_url': 'https://datapub.gfz-potsdam.de/download/10.5880.GFZ.1.4.2023.006-VEnuo/GAMIv2-1_2010-2020_100m.nc',\n",
    "            'in_vector_fn': 'https://maap-ops-workspace.s3.amazonaws.com/shared/montesano/databank/boreal_tiles_v004.gpkg' ,\n",
    "            'in_id_col': 'tile_num',\n",
    "            'in_id_num': '' ,\n",
    "            'year': '2020'\n",
    "            }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "cf6b76d6",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'in_url': 'https://datapub.gfz-potsdam.de/download/10.5880.GFZ.1.4.2023.006-VEnuo/GAMIv2-1_2010-2020_100m.nc',\n",
       " 'in_vector_fn': 'https://maap-ops-workspace.s3.amazonaws.com/shared/montesano/databank/boreal_tiles_v004.gpkg',\n",
       " 'in_id_num': '',\n",
       " 'in_id_col': 'tile_num',\n",
       " 'year': '2020'}"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "in_params_dict"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86193dd5",
   "metadata": {},
   "source": [
    "## Run a DPS job across the list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "5e619703-7095-4f06-b707-9497690434ae",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# MAAP algorithm version name\n",
    "IDENTIFIER='forestage_2020'\n",
    "MAAP_VERSION = 'tile_forestage_v1'\n",
    "ALGO_ID = \"run_tile_forestage\"\n",
    "USER = 'montesano'\n",
    "WORKER_TYPE = 'maap-dps-gedi_boreal_worker-16gb'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "01c52cde-1d06-4007-a637-34988938b099",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "run_build_stack, build_stack_v2023_2, TCC_TP_2020\n"
     ]
    }
   ],
   "source": [
    "RUN_NAME = IDENTIFIER\n",
    "print(f\"{ALGO_ID}, {MAAP_VERSION}, {RUN_NAME}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "4abfe38b",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# of input tiles for DPS: 287\n",
      "DPS run #: 1\t| tile num: 39425\t| submit status: success\t| job id: 5513828d-4b53-4300-bba4-7137b28de73a\n",
      "DPS run #: 5\t| tile num: 1031\t| submit status: success\t| job id: 32ebcb9f-bb60-4a9d-b955-27f026480c24\n",
      "DPS run #: 10\t| tile num: 1548\t| submit status: success\t| job id: 70b592ee-e8b9-45e9-b19a-1248024b06c5\n",
      "DPS run #: 50\t| tile num: 4392\t| submit status: success\t| job id: 0fde5ca7-45da-41c0-a28c-8e8445618739\n",
      "DPS run #: 100\t| tile num: 1197\t| submit status: success\t| job id: a125208e-d55c-4daf-8ad3-6a3fb76b7219\n",
      "DPS run #: 250\t| tile num: 428\t| submit status: success\t| job id: 9cff7ae8-82f9-4ba3-b139-a5907048ebce\n",
      "DPS run #: 287\t| tile num: 504\t| submit status: success\t| job id: c2953a09-1535-4835-9f85-0ae95174884f\n",
      "Current time:\t202501170803\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 287 entries, 0 to 0\n",
      "Data columns (total 10 columns):\n",
      " #   Column         Non-Null Count  Dtype \n",
      "---  ------         --------------  ----- \n",
      " 0   dps_num        287 non-null    int64 \n",
      " 1   tile_num       287 non-null    int64 \n",
      " 2   submit_time    287 non-null    object\n",
      " 3   dbs_job_hour   287 non-null    int64 \n",
      " 4   algo_id        287 non-null    object\n",
      " 5   user           287 non-null    object\n",
      " 6   worker_type    287 non-null    object\n",
      " 7   job_id         287 non-null    object\n",
      " 8   submit_status  287 non-null    object\n",
      " 9   run_name       287 non-null    object\n",
      "dtypes: int64(3), object(7)\n",
      "memory usage: 24.7+ KB\n",
      "CPU times: user 6.3 s, sys: 148 ms, total: 6.45 s\n",
      "Wall time: 33.3 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "import json\n",
    "\n",
    "submit_results_df_list = []\n",
    "len_input_list = len(DPS_INPUT_TILE_NUM_LIST)\n",
    "print(f\"# of input tiles for DPS: {len_input_list}\")\n",
    "\n",
    "for i, INPUT_TILE_NUM in enumerate(DPS_INPUT_TILE_NUM_LIST):\n",
    "    \n",
    "    DPS_num = i+1\n",
    "    \n",
    "    # Update the in_params_dict with th current INPUT_TILE_NUM\n",
    "    in_params_dict['in_tile_num'] = INPUT_TILE_NUM\n",
    "    \n",
    "    submit_result = maap.submitJob(\n",
    "            identifier=IDENTIFIER,\n",
    "            algo_id=ALGO_ID,\n",
    "            version=MAAP_VERSION,\n",
    "            username=USER, # username needs to be the same as whoever created the workspace\n",
    "            queue=WORKER_TYPE,\n",
    "            **in_params_dict\n",
    "        )\n",
    "    \n",
    "    # Build a dataframe of submission details\n",
    "    submit_result_df = pd.DataFrame( \n",
    "        {\n",
    "                'dps_num':[DPS_num],\n",
    "                'tile_num':[INPUT_TILE_NUM],\n",
    "                'submit_time':[datetime.datetime.now().strftime('%Y-%m-%d-%H-%M-%s')],\n",
    "                'dbs_job_hour': [datetime.datetime.now().hour],\n",
    "                'algo_id': [ALGO_ID],\n",
    "                'user': [USER],\n",
    "                'worker_type': [WORKER_TYPE],\n",
    "                'job_id': [submit_result.id],\n",
    "                'submit_status': [submit_result.status],\n",
    "            \n",
    "        } \n",
    "    )\n",
    "    \n",
    "    # Append to a list of data frames of submission results\n",
    "    submit_results_df_list.append(submit_result_df)\n",
    "    \n",
    "    if DPS_num in [1, 5, 10, 50, 100, 250, 500, 750, 1000, 1500, 2000, 2500, 3000, 3500, 4000, 4500, 5000, 7000, 9000, 11000, 13000, 15000, 17000, 19000, 21000, 24000, len_input_list]:\n",
    "        print(f\"DPS run #: {DPS_num}\\t| tile num: {INPUT_TILE_NUM}\\t| submit status: {submit_result.status}\\t| job id: {submit_result.id}\") \n",
    "        \n",
    "# Build a final submission results df and save\n",
    "submit_results_df = pd.concat(submit_results_df_list)\n",
    "submit_results_df['run_name'] = RUN_NAME\n",
    "nowtime = pd.Timestamp.now().strftime('%Y%m%d%H%M')\n",
    "print(f\"Current time:\\t{nowtime}\")\n",
    "submit_results_df.to_csv(f'/projects/my-public-bucket/dps_submission_results/DPS_{ALGO_ID}_{RUN_NAME}_submission_results_{len_input_list}_{nowtime}.csv')\n",
    "submit_results_df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62af6d0a",
   "metadata": {
    "tags": []
   },
   "source": [
    "After almost any DPS job, you have to assess what was marked as `success` and `fail`.  \n",
    "\n",
    "This involves:\n",
    "1. building a table of job status based on job ids captured in the job_results_df from the DPS run chunk (this takes 40 mins for ~47k jobs). This tells you how many jobs failed.\n",
    "2. merging the `job status table` with the `job results df`. This tells you which specific granules (or tile nums) failed.\n",
    "3. building another input list of granules/tiles for a follow-up DPS run.\n",
    "## Assess DPS results\n",
    "Build a table of job status based on job id - how many jobs failed?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "4ccd5836-5a5d-44b9-a56c-57ff1c2da30f",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NASA MAAP\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<module 'ExtractUtils' from '/projects/code/icesat2_boreal/lib/ExtractUtils.py'>"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import importlib\n",
    "import ExtractUtils\n",
    "importlib.reload(ExtractUtils)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "267b6baa-e4be-4991-b164-d0df18e4f141",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['/projects/my-public-bucket/dps_submission_results/DPS_run_build_stack_TCC_TP_2020_submission_results_287_202501170803.csv']"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "LIST_SUBMISSIONS = sorted(glob.glob(f'/projects/my-public-bucket/dps_submission_results/DPS_{ALGO_ID}_*_submission_results_*.csv'),key=ExtractUtils.func, reverse=True)\n",
    "LIST_SUBMISSIONS[0:1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f8194d3-233e-403e-979c-d269812941ff",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "running_list = []\n",
    "fails_list = []\n",
    "success_list = []\n",
    "offline_list = []\n",
    "\n",
    "#for DPS_DATETIME in [nowtime]:\n",
    "for fn in LIST_SUBMISSIONS[0:3]:\n",
    "    #if DPS_DATETIME in fn and not 'job_status' in fn:\n",
    "\n",
    "    DPS_alg_id = os.path.basename(fn.split('_submission_results_')[0].replace('DPS_',''))\n",
    "    thentime = fn.split('_')[-1].replace('.csv','')\n",
    "    print(f'DPS alg:\\t\\t{DPS_alg_id}')\n",
    "    print(f'DPS run name:\\t\\t{RUN_NAME}')\n",
    "    print(f'DPS launch time:\\t{thentime}')\n",
    "\n",
    "    # Build job status table\n",
    "    df_jstatus = ExtractUtils.BUILD_TABLE_JOBSTATUS(pd.read_csv(fn))\n",
    "\n",
    "    # Save job status table\n",
    "    df_jstatus.to_csv(f'/projects/my-public-bucket/dps_submission_results/DPS_{RUN_NAME}_submission_results_job_status_{len(df_jstatus)}_{thentime}.csv')\n",
    "\n",
    "    # Get current fails df and append to list\n",
    "    df_jstatus['run_type'] = RUN_NAME\n",
    "\n",
    "    running_list.append(df_jstatus[ (df_jstatus['status'] == 'Running') ] )\n",
    "    fails_list.append(  df_jstatus[ (df_jstatus['status'] == 'Failed') ] )\n",
    "    success_list.append(df_jstatus[ (df_jstatus['status'] == 'Succeeded') ] )\n",
    "    offline_list.append(df_jstatus[ (df_jstatus['status'] == 'Offline') ] )\n",
    "    print(f\"Count offline jobs: {df_jstatus[ (df_jstatus['status'] == 'Offline') ].shape[0]}\\n\")\n",
    "            \n",
    "df_all_running = pd.concat(running_list)          \n",
    "df_all_fails =   pd.concat(fails_list)\n",
    "df_all_success = pd.concat(success_list)\n",
    "df_all_offline = pd.concat(offline_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "95b8fa5e-f39f-4107-9c69-a01b70e2fd33",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#!aws s3 rm --recursive s3://maap-ops-workspace/montesano/dps_output/run_build_stack_topo/...../CopernicusGLO30"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "3e278cea-e2b4-44d0-a93f-dea80e8250a1",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[]\n"
     ]
    }
   ],
   "source": [
    "# New list = fails + still running + failed to even submit\n",
    "FAILS = df_all_fails.tile_num.to_list() +\\\n",
    "        df_all_running.tile_num.to_list() +\\\n",
    "        df_all_offline.tile_num.to_list() +\\\n",
    "        list(set(df_jstatus[df_jstatus.submit_status == 'failed'].tile_num.to_list()))\n",
    "FAILS = [int(i) for i in FAILS]\n",
    "len(FAILS)\n",
    "print(FAILS)\n",
    "DPS_INPUT_TILE_NUM_LIST=FAILS"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
