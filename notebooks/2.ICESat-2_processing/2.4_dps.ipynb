{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "macro-absence",
   "metadata": {},
   "outputs": [],
   "source": [
    "from maap.maap import MAAP\n",
    "maap = MAAP(maap_host='api.ops.maap-project.org')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "incorporated-peace",
   "metadata": {},
   "source": [
    "# Launch DPS for tile_atl08.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "annual-venezuela",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/projects/.local/lib/python3.7/site-packages/geopandas/_compat.py:110: UserWarning: The Shapely GEOS version (3.8.0-CAPI-1.13.1 ) is incompatible with the GEOS version PyGEOS was compiled with (3.9.1-CAPI-1.14.2). Conversions between both will be slow.\n",
      "  shapely_geos_version, geos_capi_version_string\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import geopandas\n",
    "import pandas as pd\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "lesbian-cartoon",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_stack_fn(stack_list_fn, in_tile_num):\n",
    "    # Find most recent topo/Landsat stack path for tile in list of stack paths from *tindex_master.csv\n",
    "    all_stacks_df = pd.read_csv(stack_list_fn)\n",
    "    stack_for_tile = all_stacks_df[all_stacks_df['location'].str.contains(\"_\"+str(in_tile_num))]\n",
    "    [print(i) for i in stack_for_tile.path.to_list()]\n",
    "    stack_for_tile_fn = stack_for_tile.path.to_list()[0]\n",
    "    if len(stack_for_tile)==0:\n",
    "        stack_for_tile_fn = None\n",
    "    return(stack_for_tile_fn)\n",
    "\n",
    "# nmt added: code that returns df of landsat locations and tile number\n",
    "# This is basically CountOutput.py\n",
    "def get_stack_df(dps_dir, TYPE, dps_year):\n",
    "    \n",
    "    if \"Landsat\" in TYPE:\n",
    "        root = f\"/projects/my-private-bucket/dps_output/do_landsat_stack_3-1-2_ubuntu/ops/{dps_year}/\"\n",
    "        ends_with_str = \"_dps.tif\"\n",
    "    if \"Topo\" in TYPE:\n",
    "        root = f\"/projects/my-private-bucket/dps_output/do_topo_stack_3-1-5_ubuntu/ops/{dps_year}/\"\n",
    "        ends_with_str = \"_stack.tif\"\n",
    "    if \"ATL08\" in TYPE:\n",
    "        root = f\"/projects/my-private-bucket/dps_output/run_extract_ubuntu/ops/{dps_year}/\"\n",
    "        ends_with_str = \"0m.csv\"\n",
    "            \n",
    "    df = pd.DataFrame(columns=['location', 'tile_num'])\n",
    "\n",
    "    for dir, subdir, files in os.walk(root):\n",
    "        for fname in files:\n",
    "            if fname.endswith(ends_with_str): \n",
    "                 \n",
    "                tile_num = fname.split('_')[1]\n",
    "                   \n",
    "                if \"ATL08\" in TYPE:\n",
    "                    df = df.append({'location':os.path.join(dir+\"/\", fname)},ignore_index=True)\n",
    "                else:\n",
    "                    df = df.append({'location':os.path.join(dir+\"/\", fname), 'tile_num':tile_num},ignore_index=True)\n",
    "        \n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "incorporate-thriller",
   "metadata": {},
   "source": [
    "## Get df's from tindex_master csvs for Topo and Landsat tiles"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "independent-straight",
   "metadata": {},
   "source": [
    "These are already done after 'build_tindex_master.py'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "powerful-triangle",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "os.system(\"python /projects/icesat2_boreal/lib/build_tindex_master.py --type Topo\")\n",
    "os.system(\"python /projects/icesat2_boreal/lib/build_tindex_master.py --type Landsat\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "requested-monte",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Topo and Landsat tindex_master csvs from CountOutput.py\n",
    "topo_tindex = \"/projects/shared-buckets/nathanmthomas/DPS_tile_lists/Topo_tindex_master.csv\"\n",
    "landsat_tindex = \"/projects/shared-buckets/nathanmthomas/DPS_tile_lists/Landsat_tindex_master.csv\"\n",
    "\n",
    "if True:\n",
    "    if os.path.isfile(landsat_tindex) and os.path.isfile(topo_tindex):\n",
    "        ls8_df = pd.read_csv(landsat_tindex)\n",
    "        topo_df = pd.read_csv(topo_tindex)\n",
    "    else:\n",
    "        s3_stem = 'https://s3.console.aws.amazon.com/s3/buckets/maap-ops-workspace/nathanmthomas'\n",
    "        local_stem = '/projects/my-private-bucket'\n",
    "\n",
    "        ls8_root =  s3_stem + '/dps_output/do_landsat_stack_3-1-2_ubuntu'\n",
    "        topo_root = s3_stem + '/dps_output/do_topo_stack_3-1-5_ubuntu'\n",
    "\n",
    "        ls8_df = get_stack_df(ls8_root, \"Landsat\", 2020)\n",
    "        topo_df = get_stack_df(topo_root, \"Topo\", 2020)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "balanced-defense",
   "metadata": {},
   "source": [
    "## Get tile nums for coincident Topo and Landsat tiles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "upper-wings",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                          local_path  tile_num\n",
      "0  /projects/my-private-bucket/dps_output/do_land...       986\n",
      "1  /projects/my-private-bucket/dps_output/do_land...       987\n",
      "2  /projects/my-private-bucket/dps_output/do_land...       979\n",
      "3  /projects/my-private-bucket/dps_output/do_land...       984\n",
      "4  /projects/my-private-bucket/dps_output/do_land...       982\n",
      "                                          local_path  tile_num\n",
      "0  /projects/my-private-bucket/dps_output/do_topo...       986\n",
      "1  /projects/my-private-bucket/dps_output/do_topo...       987\n",
      "2  /projects/my-private-bucket/dps_output/do_topo...       979\n",
      "3  /projects/my-private-bucket/dps_output/do_topo...       984\n",
      "4  /projects/my-private-bucket/dps_output/do_topo...       982\n",
      "4465 4465\n"
     ]
    }
   ],
   "source": [
    "# Model-read subset of tiles for which Topo and Landsat coincide\n",
    "model_ready_tiles_topo = \"/projects/shared-buckets/nathanmthomas/DPS_tile_lists/model_ready_tiles_topo_paths.csv\"\n",
    "model_ready_tiles_landsat = \"/projects/shared-buckets/nathanmthomas/DPS_tile_lists/model_ready_tiles_landsat_paths.csv\"\n",
    "\n",
    "if os.path.isfile(model_ready_tiles_topo) or os.path.isfile(model_ready_tiles_landsat):\n",
    "    topo_sub_df = pd.read_csv(model_ready_tiles_topo)\n",
    "    ls8_sub_df = pd.read_csv(model_ready_tiles_landsat)\n",
    "else:\n",
    "    # added by nmt: get filenames of co-incident landsat and topo\n",
    "    topo_sub_df = pd.DataFrame(columns=['local_path','tile_num'])\n",
    "    ls8_sub_df = pd.DataFrame(columns=['local_path','tile_num'])\n",
    "\n",
    "    for i in range(len(ls8_df['tile_num'])):\n",
    "        ls_tile_num = ls8_df['tile_num'][i]\n",
    "        for j in range(len(topo_df['tile_num'])):\n",
    "            topo_tile_num = topo_df['tile_num'][j]\n",
    "            if ls_tile_num == topo_tile_num:\n",
    "                # Only need to choose one, but we'll do 2 and then check\n",
    "                ls8_sub_df = ls8_sub_df.append({'local_path':ls8_df['local_path'][i],'tile_num':ls8_df['tile_num'][i].astype(int)}, ignore_index=True)\n",
    "                topo_sub_df = topo_sub_df.append({'local_path':topo_df['local_path'][j],'tile_num':topo_df['tile_num'][j].astype(int)}, ignore_index=True)\n",
    "\n",
    "    #ls8_sub_df['tile_num'] = ls8_sub_df['tile_num'].astype(float, errors = 'raise')\n",
    "\n",
    "    topo_sub_df.to_csv( model_ready_tiles_topo, index=False, encoding='utf-8-sig')\n",
    "    ls8_sub_df.to_csv( model_ready_tiles_landsat, index=False, encoding='utf-8-sig')\n",
    "    \n",
    "print(ls8_sub_df.head())\n",
    "print(topo_sub_df.head())\n",
    "print(len(ls8_sub_df),len(topo_sub_df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "loving-reservoir",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4465"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "topo_sub_df = pd.read_csv(\"/projects/shared-buckets/nathanmthomas/DPS_tile_lists/model_ready_tiles_topo_paths.csv\")\n",
    "INPUT_TILE_NUM_LIST = topo_sub_df['tile_num'].values.astype(int).tolist()\n",
    "len(INPUT_TILE_NUM_LIST)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "blond-passenger",
   "metadata": {},
   "source": [
    "## Run a DPS job"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "respected-wedding",
   "metadata": {},
   "outputs": [],
   "source": [
    "#\"https://maap-ops-workspace.s3.amazonaws.com.com/lduncanson\"\n",
    "#s3_stem = 'https://s3.console.aws.amazon.com/s3/buckets/maap-ops-workspace/nathanmthomas'\n",
    "#local_stem = '/projects/my-private-bucket'\n",
    "RUN_DPS  = False\n",
    "if RUN_DPS:\n",
    "    ##################################\n",
    "    #Test DPS submission on a single file\n",
    "    for i, INPUT_TILE_NUM in enumerate(INPUT_TILE_NUM_LIST):\n",
    "        DPS_num = i+1\n",
    "        if True:\n",
    "            in_param_dict = {\n",
    "                                'in_tile_num': INPUT_TILE_NUM,\n",
    "                                'in_tile_fn': 'https://maap-ops-workspace.s3.amazonaws.com/shared/nathanmthomas/boreal_grid_albers90k_gpkg.gpkg',\n",
    "                                'in_tile_layer': 'grid_boreal_albers90k_gpkg',\n",
    "                                'csv_list_fn': 's3://maap-ops-workspace/shared/lduncanson/DPS_tile_lists/ATL08_tindex_master.csv',\n",
    "                                'topo_stack_list_fn': 's3://maap-ops-workspace/shared/nathanmthomas/DPS_tile_lists/Topo_tindex_master.csv',\n",
    "                                'landsat_stack_list_fn': 's3://maap-ops-workspace/shared/nathanmthomas/DPS_tile_lists/Landsat_tindex_master.csv',\n",
    "                                'user_stacks': 'nathanmthomas',\n",
    "                                'user_atl08': 'lduncanson'\n",
    "            }\n",
    "\n",
    "            submit_result = maap.submitJob(\n",
    "                identifier='run_tile_atl08',\n",
    "                algo_id='run_tile_atl08_ubuntu',\n",
    "                version='master',\n",
    "                username='lduncanson', # username needs to be the same as whoever created the workspace\n",
    "                queue='maap-dps-worker-8gb',\n",
    "                **in_param_dict\n",
    "            )\n",
    "\n",
    "        #submit_result = 'submit test'\n",
    "        if DPS_num in [1, 100,500,1000,3000, len(INPUT_TILE_NUM_LIST)]:\n",
    "           print(f\"DPS run num: {DPS_num}, tile num: {INPUT_TILE_NUM}, job info: {submit_result}\") \n",
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "loaded-macedonia",
   "metadata": {},
   "source": [
    "Now build the tindex csv to show paths of all output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "stuffed-fashion",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.system(\"python /projects/icesat2_boreal/lib/build_tindex_master.py --type ATL08_filt\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "acoustic-economics",
   "metadata": {},
   "source": [
    "# Review the DPS outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "white-drill",
   "metadata": {},
   "outputs": [],
   "source": [
    "def local_to_s3(url, user = 'nathanmthomas', type='public'):\n",
    "    ''' A Function to convert local paths to s3 urls'''\n",
    "    if type is 'public':\n",
    "        replacement_str = f's3://maap-ops-workspace/shared/{user}'\n",
    "    else:\n",
    "        replacement_str = f's3://maap-ops-workspace/{user}'\n",
    "    return url.replace(f'/projects/my-{type}-bucket', replacement_str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "respiratory-grade",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Unnamed: 0                                         local_path  tile_num  \\\n",
      "0           0  /projects/my-private-bucket/dps_output/run_til...       986   \n",
      "1           1  /projects/my-private-bucket/dps_output/run_til...       986   \n",
      "2           2  /projects/my-private-bucket/dps_output/run_til...       979   \n",
      "3           3  /projects/my-private-bucket/dps_output/run_til...       987   \n",
      "4           4  /projects/my-private-bucket/dps_output/run_til...       982   \n",
      "\n",
      "                                                  s3  \n",
      "0  /projects/my-private-bucket/dps_output/run_til...  \n",
      "1  /projects/my-private-bucket/dps_output/run_til...  \n",
      "2  /projects/my-private-bucket/dps_output/run_til...  \n",
      "3  /projects/my-private-bucket/dps_output/run_til...  \n",
      "4  /projects/my-private-bucket/dps_output/run_til...  \n",
      "   tile_num                                           geometry\n",
      "0         1  POLYGON ((-2151478.000 9423304.000, -2061478.0...\n",
      "1         2  POLYGON ((-2061478.000 9423304.000, -1971478.0...\n",
      "2         3  POLYGON ((-1971478.000 9423304.000, -1881478.0...\n",
      "3         4  POLYGON ((-2241478.000 9333304.000, -2151478.0...\n",
      "4         5  POLYGON ((-2151478.000 9333304.000, -2061478.0...\n"
     ]
    }
   ],
   "source": [
    "tindex_master_fn = 's3://maap-ops-workspace/shared/lduncanson/DPS_tile_lists/ATL08_filt_tindex_master.csv'\n",
    "\n",
    "# Build up a dataframe from the list of dps output files\n",
    "tindex_master = pd.read_csv(tindex_master_fn)\n",
    "tindex_master['s3'] = [local_to_s3(local_path, user='lduncanson') for local_path in tindex_master['local_path']]\n",
    "print(tindex_master.head())\n",
    "\n",
    "# Get boreal tiles\n",
    "boreal_tile_index_path = '/projects/shared-buckets/nathanmthomas/boreal_grid_albers90k_gpkg.gpkg'\n",
    "boreal_tile_index = geopandas.read_file(boreal_tile_index_path)\n",
    "boreal_tile_index.astype({'layer':'int'})\n",
    "boreal_tile_index.rename(columns={\"layer\":\"tile_num\"}, inplace=True)\n",
    "boreal_tile_index[\"tile_num\"] = boreal_tile_index[\"tile_num\"].astype(int)\n",
    "\n",
    "bad_tiles = [3540,3634,3728,3823,3916,4004] #Dropping the tiles near antimeridian that reproject poorly.\n",
    "\n",
    "# For some reason, doing this causes 'MosaicJSON.from_features()' to fail...(below)\n",
    "if True:\n",
    "    # Remove bad tiles\n",
    "    boreal_tile_index = boreal_tile_index[~boreal_tile_index['tile_num'].isin(bad_tiles)]\n",
    "    \n",
    "print(boreal_tile_index.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "suburban-happiness",
   "metadata": {},
   "source": [
    "# Identify duplicate tiles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "excited-sense",
   "metadata": {},
   "outputs": [],
   "source": [
    "import collections\n",
    "duplicate_tiles = [item for item, count in collections.Counter(tindex_master[\"tile_num\"]).items() if count > 1]\n",
    "print(duplicate_tiles)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "textile-fever",
   "metadata": {},
   "source": [
    "# Identify matching tiles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "express-colony",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select the rows we have results for\n",
    "tile_matches = boreal_tile_index.merge(tindex_master[~tindex_master['tile_num'].isin(bad_tiles)], how='right', on='tile_num')\n",
    "print(tile_matches.shape)\n",
    "\n",
    "tile_matches_duplicates = boreal_tile_index.merge(tindex_master[tindex_master['tile_num'].isin(duplicate_tiles)], how='right', on='tile_num')\n",
    "print(tile_matches_duplicates.shape)\n",
    "\n",
    "tile_matches_geojson_string = tile_matches.to_crs(\"EPSG:4326\").to_json()\n",
    "tile_matches_geojson = json.loads(tile_matches_geojson_string)\n",
    "\n",
    "tile_matches_duplicates_geojson_string = tile_matches_duplicates.to_crs(\"EPSG:4326\").to_json()\n",
    "tile_matches_duplicates_geojson = json.loads(tile_matches_duplicates_geojson_string)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "choice-radius",
   "metadata": {},
   "source": [
    "## Build a MosaicJSON"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "choice-collaboration",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Dict\n",
    "\n",
    "from cogeo_mosaic.mosaic import MosaicJSON\n",
    "from cogeo_mosaic.backends import MosaicBackend\n",
    "\n",
    "def get_accessor(feature: Dict):\n",
    "    \"\"\"Return specific feature identifier.\"\"\"\n",
    "    return feature[\"properties\"][\"s3\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "respective-prompt",
   "metadata": {},
   "outputs": [],
   "source": [
    "out_mosaic_json_fn = 's3://maap-ops-workspace/shared/lduncanson/DPS_tile_lists/ATL08_filt_tindex_master_mosaic.json' \n",
    "\n",
    "mosaicdata = MosaicJSON.from_features(tile_matches_geojson.get('features'), minzoom=6, maxzoom=18, accessor=get_accessor)\n",
    "\n",
    "with MosaicBackend(out_mosaic_json_fn, mosaic_def=mosaicdata) as mosaic:\n",
    "    mosaic.write(overwrite=True)\n",
    "    \n",
    "# URL to give tiler is\n",
    "# s3://maap-ops-workspace/shared/nathanmthomas/Landsat/landsat8_mosaic.json"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "pressed-louisville",
   "metadata": {},
   "source": [
    "## View the Results with Folium"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "quantitative-cologne",
   "metadata": {},
   "outputs": [],
   "source": [
    "from folium import Map, TileLayer, GeoJson, LayerControl, Icon, Marker"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "superior-operations",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'geopandas' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-5868e07543ec>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;31m# Get Vector layers\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0mboreal_geojson\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'/projects/shared-buckets/nathanmthomas/boreal.geojson'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m \u001b[0mboreal\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgeopandas\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_file\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mboreal_geojson\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     12\u001b[0m \u001b[0mecoboreal_geojson\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'/projects/shared-buckets/nathanmthomas/Ecoregions2017_boreal_m.geojson'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0mecoboreal\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgeopandas\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_file\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mecoboreal_geojson\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'geopandas' is not defined"
     ]
    }
   ],
   "source": [
    "# Setup the mosaic tiling\n",
    "tiler_base = \"https://jqsd6bqdsf.execute-api.us-west-2.amazonaws.com/\"\n",
    "tiler_mosaic =  \"\".join([tiler_base, \"mosaicjson/tiles/{z}/{x}/{y}\"])\n",
    "\n",
    "# Get a basemap\n",
    "tiler_basemap_gray = \"http://services.arcgisonline.com/ArcGIS/rest/services/Canvas/World_Light_Gray_Base/MapServer/tile/{z}/{y}/{x}\"\n",
    "tiler_basemap_image = 'https://services.arcgisonline.com/arcgis/rest/services/World_Imagery/MapServer/tile/{z}/{y}/{x}'\n",
    "\n",
    "# Get Vector layers\n",
    "boreal_geojson = '/projects/shared-buckets/nathanmthomas/boreal.geojson' \n",
    "boreal = geopandas.read_file(boreal_geojson)\n",
    "ecoboreal_geojson = '/projects/shared-buckets/nathanmthomas/Ecoregions2017_boreal_m.geojson'\n",
    "ecoboreal = geopandas.read_file(ecoboreal_geojson)\n",
    "\n",
    "# Reproject Vector Layers\n",
    "p1, p2, clat, clon = [50, 70, 40, 160]\n",
    "proj_str_aea = '+proj=aea +lat_1={:.2f} +lat_2={:.2f} +lat_0={:.2f} +lon_0={:.2f}'.format(p1, p2, clat, clon)\n",
    "ecoboreal_aea = ecoboreal.to_crs(proj_str_aea)\n",
    "# Apply a buffer\n",
    "ecoboreal_aea_buf = ecoboreal_aea[\"geometry\"].buffer(1e5)\n",
    "# Go back to GCS\n",
    "ecoboreal_buf = ecoboreal_aea_buf.to_crs(boreal_tile_index.crs)\n",
    "\n",
    "# Style Vector Layers\n",
    "ecoboreal_style = {'fillColor': 'orange', 'color': 'orange'}\n",
    "boreal_style = {'fillColor': 'green', 'color': 'green'}\n",
    "boreal_subset_style = {'fillColor': 'red', 'color': 'red'}\n",
    "\n",
    "# Map the Layers\n",
    "#------------------\n",
    "m1 = Map(\n",
    "    tiles=\"Stamen Terrain\"\n",
    ")\n",
    "\n",
    "#GeoJson(ecoboreal_aea_buf, name=\"Boreal extent from Ecoregions\", style_function=lambda x:ecoboreal_style).add_to(m1)\n",
    "GeoJson(boreal, name=\"Boreal extent\", style_function=lambda x:boreal_style).add_to(m1)\n",
    "\n",
    "bbox_style = {'fillColor': '#ff7f00', 'color': '#ff7f00'}\n",
    "all_tiles = GeoJson(\n",
    "    data=boreal_tile_index.to_crs(\"EPSG:4326\").to_json(),\n",
    "    style_function=lambda x:bbox_style,\n",
    "    name=\"Boreal tiles\"\n",
    ").add_to(m1)\n",
    "\n",
    "atl08_style = {'fillColor': '#377eb8', 'color': '#377eb8'}\n",
    "atl08_dup_style = {'fillColor': 'red', 'color': 'red'}\n",
    "\n",
    "atl08_geojson = GeoJson(\n",
    "        data=tile_matches_geojson,\n",
    "        style_function=lambda x:atl08_style,\n",
    "        name=\"ATL08-filt DPS subset of Boreal tiles\"\n",
    "    ).add_to(m1)\n",
    "\n",
    "atl08_duplicates_geojson = GeoJson(\n",
    "        data=tile_matches_duplicates_geojson,\n",
    "        style_function=lambda x:atl08_dup_style,\n",
    "        name=\"Duplicates: ATL08-filt DPS subset of Boreal tiles\"\n",
    "    ).add_to(m1)\n",
    "if True:\n",
    "    \n",
    "    basemap_gray = TileLayer(\n",
    "        tiles=tiler_basemap_gray,\n",
    "        opacity=1,\n",
    "        name=\"World gray basemap\",\n",
    "        attr=\"MAAP\",\n",
    "        overlay=True\n",
    "    )\n",
    "    basemap_image = TileLayer(\n",
    "        tiles=tiler_basemap_image,\n",
    "        opacity=1,\n",
    "        name=\"Image basemap\",\n",
    "        attr=\"MAAP\",\n",
    "        overlay=True\n",
    "    )\n",
    "    landsat_tiles = f\"{tiler_mosaic}?url=s3://maap-ops-workspace/shared/nathanmthomas/DPS_tile_lists/Landsat_mosaic.json&rescale=0.01,0.5&bidx=6&colormap_name=viridis\"\n",
    "    landsat_tiles_layer = TileLayer(\n",
    "        tiles=landsat_tiles,\n",
    "        opacity=1,\n",
    "        name=\"landsat covars\",\n",
    "        attr=\"MAAP\",\n",
    "        overlay=True\n",
    "    )\n",
    "    topo_tiles = f\"{tiler_mosaic}?url=s3://maap-ops-workspace/shared/nathanmthomas/DPS_tile_lists/Topo_mosaic.json&rescale=0,1&bidx=3&colormap_name=bone\"\n",
    "    topo_tiles_layer = TileLayer(\n",
    "        tiles=topo_tiles,\n",
    "        opacity=1,\n",
    "        name=\"topo covars\",\n",
    "        attr=\"MAAP\",\n",
    "        overlay=True\n",
    "    )\n",
    "    basemap_gray.add_to(m1)\n",
    "    basemap_image.add_to(m1)\n",
    "    landsat_tiles_layer.add_to(m1)\n",
    "    topo_tiles_layer.add_to(m1)\n",
    "\n",
    "LayerControl().add_to(m1)\n",
    "\n",
    "m1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "engaging-rubber",
   "metadata": {},
   "source": [
    "# Tests for getting neighbor tiles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "adaptive-editing",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'geopandas.geodataframe.GeoDataFrame'>\n",
      "RangeIndex: 4557 entries, 0 to 4556\n",
      "Data columns (total 2 columns):\n",
      " #   Column    Non-Null Count  Dtype   \n",
      "---  ------    --------------  -----   \n",
      " 0   tile_num  4557 non-null   int64   \n",
      " 1   geometry  4557 non-null   geometry\n",
      "dtypes: geometry(1), int64(1)\n",
      "memory usage: 71.3 KB\n"
     ]
    }
   ],
   "source": [
    "boreal_tile_index_path = '/projects/shared-buckets/nathanmthomas/boreal_grid_albers90k_gpkg.gpkg'\n",
    "boreal_tile_index = geopandas.read_file(boreal_tile_index_path)\n",
    "boreal_tile_index.rename(columns={\"layer\":\"tile_num\"}, inplace=True)\n",
    "boreal_tile_index[\"tile_num\"] = boreal_tile_index[\"tile_num\"].astype(int)\n",
    "boreal_tile_index.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "discrete-belize",
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "unexpected EOF while parsing (<ipython-input-111-6418f5cf4f7f>, line 49)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-111-6418f5cf4f7f>\"\u001b[0;36m, line \u001b[0;32m49\u001b[0m\n\u001b[0;31m    return url.replace(f'/projects/my-{type}-bucket', replacement_str\u001b[0m\n\u001b[0m                                                                     ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m unexpected EOF while parsing\n"
     ]
    }
   ],
   "source": [
    "# add NEIGHBORS column\n",
    "#https://gis.stackexchange.com/questions/281652/finding-all-neighbors-using-geopandas/281676#281676\n",
    "\n",
    "def get_neighbors(input_gdf, input_id_field, input_id):\n",
    "    for index, feature in input_gdf.iterrows():   \n",
    "        if feature[input_id_field] == input_id:\n",
    "            #print(tile.tile_num)\n",
    "            # get 'not disjoint' countries\n",
    "            neighbors = input_gdf[~input_gdf.geometry.disjoint(feature.geometry)][input_id_field].tolist()\n",
    "            #print(feature.tile_num)\n",
    "            # remove own name of the country from the list\n",
    "            neighbors = [ fid for fid in neighbors if feature[input_id_field] != fid ]\n",
    "            #print(neighbors)\n",
    "\n",
    "            # add names of neighbors as NEIGHBORS value\n",
    "            #boreal_tile_index.at[index, \"NEIGHBORS\"] = \", \".join(neighbors)\n",
    "            if False:\n",
    "                # This will put the neighbors list into a field in the subset df\n",
    "                # https://stackoverflow.com/questions/57348503/how-do-you-store-a-tuple-in-a-geopandas-geodataframe\n",
    "                subset_df = input_gdf.loc[input_gdf[input_id_field] == input_id]\n",
    "                subset_df[\"NEIGHBORS\"] = None\n",
    "                subset_df['NEIGHBORS'] = subset_df.apply(lambda row: (neighbors), axis=1)\n",
    "\n",
    "    \n",
    "    return neighbors\n",
    "\n",
    "def local_to_s3(url, user = 'nathanmthomas', type='public'):\n",
    "    ''' A Function to convert local paths to s3 urls'''\n",
    "    if type is 'public':\n",
    "        replacement_str = f's3://maap-ops-workspace/shared/{user}'\n",
    "    else:\n",
    "        replacement_str = f's3://maap-ops-workspace/{user}'\n",
    "    return url.replace(f'/projects/my-{type}-bucket', replacement_str"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "packed-switzerland",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/projects/.local/lib/python3.7/site-packages/geopandas/geodataframe.py:1322: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  super(GeoDataFrame, self).__setitem__(key, value)\n"
     ]
    }
   ],
   "source": [
    "input_gdf = boreal_tile_index\n",
    "input_id_field = 'tile_num'\n",
    "input_id = 2130\n",
    "neighbor_tile_ids = get_neighbors(input_gdf, input_id_field, input_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "id": "eleven-friday",
   "metadata": {},
   "outputs": [],
   "source": [
    "ATL08_filt_tindex_master =   pd.read_csv('s3://maap-ops-workspace/shared/lduncanson/DPS_tile_lists/ATL08_filt_tindex_master.csv')\n",
    "ATL08_filt_tindex_master['s3'] = [local_to_s3(local_path, user='lduncanson', type = 'private') for local_path in ATL08_filt_tindex_master['local_path']]\n",
    "ATL08_filt_csv_s3_fn_list = [ATL08_filt_tindex_master['s3'].loc[ATL08_filt_tindex_master.tile_num == tile_id].tolist()[0] for tile_id in neighbor_tile_ids]\n",
    "#ATL08_filt_tindex_master['s3'].loc[ATL08_filt_tindex_master.tile_num == neighbor_tile_ids[2]]#  .tolist()\n",
    "ATL08_filt_csv_s3_fn_list\n",
    "atl08 = pd.concat([pd.read_csv(f) for f in ATL08_filt_csv_s3_fn_list ], sort=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "id": "structured-nerve",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'atl08_004_30m_filt_merge_neighbors_2130.csv'"
      ]
     },
     "execution_count": 136,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "focal_csv_fn = ATL08_filt_tindex_master['s3'].loc[ATL08_filt_tindex_master.tile_num == input_id].tolist()[0]\n",
    "\"atl08_004_30m_filt_merge_neighbors_\"+str(f'{input_id:04}.csv')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
