{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "younger-solomon",
   "metadata": {},
   "outputs": [],
   "source": [
    "from maap.maap import MAAP\n",
    "maap = MAAP(maap_host='api.ops.maap-project.org')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "corresponding-fifty",
   "metadata": {},
   "source": [
    "# Launch DPS for tile_atl08.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "sweet-terrorist",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import geopandas\n",
    "import pandas as pd\n",
    "import glob\n",
    "import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "oriental-thesaurus",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_stack_fn(stack_list_fn, in_tile_num):\n",
    "    # Find most recent topo/Landsat stack path for tile in list of stack paths from *tindex_master.csv\n",
    "    all_stacks_df = pd.read_csv(stack_list_fn)\n",
    "    stack_for_tile = all_stacks_df[all_stacks_df['location'].str.contains(\"_\"+str(in_tile_num))]\n",
    "    [print(i) for i in stack_for_tile.path.to_list()]\n",
    "    stack_for_tile_fn = stack_for_tile.path.to_list()[0]\n",
    "    if len(stack_for_tile)==0:\n",
    "        stack_for_tile_fn = None\n",
    "    return(stack_for_tile_fn)\n",
    "\n",
    "# nmt added: code that returns df of landsat locations and tile number\n",
    "# This is basically CountOutput.py\n",
    "def get_stack_df(dps_dir, TYPE, dps_year):\n",
    "    \n",
    "    if \"Landsat\" in TYPE:\n",
    "        root = f\"/projects/my-private-bucket/dps_output/do_landsat_stack_3-1-2_ubuntu/ops/{dps_year}/\"\n",
    "        ends_with_str = \"_dps.tif\"\n",
    "    if \"Topo\" in TYPE:\n",
    "        root = f\"/projects/my-private-bucket/dps_output/do_topo_stack_3-1-5_ubuntu/ops/{dps_year}/\"\n",
    "        ends_with_str = \"_stack.tif\"\n",
    "    if \"ATL08\" in TYPE:\n",
    "        root = f\"/projects/my-private-bucket/dps_output/run_extract_ubuntu/ops/{dps_year}/\"\n",
    "        ends_with_str = \"0m.csv\"\n",
    "            \n",
    "    df = pd.DataFrame(columns=['location', 'tile_num'])\n",
    "\n",
    "    for dir, subdir, files in os.walk(root):\n",
    "        for fname in files:\n",
    "            if fname.endswith(ends_with_str): \n",
    "                 \n",
    "                tile_num = fname.split('_')[1]\n",
    "                   \n",
    "                if \"ATL08\" in TYPE:\n",
    "                    df = df.append({'location':os.path.join(dir+\"/\", fname)},ignore_index=True)\n",
    "                else:\n",
    "                    df = df.append({'location':os.path.join(dir+\"/\", fname), 'tile_num':tile_num},ignore_index=True)\n",
    "        \n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "unavailable-database",
   "metadata": {},
   "source": [
    "#### Set the names of the data frames to create"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "certified-algebra",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Topo and Landsat tindex_master csvs from build_tindex_master.py\n",
    "topo_tindex = \"/projects/my-public-bucket/DPS_tile_lists/Topo_tindex_master.csv\"\n",
    "landsat_tindex = \"/projects/my-public-bucket/DPS_tile_lists/Landsat_tindex_master.csv\"\n",
    "\n",
    "# Model-ready subset of tiles for which Topo and Landsat coincide\n",
    "model_ready_tiles_topo = \"/projects/my-public-bucket/DPS_tile_lists/model_ready_tiles_topo_paths.csv\"\n",
    "model_ready_tiles_landsat = \"/projects/my-public-bucket/DPS_tile_lists/model_ready_tiles_landsat_paths.csv\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "upset-oxygen",
   "metadata": {},
   "source": [
    "## Make the data frames from build_tindex_master.py csvs for Topo and Landsat tiles\n",
    "python lib/build_tindex_master.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "restricted-accordance",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading existing...\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>local_path</th>\n",
       "      <th>tile_num</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>/projects/my-private-bucket/dps_output/do_topo...</td>\n",
       "      <td>421</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>/projects/my-private-bucket/dps_output/do_topo...</td>\n",
       "      <td>455</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>/projects/my-private-bucket/dps_output/do_topo...</td>\n",
       "      <td>456</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>/projects/my-private-bucket/dps_output/do_topo...</td>\n",
       "      <td>491</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>/projects/my-private-bucket/dps_output/do_topo...</td>\n",
       "      <td>492</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0                                         local_path  tile_num\n",
       "0           0  /projects/my-private-bucket/dps_output/do_topo...       421\n",
       "1           1  /projects/my-private-bucket/dps_output/do_topo...       455\n",
       "2           2  /projects/my-private-bucket/dps_output/do_topo...       456\n",
       "3           3  /projects/my-private-bucket/dps_output/do_topo...       491\n",
       "4           4  /projects/my-private-bucket/dps_output/do_topo...       492"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "if os.path.isfile(landsat_tindex) and os.path.isfile(topo_tindex):\n",
    "    print('Reading existing...')\n",
    "    ls8_df = pd.read_csv(landsat_tindex)\n",
    "    topo_df = pd.read_csv(topo_tindex)\n",
    "else:\n",
    "    s3_stem = 'https://s3.console.aws.amazon.com/s3/buckets/maap-ops-workspace/nathanmthomas'\n",
    "    local_stem = '/projects/my-private-bucket'\n",
    "\n",
    "    ls8_root =  s3_stem + '/dps_output/do_landsat_stack_3-1-2_ubuntu'\n",
    "    topo_root = s3_stem + '/dps_output/do_topo_stack_3-1-5_ubuntu'\n",
    "    \n",
    "    ls8_df = get_stack_df(ls8_root, \"Landsat\")\n",
    "    topo_df = get_stack_df(topo_root, \"Topo\")\n",
    "topo_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "middle-azerbaijan",
   "metadata": {},
   "source": [
    "## Get tile ids for which both Topo and Landsat stacks exist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "handed-dress",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                          local_path tile_num\n",
      "0  /projects/my-private-bucket/dps_output/do_land...      986\n",
      "1  /projects/my-private-bucket/dps_output/do_land...      987\n",
      "2  /projects/my-private-bucket/dps_output/do_land...      979\n",
      "3  /projects/my-private-bucket/dps_output/do_land...      984\n",
      "4  /projects/my-private-bucket/dps_output/do_land...      982\n",
      "                                          local_path tile_num\n",
      "0  /projects/my-private-bucket/dps_output/do_topo...      986\n",
      "1  /projects/my-private-bucket/dps_output/do_topo...      987\n",
      "2  /projects/my-private-bucket/dps_output/do_topo...      979\n",
      "3  /projects/my-private-bucket/dps_output/do_topo...      984\n",
      "4  /projects/my-private-bucket/dps_output/do_topo...      982\n",
      "4465 4465\n"
     ]
    }
   ],
   "source": [
    "# added by nmt: get filenames of co-incident landsat and topo\n",
    "\n",
    "topo_sub_df = pd.DataFrame(columns=['local_path','tile_num'])\n",
    "ls8_sub_df = pd.DataFrame(columns=['local_path','tile_num'])\n",
    "\n",
    "for i in range(len(ls8_df['tile_num'])):\n",
    "    ls_tile_num = ls8_df['tile_num'][i]\n",
    "    for j in range(len(topo_df['tile_num'])):\n",
    "        topo_tile_num = topo_df['tile_num'][j]\n",
    "        if ls_tile_num == topo_tile_num:\n",
    "            # Only need to choose one, but we'll do 2 and then check\n",
    "            ls8_sub_df = ls8_sub_df.append({'local_path':ls8_df['local_path'][i],'tile_num':ls8_df['tile_num'][i].astype(int)}, ignore_index=True)\n",
    "            topo_sub_df = topo_sub_df.append({'local_path':topo_df['local_path'][j],'tile_num':topo_df['tile_num'][j].astype(int)}, ignore_index=True)\n",
    "\n",
    "#ls8_sub_df['tile_num'] = ls8_sub_df['tile_num'].astype(float, errors = 'raise')\n",
    "print(ls8_sub_df.head())\n",
    "print(topo_sub_df.head())\n",
    "print(len(ls8_sub_df),len(topo_sub_df))\n",
    "\n",
    "topo_sub_df.to_csv( model_ready_tiles_topo, index=False, encoding='utf-8-sig')\n",
    "ls8_sub_df.to_csv( model_ready_tiles_landsat, index=False, encoding='utf-8-sig')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "quality-console",
   "metadata": {},
   "source": [
    "#### Now you have a set of tile ids for which both Landsat and Topo stacks exist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "natural-termination",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4465"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "topo_sub_df = pd.read_csv(\"/projects/my-public-bucket/DPS_tile_lists/model_ready_tiles_topo_paths.csv\")\n",
    "INPUT_TILE_NUM_LIST = topo_sub_df['tile_num'].values.astype(int).tolist()\n",
    "len(INPUT_TILE_NUM_LIST)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "worst-scratch",
   "metadata": {},
   "source": [
    "##### Test: get a subset of tile ids for Norway tiles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "incorporated-amino",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "123"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "INPUT_TILE_NUM_LIST_NORWAY = pd.read_csv('/projects/my-public-bucket/misc_files/norway_tiles.csv').layer.tolist()\n",
    "len(INPUT_TILE_NUM_LIST_NORWAY)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "electoral-thesaurus",
   "metadata": {},
   "source": [
    "#### Read in the latest tindex and compare with a previous set of completed tiles to see which ones still need to be run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "vietnamese-makeup",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tiles completed: 106\n",
      "Tiles missing: 4325\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "4325"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "tiles_completed = pd.read_csv('/projects/my-public-bucket/DPS_tile_lists/ATL08_filt_tindex_master.csv')\n",
    "print(f'Tiles completed: {len(tiles_completed)}')\n",
    "tile_nums_missing = np.setdiff1d(INPUT_TILE_NUM_LIST, tiles_completed.tile_num)\n",
    "print(f'Tiles missing: {len(tile_nums_missing)}')\n",
    "INPUT_TILE_NUM_LIST = tile_nums_missing.tolist()\n",
    "len(INPUT_TILE_NUM_LIST)\n",
    "#print(INPUT_TILE_NUM_LIST)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "small-channels",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5921"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tindex_master_fn = f'/projects/shared-buckets/lduncanson/DPS_tile_lists/ATL08_tindex_master.csv'\n",
    "tiles = pd.read_csv(tindex_master_fn)\n",
    "len(tiles)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "id": "underlying-reporter",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[131, 132]\n"
     ]
    }
   ],
   "source": [
    "TEST_DPS  = True\n",
    "\n",
    "if TEST_DPS:\n",
    "    DPS_INPUT_TILE_NUM_LIST = INPUT_TILE_NUM_LIST_NORWAY #INPUT_TILE_NUM_LIST[-10:]\n",
    "    DPS_INPUT_TILE_NUM_LIST = DPS_INPUT_TILE_NUM_LIST[0:2]\n",
    "else:\n",
    "    DPS_INPUT_TILE_NUM_LIST = INPUT_TILE_NUM_LIST\n",
    "    \n",
    "print(DPS_INPUT_TILE_NUM_LIST)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "central-intervention",
   "metadata": {},
   "source": [
    "#### Customize the DPS run: set up the parameters dictionary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "id": "raised-shakespeare",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Norway test 01\n",
    "# Just include sol_el so we can use sol_el < 5\n",
    "in_param_dict_norway01 = {\n",
    "                        'in_tile_num': '',\n",
    "                        'in_tile_fn': 'https://maap-ops-workspace.s3.amazonaws.com/shared/nathanmthomas/boreal_tiles_v002.gpkg',\n",
    "                        'in_tile_layer': 'boreal_tiles_v002',\n",
    "                        'csv_list_fn': 's3://maap-ops-workspace/shared/lduncanson/DPS_tile_lists/ATL08_tindex_master.csv',\n",
    "                        'topo_stack_list_fn': 's3://maap-ops-workspace/shared/nathanmthomas/DPS_tile_lists/Topo_tindex_master.csv',\n",
    "                        'landsat_stack_list_fn': 's3://maap-ops-workspace/shared/nathanmthomas/DPS_tile_lists/Landsat_tindex_master.csv',\n",
    "                        'years_list': '2019 2020 2021',\n",
    "                        'user_stacks': 'nathanmthomas',\n",
    "                        'user_atl08': 'lduncanson',\n",
    "                        'thresh_sol_el': 5,\n",
    "                        'v_ATL08': 4,\n",
    "                        'minmonth': 6,\n",
    "                        'maxmonth': 9\n",
    "    }\n",
    "# Norway test 02\n",
    "# Use v005 ATL08, which will apply lc-based thresholds, extend to all months\n",
    "# NOTE!! make sure you manually update to use the correct filter in tile_atl08.py\n",
    "in_param_dict_norway02 = {\n",
    "                        'in_tile_num': '',\n",
    "                        'in_tile_fn': 'https://maap-ops-workspace.s3.amazonaws.com/shared/nathanmthomas/boreal_tiles_v002.gpkg',\n",
    "                        'in_tile_layer': 'boreal_tiles_v002',\n",
    "                        'csv_list_fn': 's3://maap-ops-workspace/shared/lduncanson/DPS_tile_lists/ATL08_tindex_master.csv',\n",
    "                        'topo_stack_list_fn': 's3://maap-ops-workspace/shared/nathanmthomas/DPS_tile_lists/Topo_tindex_master.csv',\n",
    "                        'landsat_stack_list_fn': 's3://maap-ops-workspace/shared/nathanmthomas/DPS_tile_lists/Landsat_tindex_master.csv',\n",
    "                        'years_list': '2019 2020 2021',\n",
    "                        'user_stacks': 'nathanmthomas',\n",
    "                        'user_atl08': 'lduncanson',\n",
    "                        'thresh_sol_el': 5,\n",
    "                        'v_ATL08': 5,\n",
    "                        'minmonth': 1,\n",
    "                        'maxmonth': 12\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "id": "referenced-philadelphia",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'in_tile_num': '',\n",
       " 'in_tile_fn': 'https://maap-ops-workspace.s3.amazonaws.com/shared/nathanmthomas/boreal_tiles_v002.gpkg',\n",
       " 'in_tile_layer': 'boreal_tiles_v002',\n",
       " 'csv_list_fn': 's3://maap-ops-workspace/shared/lduncanson/DPS_tile_lists/ATL08_tindex_master.csv',\n",
       " 'topo_stack_list_fn': 's3://maap-ops-workspace/shared/nathanmthomas/DPS_tile_lists/Topo_tindex_master.csv',\n",
       " 'landsat_stack_list_fn': 's3://maap-ops-workspace/shared/nathanmthomas/DPS_tile_lists/Landsat_tindex_master.csv',\n",
       " 'years_list': '2019 2020 2021',\n",
       " 'user_stacks': 'nathanmthomas',\n",
       " 'user_atl08': 'lduncanson',\n",
       " 'thresh_sol_el': 5,\n",
       " 'v_ATL08': 4,\n",
       " 'minmonth': 6,\n",
       " 'maxmonth': 9}"
      ]
     },
     "execution_count": 138,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "in_param_dict = in_param_dict_norway01\n",
    "in_param_dict"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "acoustic-savannah",
   "metadata": {},
   "source": [
    "## Run a DPS job across the list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "id": "parliamentary-offense",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# of input tiles for DPS: 2\n",
      "job info: {'status': 'success', 'http_status_code': 200, 'job_id': '45f2b9d5-6440-488d-8979-f06b3ee1a150', 'dps_num': 1, 'tile_num': 131, 'submit_time': datetime.datetime(2022, 3, 2, 14, 44, 20, 384543), 'dbs_job_hour': 14, 'algo_id': 'run_tile_atl08_ubuntu', 'user': 'lduncanson', 'worker_type': 'maap-dps-worker-8gb'}\n",
      "job info: {'status': 'success', 'http_status_code': 200, 'job_id': 'eaa99e87-8955-4d8a-9353-60b88a86f3d4', 'dps_num': 2, 'tile_num': 132, 'submit_time': datetime.datetime(2022, 3, 2, 14, 44, 20, 469383), 'dbs_job_hour': 14, 'algo_id': 'run_tile_atl08_ubuntu', 'user': 'lduncanson', 'worker_type': 'maap-dps-worker-8gb'}\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>status</th>\n",
       "      <th>http_status_code</th>\n",
       "      <th>job_id</th>\n",
       "      <th>dps_num</th>\n",
       "      <th>tile_num</th>\n",
       "      <th>submit_time</th>\n",
       "      <th>dbs_job_hour</th>\n",
       "      <th>algo_id</th>\n",
       "      <th>user</th>\n",
       "      <th>worker_type</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>success</td>\n",
       "      <td>200</td>\n",
       "      <td>45f2b9d5-6440-488d-8979-f06b3ee1a150</td>\n",
       "      <td>1</td>\n",
       "      <td>131</td>\n",
       "      <td>2022-03-02 14:44:20.384543</td>\n",
       "      <td>14</td>\n",
       "      <td>run_tile_atl08_ubuntu</td>\n",
       "      <td>lduncanson</td>\n",
       "      <td>maap-dps-worker-8gb</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>success</td>\n",
       "      <td>200</td>\n",
       "      <td>eaa99e87-8955-4d8a-9353-60b88a86f3d4</td>\n",
       "      <td>2</td>\n",
       "      <td>132</td>\n",
       "      <td>2022-03-02 14:44:20.469383</td>\n",
       "      <td>14</td>\n",
       "      <td>run_tile_atl08_ubuntu</td>\n",
       "      <td>lduncanson</td>\n",
       "      <td>maap-dps-worker-8gb</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    status  http_status_code                                job_id  dps_num  \\\n",
       "0  success               200  45f2b9d5-6440-488d-8979-f06b3ee1a150        1   \n",
       "0  success               200  eaa99e87-8955-4d8a-9353-60b88a86f3d4        2   \n",
       "\n",
       "   tile_num                submit_time  dbs_job_hour                algo_id  \\\n",
       "0       131 2022-03-02 14:44:20.384543            14  run_tile_atl08_ubuntu   \n",
       "0       132 2022-03-02 14:44:20.469383            14  run_tile_atl08_ubuntu   \n",
       "\n",
       "         user          worker_type  \n",
       "0  lduncanson  maap-dps-worker-8gb  \n",
       "0  lduncanson  maap-dps-worker-8gb  "
      ]
     },
     "execution_count": 139,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "job_results_list = []\n",
    "\n",
    "print(f\"# of input tiles for DPS: {len(DPS_INPUT_TILE_NUM_LIST)}\")\n",
    "for i, INPUT_TILE_NUM in enumerate(DPS_INPUT_TILE_NUM_LIST):\n",
    "\n",
    "    DPS_num = i+1\n",
    "    IDENTIFIER = 'run_tile_atl08'\n",
    "    ALGO_ID = f'{IDENTIFIER}_ubuntu'\n",
    "    USER = 'lduncanson'\n",
    "    WORKER_TYPE = 'maap-dps-worker-8gb'\n",
    "    \n",
    "    in_param_dict['in_tile_num'] = INPUT_TILE_NUM\n",
    "    \n",
    "    submit_result = maap.submitJob(\n",
    "            identifier=IDENTIFIER,\n",
    "            algo_id=ALGO_ID,\n",
    "            version='master',\n",
    "            username=USER, # username needs to be the same as whoever created the workspace\n",
    "            queue=WORKER_TYPE,\n",
    "            **in_param_dict\n",
    "        )\n",
    "    \n",
    "    # Build a dataframe of submission details\n",
    "    submit_result['dps_num'] = DPS_num\n",
    "    submit_result['tile_num'] = INPUT_TILE_NUM\n",
    "    submit_result['submit_time'] = datetime.datetime.now()\n",
    "    submit_result['dbs_job_hour'] =datetime.datetime.now().hour\n",
    "    submit_result['algo_id'] = ALGO_ID\n",
    "    submit_result['user'] = USER\n",
    "    submit_result['worker_type'] = WORKER_TYPE\n",
    "    job_results_list.append(pd.DataFrame([submit_result]))\n",
    "    \n",
    "    if DPS_num in [1, 100, 500, 1000, 3000, len(DPS_INPUT_TILE_NUM_LIST)]:\n",
    "        #print(f\"DPS run #: {DPS_num} | tile num: {INPUT_TILE_NUM} | job info: {submit_result}\") \n",
    "        print(f\"job info: {submit_result}\") \n",
    "    \n",
    "job_results_df = pd.concat(job_results_list)\n",
    "job_results_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "accredited-association",
   "metadata": {},
   "source": [
    "#### Quick check of a deep DPS dir to see what was returned from the run above"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "id": "incredible-baptist",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The data frame show you submitted 2 jobs. Check the returned results to see if the total returned = total submitted...\n",
      "For DPS job that returned results in hour 1, # tiles that ran: 0\n",
      "For DPS job that returned results in hour 2, # tiles that ran: 0\n",
      "For DPS job that returned results in hour 3, # tiles that ran: 0\n",
      "For DPS job that returned results in hour 4, # tiles that ran: 0\n",
      "For DPS job that returned results in hour 5, # tiles that ran: 0\n",
      "For DPS job that returned results in hour 6, # tiles that ran: 0\n",
      "For DPS job that returned results in hour 7, # tiles that ran: 0\n",
      "For DPS job that returned results in hour 8, # tiles that ran: 0\n",
      "For DPS job that returned results in hour 9, # tiles that ran: 0\n",
      "For DPS job that returned results in hour 10, # tiles that ran: 0\n",
      "For DPS job that returned results in hour 11, # tiles that ran: 0\n",
      "For DPS job that returned results in hour 12, # tiles that ran: 0\n",
      "For DPS job that returned results in hour 13, # tiles that ran: 0\n",
      "For DPS job that returned results in hour 14, # tiles that ran: 0\n",
      "For DPS job that returned results in hour 15, # tiles that ran: 0\n",
      "For DPS job that returned results in hour 16, # tiles that ran: 0\n",
      "For DPS job that returned results in hour 17, # tiles that ran: 0\n",
      "For DPS job that returned results in hour 18, # tiles that ran: 0\n",
      "For DPS job that returned results in hour 19, # tiles that ran: 0\n",
      "For DPS job that returned results in hour 20, # tiles that ran: 0\n",
      "For DPS job that returned results in hour 21, # tiles that ran: 0\n",
      "For DPS job that returned results in hour 22, # tiles that ran: 0\n",
      "For DPS job that returned results in hour 23, # tiles that ran: 0\n",
      "For DPS job that returned results in hour 24, # tiles that ran: 0\n"
     ]
    }
   ],
   "source": [
    "print(f\"The data frame show you submitted {len(job_results_df)} jobs. Check the returned results to see if the total returned = total submitted...\")\n",
    "for JOB_HOUR in range(1,25):\n",
    "    returned_results_list = glob.glob(f\"/projects/my-private-bucket/dps_output/run_tile_atl08_ubuntu/master/2022/03/02/{JOB_HOUR}/**/_stdout.txt\", recursive=True)\n",
    "    print(f\"For DPS job that returned results in hour {JOB_HOUR}, # tiles that ran: {len(returned_results_list)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "id": "every-iraqi",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<Response [200]>\n"
     ]
    }
   ],
   "source": [
    "print(maap.getJobStatus('0d0deab8-27bc-481a-81e5-301a3bc6b72f'))\n",
    "#maap.listJobs(username='lduncanson')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "genetic-venue",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "need_df_fn = pd.read_csv(\"/projects/my-public-bucket/DPS_tile_lists/Need_ATL08_filt_tindex_master.csv\")\n",
    "INPUT_TILE_NUM_LIST = need_df_fn['tile_num'].values.astype(int).tolist()\n",
    "len(INPUT_TILE_NUM_LIST)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "public-public",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div style=\"width:100%;\"><div style=\"position:relative;width:100%;height:0;padding-bottom:60%;\"><span style=\"color:#565656\">Make this Notebook Trusted to load map: File -> Trust Notebook</span><iframe src=\"about:blank\" style=\"position:absolute;width:100%;height:100%;left:0;top:0;border:none !important;\" data-html=%3C%21DOCTYPE%20html%3E%0A%3Chead%3E%20%20%20%20%0A%20%20%20%20%3Cmeta%20http-equiv%3D%22content-type%22%20content%3D%22text/html%3B%20charset%3DUTF-8%22%20/%3E%0A%20%20%20%20%0A%20%20%20%20%20%20%20%20%3Cscript%3E%0A%20%20%20%20%20%20%20%20%20%20%20%20L_NO_TOUCH%20%3D%20false%3B%0A%20%20%20%20%20%20%20%20%20%20%20%20L_DISABLE_3D%20%3D%20false%3B%0A%20%20%20%20%20%20%20%20%3C/script%3E%0A%20%20%20%20%0A%20%20%20%20%3Cstyle%3Ehtml%2C%20body%20%7Bwidth%3A%20100%25%3Bheight%3A%20100%25%3Bmargin%3A%200%3Bpadding%3A%200%3B%7D%3C/style%3E%0A%20%20%20%20%3Cstyle%3E%23map%20%7Bposition%3Aabsolute%3Btop%3A0%3Bbottom%3A0%3Bright%3A0%3Bleft%3A0%3B%7D%3C/style%3E%0A%20%20%20%20%3Cscript%20src%3D%22https%3A//cdn.jsdelivr.net/npm/leaflet%401.6.0/dist/leaflet.js%22%3E%3C/script%3E%0A%20%20%20%20%3Cscript%20src%3D%22https%3A//code.jquery.com/jquery-1.12.4.min.js%22%3E%3C/script%3E%0A%20%20%20%20%3Cscript%20src%3D%22https%3A//maxcdn.bootstrapcdn.com/bootstrap/3.2.0/js/bootstrap.min.js%22%3E%3C/script%3E%0A%20%20%20%20%3Cscript%20src%3D%22https%3A//cdnjs.cloudflare.com/ajax/libs/Leaflet.awesome-markers/2.0.2/leaflet.awesome-markers.js%22%3E%3C/script%3E%0A%20%20%20%20%3Clink%20rel%3D%22stylesheet%22%20href%3D%22https%3A//cdn.jsdelivr.net/npm/leaflet%401.6.0/dist/leaflet.css%22/%3E%0A%20%20%20%20%3Clink%20rel%3D%22stylesheet%22%20href%3D%22https%3A//maxcdn.bootstrapcdn.com/bootstrap/3.2.0/css/bootstrap.min.css%22/%3E%0A%20%20%20%20%3Clink%20rel%3D%22stylesheet%22%20href%3D%22https%3A//maxcdn.bootstrapcdn.com/bootstrap/3.2.0/css/bootstrap-theme.min.css%22/%3E%0A%20%20%20%20%3Clink%20rel%3D%22stylesheet%22%20href%3D%22https%3A//maxcdn.bootstrapcdn.com/font-awesome/4.6.3/css/font-awesome.min.css%22/%3E%0A%20%20%20%20%3Clink%20rel%3D%22stylesheet%22%20href%3D%22https%3A//cdnjs.cloudflare.com/ajax/libs/Leaflet.awesome-markers/2.0.2/leaflet.awesome-markers.css%22/%3E%0A%20%20%20%20%3Clink%20rel%3D%22stylesheet%22%20href%3D%22https%3A//cdn.jsdelivr.net/gh/python-visualization/folium/folium/templates/leaflet.awesome.rotate.min.css%22/%3E%0A%20%20%20%20%0A%20%20%20%20%20%20%20%20%20%20%20%20%3Cmeta%20name%3D%22viewport%22%20content%3D%22width%3Ddevice-width%2C%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20initial-scale%3D1.0%2C%20maximum-scale%3D1.0%2C%20user-scalable%3Dno%22%20/%3E%0A%20%20%20%20%20%20%20%20%20%20%20%20%3Cstyle%3E%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%23map_a59229428b57420ca402277806cd2cfc%20%7B%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20position%3A%20relative%3B%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20width%3A%20100.0%25%3B%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20height%3A%20100.0%25%3B%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20left%3A%200.0%25%3B%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20top%3A%200.0%25%3B%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%7D%0A%20%20%20%20%20%20%20%20%20%20%20%20%3C/style%3E%0A%20%20%20%20%20%20%20%20%0A%20%20%20%20%3Cscript%20src%3D%22https%3A//unpkg.com/leaflet-control-geocoder/dist/Control.Geocoder.js%22%3E%3C/script%3E%0A%20%20%20%20%3Clink%20rel%3D%22stylesheet%22%20href%3D%22https%3A//unpkg.com/leaflet-control-geocoder/dist/Control.Geocoder.css%22/%3E%0A%3C/head%3E%0A%3Cbody%3E%20%20%20%20%0A%20%20%20%20%0A%20%20%20%20%20%20%20%20%20%20%20%20%3Cdiv%20class%3D%22folium-map%22%20id%3D%22map_a59229428b57420ca402277806cd2cfc%22%20%3E%3C/div%3E%0A%20%20%20%20%20%20%20%20%0A%3C/body%3E%0A%3Cscript%3E%20%20%20%20%0A%20%20%20%20%0A%20%20%20%20%20%20%20%20%20%20%20%20var%20map_a59229428b57420ca402277806cd2cfc%20%3D%20L.map%28%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%22map_a59229428b57420ca402277806cd2cfc%22%2C%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%7B%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20center%3A%20%5B0%2C%200%5D%2C%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20crs%3A%20L.CRS.EPSG3857%2C%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20zoom%3A%201%2C%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20zoomControl%3A%20true%2C%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20preferCanvas%3A%20false%2C%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%7D%0A%20%20%20%20%20%20%20%20%20%20%20%20%29%3B%0A%0A%20%20%20%20%20%20%20%20%20%20%20%20%0A%0A%20%20%20%20%20%20%20%20%0A%20%20%20%20%0A%20%20%20%20%20%20%20%20%20%20%20%20var%20tile_layer_71e248959df746bb83d7788dd024be3e%20%3D%20L.tileLayer%28%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%22https%3A//%7Bs%7D.tile.openstreetmap.org/%7Bz%7D/%7Bx%7D/%7By%7D.png%22%2C%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%7B%22attribution%22%3A%20%22Data%20by%20%5Cu0026copy%3B%20%5Cu003ca%20href%3D%5C%22http%3A//openstreetmap.org%5C%22%5Cu003eOpenStreetMap%5Cu003c/a%5Cu003e%2C%20under%20%5Cu003ca%20href%3D%5C%22http%3A//www.openstreetmap.org/copyright%5C%22%5Cu003eODbL%5Cu003c/a%5Cu003e.%22%2C%20%22detectRetina%22%3A%20false%2C%20%22maxNativeZoom%22%3A%2018%2C%20%22maxZoom%22%3A%2018%2C%20%22minZoom%22%3A%200%2C%20%22noWrap%22%3A%20false%2C%20%22opacity%22%3A%201%2C%20%22subdomains%22%3A%20%22abc%22%2C%20%22tms%22%3A%20false%7D%0A%20%20%20%20%20%20%20%20%20%20%20%20%29.addTo%28map_a59229428b57420ca402277806cd2cfc%29%3B%0A%20%20%20%20%20%20%20%20%0A%20%20%20%20%0A%20%20%20%20%20%20%20%20%20%20%20%20L.Control.geocoder%28%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%7B%22collapsed%22%3A%20false%2C%20%22defaultMarkGeocode%22%3A%20true%2C%20%22position%22%3A%20%22topright%22%7D%0A%20%20%20%20%20%20%20%20%20%20%20%20%29.on%28%27markgeocode%27%2C%20function%28e%29%20%7B%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20map_a59229428b57420ca402277806cd2cfc.setView%28e.geocode.center%2C%2011%29%3B%0A%20%20%20%20%20%20%20%20%20%20%20%20%7D%29.addTo%28map_a59229428b57420ca402277806cd2cfc%29%3B%0A%0A%20%20%20%20%20%20%20%20%0A%3C/script%3E onload=\"this.contentDocument.open();this.contentDocument.write(    decodeURIComponent(this.getAttribute('data-html')));this.contentDocument.close();\" allowfullscreen webkitallowfullscreen mozallowfullscreen></iframe></div></div>"
      ],
      "text/plain": [
       "<folium.folium.Map at 0x7f2bc3f5c990>"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "DATE_START = '01-01' + 'T00:00:00Z' # SUMMER start\n",
    "DATE_END = '12-31' + 'T23:59:59Z' # SUMMER end\n",
    "version = 5\n",
    "\n",
    "date_filters = [f'{year}-{DATE_START},{year}-{DATE_END}' for year in YEARS]\n",
    "version = str(f'{version:03}')\n",
    "\n",
    "base_query = {\n",
    "'short_name':\"ATL08\",\n",
    "'version':version, \n",
    "'bounding_box':in_bbox\n",
    "}\n",
    "\n",
    "#q3 = [build_query(copy.copy(base_query), date_filter) for date_filter in date_filters]\n",
    "queries = [dict(base_query, temporal=date_filter) for date_filter in date_filters]\n",
    "print(f\"\\tSearching MAAP for granules using these parameters: \\n\\t{queries}\")\n",
    "\n",
    "# query CMR as many seasons as necessary\n",
    "result_chain = itertools.chain.from_iterable([maap.searchGranule(**query) for query in queries])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
