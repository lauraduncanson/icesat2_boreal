{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "fixed-venice",
   "metadata": {},
   "outputs": [],
   "source": [
    "from maap.maap import MAAP\n",
    "maap = MAAP(maap_host='api.ops.maap-project.org')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "confident-scottish",
   "metadata": {},
   "source": [
    "# Launch DPS for tile_atl08.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "regulated-archives",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/projects/.local/lib/python3.7/site-packages/geopandas/_compat.py:110: UserWarning: The Shapely GEOS version (3.8.0-CAPI-1.13.1 ) is incompatible with the GEOS version PyGEOS was compiled with (3.9.1-CAPI-1.14.2). Conversions between both will be slow.\n",
      "  shapely_geos_version, geos_capi_version_string\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import geopandas\n",
    "import pandas as pd\n",
    "import glob\n",
    "import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "living-effort",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_stack_fn(stack_list_fn, in_tile_num):\n",
    "    # Find most recent topo/Landsat stack path for tile in list of stack paths from *tindex_master.csv\n",
    "    all_stacks_df = pd.read_csv(stack_list_fn)\n",
    "    stack_for_tile = all_stacks_df[all_stacks_df['location'].str.contains(\"_\"+str(in_tile_num))]\n",
    "    [print(i) for i in stack_for_tile.path.to_list()]\n",
    "    stack_for_tile_fn = stack_for_tile.path.to_list()[0]\n",
    "    if len(stack_for_tile)==0:\n",
    "        stack_for_tile_fn = None\n",
    "    return(stack_for_tile_fn)\n",
    "\n",
    "# nmt added: code that returns df of landsat locations and tile number\n",
    "# This is basically CountOutput.py\n",
    "def get_stack_df(dps_dir, TYPE, dps_year):\n",
    "    \n",
    "    if \"Landsat\" in TYPE:\n",
    "        root = f\"/projects/my-private-bucket/dps_output/do_landsat_stack_3-1-2_ubuntu/ops/{dps_year}/\"\n",
    "        ends_with_str = \"_dps.tif\"\n",
    "    if \"Topo\" in TYPE:\n",
    "        root = f\"/projects/my-private-bucket/dps_output/do_topo_stack_3-1-5_ubuntu/ops/{dps_year}/\"\n",
    "        ends_with_str = \"_stack.tif\"\n",
    "    if \"ATL08\" in TYPE:\n",
    "        root = f\"/projects/my-private-bucket/dps_output/run_extract_ubuntu/ops/{dps_year}/\"\n",
    "        ends_with_str = \"0m.csv\"\n",
    "            \n",
    "    df = pd.DataFrame(columns=['location', 'tile_num'])\n",
    "\n",
    "    for dir, subdir, files in os.walk(root):\n",
    "        for fname in files:\n",
    "            if fname.endswith(ends_with_str): \n",
    "                 \n",
    "                tile_num = fname.split('_')[1]\n",
    "                   \n",
    "                if \"ATL08\" in TYPE:\n",
    "                    df = df.append({'location':os.path.join(dir+\"/\", fname)},ignore_index=True)\n",
    "                else:\n",
    "                    df = df.append({'location':os.path.join(dir+\"/\", fname), 'tile_num':tile_num},ignore_index=True)\n",
    "        \n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "identical-illinois",
   "metadata": {},
   "source": [
    "#### Set the names of the data frames to create"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "blond-borough",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Topo and Landsat tindex_master csvs from build_tindex_master.py\n",
    "topo_tindex = \"/projects/my-public-bucket/DPS_tile_lists/Topo_tindex_master.csv\"\n",
    "landsat_tindex = \"/projects/my-public-bucket/DPS_tile_lists/Landsat_tindex_master.csv\"\n",
    "\n",
    "# Model-ready subset of tiles for which Topo and Landsat coincide\n",
    "model_ready_tiles_topo = \"/projects/my-public-bucket/DPS_tile_lists/model_ready_tiles_topo_paths.csv\"\n",
    "model_ready_tiles_landsat = \"/projects/my-public-bucket/DPS_tile_lists/model_ready_tiles_landsat_paths.csv\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "exterior-trace",
   "metadata": {},
   "source": [
    "## Make the data frames from build_tindex_master.py csvs for Topo and Landsat tiles\n",
    "python lib/build_tindex_master.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "pending-intermediate",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading existing...\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>local_path</th>\n",
       "      <th>tile_num</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>/projects/my-private-bucket/dps_output/do_topo...</td>\n",
       "      <td>421</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>/projects/my-private-bucket/dps_output/do_topo...</td>\n",
       "      <td>455</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>/projects/my-private-bucket/dps_output/do_topo...</td>\n",
       "      <td>456</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>/projects/my-private-bucket/dps_output/do_topo...</td>\n",
       "      <td>491</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>/projects/my-private-bucket/dps_output/do_topo...</td>\n",
       "      <td>492</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0                                         local_path  tile_num\n",
       "0           0  /projects/my-private-bucket/dps_output/do_topo...       421\n",
       "1           1  /projects/my-private-bucket/dps_output/do_topo...       455\n",
       "2           2  /projects/my-private-bucket/dps_output/do_topo...       456\n",
       "3           3  /projects/my-private-bucket/dps_output/do_topo...       491\n",
       "4           4  /projects/my-private-bucket/dps_output/do_topo...       492"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "if os.path.isfile(landsat_tindex) and os.path.isfile(topo_tindex):\n",
    "    print('Reading existing...')\n",
    "    ls8_df = pd.read_csv(landsat_tindex)\n",
    "    topo_df = pd.read_csv(topo_tindex)\n",
    "else:\n",
    "    s3_stem = 'https://s3.console.aws.amazon.com/s3/buckets/maap-ops-workspace/nathanmthomas'\n",
    "    local_stem = '/projects/my-private-bucket'\n",
    "\n",
    "    ls8_root =  s3_stem + '/dps_output/do_landsat_stack_3-1-2_ubuntu'\n",
    "    topo_root = s3_stem + '/dps_output/do_topo_stack_3-1-5_ubuntu'\n",
    "    \n",
    "    ls8_df = get_stack_df(ls8_root, \"Landsat\")\n",
    "    topo_df = get_stack_df(topo_root, \"Topo\")\n",
    "topo_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "bulgarian-stone",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'https://s3.console.aws.amazon.com/s3/buckets/maap-ops-workspace/nathanmthomas/dps_output/do_topo_stack_3-1-5_ubuntu/ops/2021/07/23/23/32/27/934649/Copernicus_3457_covars_cog_topo_stack.tif'"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "topo_tindex = \"/projects/my-public-bucket/DPS_tile_lists/Topo_tindex_master.csv\"\n",
    "topo_df = pd.read_csv(topo_tindex)\n",
    "topo_df[topo_df.tile_num == 3457].local_path.tolist()[0].replace('/projects/my-private-bucket', 'https://s3.console.aws.amazon.com/s3/buckets/maap-ops-workspace/nathanmthomas')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "secure-patient",
   "metadata": {},
   "source": [
    "## Get tile ids for which both Topo and Landsat stacks exist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "id": "unknown-approval",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-149-16c9997795af>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      7\u001b[0m     \u001b[0mls_tile_num\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mls8_df\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'tile_num'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mj\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtopo_df\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'tile_num'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m         \u001b[0mtopo_tile_num\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtopo_df\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'tile_num'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mj\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     10\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mls_tile_num\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mtopo_tile_num\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m             \u001b[0;31m# Only need to choose one, but we'll do 2 and then check\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.7/site-packages/pandas/core/series.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m    849\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    850\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0mkey_is_scalar\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 851\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_value\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    852\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    853\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mis_hashable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.7/site-packages/pandas/core/series.py\u001b[0m in \u001b[0;36m_get_value\u001b[0;34m(self, label, takeable)\u001b[0m\n\u001b[1;32m    957\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    958\u001b[0m         \u001b[0;31m# Similar to Index.get_value, but we do not fall back to positional\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 959\u001b[0;31m         \u001b[0mloc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlabel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    960\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_values_for_loc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    961\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# added by nmt: get filenames of co-incident landsat and topo\n",
    "\n",
    "topo_sub_df = pd.DataFrame(columns=['local_path','tile_num'])\n",
    "ls8_sub_df = pd.DataFrame(columns=['local_path','tile_num'])\n",
    "\n",
    "for i in range(len(ls8_df['tile_num'])):\n",
    "    ls_tile_num = ls8_df['tile_num'][i]\n",
    "    for j in range(len(topo_df['tile_num'])):\n",
    "        topo_tile_num = topo_df['tile_num'][j]\n",
    "        if ls_tile_num == topo_tile_num:\n",
    "            # Only need to choose one, but we'll do 2 and then check\n",
    "            ls8_sub_df = ls8_sub_df.append({'local_path':ls8_df['local_path'][i],'tile_num':ls8_df['tile_num'][i].astype(int)}, ignore_index=True)\n",
    "            topo_sub_df = topo_sub_df.append({'local_path':topo_df['local_path'][j],'tile_num':topo_df['tile_num'][j].astype(int)}, ignore_index=True)\n",
    "\n",
    "#ls8_sub_df['tile_num'] = ls8_sub_df['tile_num'].astype(float, errors = 'raise')\n",
    "print(ls8_sub_df.head())\n",
    "print(topo_sub_df.head())\n",
    "print(len(ls8_sub_df),len(topo_sub_df))\n",
    "\n",
    "topo_sub_df.to_csv( model_ready_tiles_topo, index=False, encoding='utf-8-sig')\n",
    "ls8_sub_df.to_csv( model_ready_tiles_landsat, index=False, encoding='utf-8-sig')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "contemporary-filter",
   "metadata": {},
   "source": [
    "#### Now you have a set of tile ids for which both Landsat and Topo stacks exist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "potential-variable",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4465"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "topo_sub_df = pd.read_csv(\"/projects/my-public-bucket/DPS_tile_lists/model_ready_tiles_topo_paths.csv\")\n",
    "INPUT_TILE_NUM_LIST = topo_sub_df['tile_num'].values.astype(int).tolist()\n",
    "len(INPUT_TILE_NUM_LIST)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "superb-joyce",
   "metadata": {},
   "source": [
    "##### Test: get a subset of tile ids for Norway tiles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "focused-camping",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "123"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "INPUT_TILE_NUM_LIST_NORWAY = pd.read_csv('/projects/my-public-bucket/misc_files/norway_tiles.csv').layer.tolist()\n",
    "len(INPUT_TILE_NUM_LIST_NORWAY)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "beginning-welcome",
   "metadata": {},
   "source": [
    "#### Read in the latest tindex and compare with a previous set of completed tiles to see which ones still need to be run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "rotary-ocean",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tiles completed: 106\n",
      "Tiles missing: 4325\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "4325"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "tiles_completed = pd.read_csv('/projects/my-public-bucket/DPS_tile_lists/ATL08_filt_tindex_master.csv')\n",
    "print(f'Tiles completed: {len(tiles_completed)}')\n",
    "tile_nums_missing = np.setdiff1d(INPUT_TILE_NUM_LIST, tiles_completed.tile_num)\n",
    "print(f'Tiles missing: {len(tile_nums_missing)}')\n",
    "INPUT_TILE_NUM_LIST = tile_nums_missing.tolist()\n",
    "len(INPUT_TILE_NUM_LIST)\n",
    "#print(INPUT_TILE_NUM_LIST)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "minus-minute",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5921"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tindex_master_fn = f'/projects/shared-buckets/lduncanson/DPS_tile_lists/ATL08_tindex_master.csv'\n",
    "tiles = pd.read_csv(tindex_master_fn)\n",
    "len(tiles)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "through-orchestra",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[131, 132, 133, 4, 5, 6, 7, 270, 271, 9]\n"
     ]
    }
   ],
   "source": [
    "TEST_DPS  = True\n",
    "\n",
    "if TEST_DPS:\n",
    "    DPS_INPUT_TILE_NUM_LIST = INPUT_TILE_NUM_LIST_NORWAY #INPUT_TILE_NUM_LIST[-10:]\n",
    "    DPS_INPUT_TILE_NUM_LIST = DPS_INPUT_TILE_NUM_LIST[0:10]\n",
    "else:\n",
    "    DPS_INPUT_TILE_NUM_LIST = INPUT_TILE_NUM_LIST\n",
    "    \n",
    "print(DPS_INPUT_TILE_NUM_LIST)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "changing-selling",
   "metadata": {},
   "source": [
    "#### Customize the DPS run: set up the parameters dictionary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "dirty-activity",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Norway test 01\n",
    "# Just include sol_el so we can use sol_el < 5\n",
    "in_param_dict_norway01 = {\n",
    "                        'in_tile_num': '',\n",
    "                        'in_tile_fn': 'https://maap-ops-workspace.s3.amazonaws.com/shared/nathanmthomas/boreal_tiles_v002.gpkg',\n",
    "                        'in_tile_layer': 'boreal_tiles_v002',\n",
    "                        'csv_list_fn': 's3://maap-ops-workspace/shared/lduncanson/DPS_tile_lists/ATL08_tindex_master.csv',\n",
    "                        'topo_stack_list_fn': 's3://maap-ops-workspace/shared/nathanmthomas/DPS_tile_lists/Topo_tindex_master.csv',\n",
    "                        'landsat_stack_list_fn': 's3://maap-ops-workspace/shared/nathanmthomas/DPS_tile_lists/Landsat_tindex_master.csv',\n",
    "                        'years_list': '2019 2020 2021',\n",
    "                        'user_stacks': 'nathanmthomas',\n",
    "                        'user_atl08': 'lduncanson',\n",
    "                        'thresh_sol_el': 5,\n",
    "                        'v_ATL08': 4,\n",
    "                        'minmonth': 6,\n",
    "                        'maxmonth': 9\n",
    "    }\n",
    "# Norway test 02\n",
    "# Use v005 ATL08, which will apply lc-based thresholds, extend to all months\n",
    "# NOTE!! make sure you manually update to use the correct filter in tile_atl08.py\n",
    "in_param_dict_norway02 = {\n",
    "                        'in_tile_num': '',\n",
    "                        'in_tile_fn': 'https://maap-ops-workspace.s3.amazonaws.com/shared/nathanmthomas/boreal_tiles_v002.gpkg',\n",
    "                        'in_tile_layer': 'boreal_tiles_v002',\n",
    "                        'csv_list_fn': 's3://maap-ops-workspace/shared/lduncanson/DPS_tile_lists/ATL08_tindex_master.csv',\n",
    "                        'topo_stack_list_fn': 's3://maap-ops-workspace/shared/nathanmthomas/DPS_tile_lists/Topo_tindex_master.csv',\n",
    "                        'landsat_stack_list_fn': 's3://maap-ops-workspace/shared/nathanmthomas/DPS_tile_lists/Landsat_tindex_master.csv',\n",
    "                        'years_list': '2019 2020 2021',\n",
    "                        'user_stacks': 'nathanmthomas',\n",
    "                        'user_atl08': 'lduncanson',\n",
    "                        'thresh_sol_el': 5,\n",
    "                        'v_ATL08': 5,\n",
    "                        'minmonth': 1,\n",
    "                        'maxmonth': 12\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "mighty-glory",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'in_tile_num': '',\n",
       " 'in_tile_fn': 'https://maap-ops-workspace.s3.amazonaws.com/shared/nathanmthomas/boreal_tiles_v002.gpkg',\n",
       " 'in_tile_layer': 'boreal_tiles_v002',\n",
       " 'csv_list_fn': 's3://maap-ops-workspace/shared/lduncanson/DPS_tile_lists/ATL08_tindex_master.csv',\n",
       " 'topo_stack_list_fn': 's3://maap-ops-workspace/shared/nathanmthomas/DPS_tile_lists/Topo_tindex_master.csv',\n",
       " 'landsat_stack_list_fn': 's3://maap-ops-workspace/shared/nathanmthomas/DPS_tile_lists/Landsat_tindex_master.csv',\n",
       " 'years_list': '2019 2020 2021',\n",
       " 'user_stacks': 'nathanmthomas',\n",
       " 'user_atl08': 'lduncanson',\n",
       " 'thresh_sol_el': 5,\n",
       " 'v_ATL08': 4,\n",
       " 'minmonth': 6,\n",
       " 'maxmonth': 9}"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "in_param_dict = in_param_dict_norway01\n",
    "in_param_dict"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "unavailable-latino",
   "metadata": {},
   "source": [
    "## Run a DPS job across the list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "female-accreditation",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# of input tiles for DPS: 10\n",
      "job info: {'status': 'success', 'http_status_code': 200, 'job_id': '861893e1-81f7-45a6-bbb2-ffe1238cccd8', 'dps_num': 1, 'tile_num': 131, 'submit_time': datetime.datetime(2022, 3, 2, 19, 16, 35, 490640), 'dbs_job_hour': 19, 'algo_id': 'run_tile_atl08_ubuntu', 'user': 'lduncanson', 'worker_type': 'maap-dps-worker-8gb'}\n",
      "job info: {'status': 'success', 'http_status_code': 200, 'job_id': '56e39dc2-4333-496f-b086-60f817dbe442', 'dps_num': 10, 'tile_num': 9, 'submit_time': datetime.datetime(2022, 3, 2, 19, 16, 36, 496839), 'dbs_job_hour': 19, 'algo_id': 'run_tile_atl08_ubuntu', 'user': 'lduncanson', 'worker_type': 'maap-dps-worker-8gb'}\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>status</th>\n",
       "      <th>http_status_code</th>\n",
       "      <th>job_id</th>\n",
       "      <th>dps_num</th>\n",
       "      <th>tile_num</th>\n",
       "      <th>submit_time</th>\n",
       "      <th>dbs_job_hour</th>\n",
       "      <th>algo_id</th>\n",
       "      <th>user</th>\n",
       "      <th>worker_type</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>success</td>\n",
       "      <td>200</td>\n",
       "      <td>861893e1-81f7-45a6-bbb2-ffe1238cccd8</td>\n",
       "      <td>1</td>\n",
       "      <td>131</td>\n",
       "      <td>2022-03-02 19:16:35.490640</td>\n",
       "      <td>19</td>\n",
       "      <td>run_tile_atl08_ubuntu</td>\n",
       "      <td>lduncanson</td>\n",
       "      <td>maap-dps-worker-8gb</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>success</td>\n",
       "      <td>200</td>\n",
       "      <td>a23e7809-0ad7-4ce9-91df-3f27d10506bf</td>\n",
       "      <td>2</td>\n",
       "      <td>132</td>\n",
       "      <td>2022-03-02 19:16:35.565156</td>\n",
       "      <td>19</td>\n",
       "      <td>run_tile_atl08_ubuntu</td>\n",
       "      <td>lduncanson</td>\n",
       "      <td>maap-dps-worker-8gb</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>success</td>\n",
       "      <td>200</td>\n",
       "      <td>3adcfd47-f360-4417-94e4-67bb59bfe6d8</td>\n",
       "      <td>3</td>\n",
       "      <td>133</td>\n",
       "      <td>2022-03-02 19:16:35.660410</td>\n",
       "      <td>19</td>\n",
       "      <td>run_tile_atl08_ubuntu</td>\n",
       "      <td>lduncanson</td>\n",
       "      <td>maap-dps-worker-8gb</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>success</td>\n",
       "      <td>200</td>\n",
       "      <td>77a18f56-d8f0-49f7-b213-88797e1d36ab</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>2022-03-02 19:16:35.757032</td>\n",
       "      <td>19</td>\n",
       "      <td>run_tile_atl08_ubuntu</td>\n",
       "      <td>lduncanson</td>\n",
       "      <td>maap-dps-worker-8gb</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>success</td>\n",
       "      <td>200</td>\n",
       "      <td>ff00662b-cf07-494d-816f-25df49b1bf1a</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>2022-03-02 19:16:35.869175</td>\n",
       "      <td>19</td>\n",
       "      <td>run_tile_atl08_ubuntu</td>\n",
       "      <td>lduncanson</td>\n",
       "      <td>maap-dps-worker-8gb</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>success</td>\n",
       "      <td>200</td>\n",
       "      <td>e0376079-6b05-433f-b623-6a1cdbe5bc8e</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>2022-03-02 19:16:35.983754</td>\n",
       "      <td>19</td>\n",
       "      <td>run_tile_atl08_ubuntu</td>\n",
       "      <td>lduncanson</td>\n",
       "      <td>maap-dps-worker-8gb</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>success</td>\n",
       "      <td>200</td>\n",
       "      <td>e92c155a-583d-4d49-b13b-92a7a76f6d72</td>\n",
       "      <td>7</td>\n",
       "      <td>7</td>\n",
       "      <td>2022-03-02 19:16:36.099745</td>\n",
       "      <td>19</td>\n",
       "      <td>run_tile_atl08_ubuntu</td>\n",
       "      <td>lduncanson</td>\n",
       "      <td>maap-dps-worker-8gb</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>success</td>\n",
       "      <td>200</td>\n",
       "      <td>8f8fa321-518e-4cc5-b8d8-2e146f24f5df</td>\n",
       "      <td>8</td>\n",
       "      <td>270</td>\n",
       "      <td>2022-03-02 19:16:36.299356</td>\n",
       "      <td>19</td>\n",
       "      <td>run_tile_atl08_ubuntu</td>\n",
       "      <td>lduncanson</td>\n",
       "      <td>maap-dps-worker-8gb</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>success</td>\n",
       "      <td>200</td>\n",
       "      <td>3ce9d7c6-d2e9-46dd-ade6-8b98a4a19631</td>\n",
       "      <td>9</td>\n",
       "      <td>271</td>\n",
       "      <td>2022-03-02 19:16:36.409069</td>\n",
       "      <td>19</td>\n",
       "      <td>run_tile_atl08_ubuntu</td>\n",
       "      <td>lduncanson</td>\n",
       "      <td>maap-dps-worker-8gb</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>success</td>\n",
       "      <td>200</td>\n",
       "      <td>56e39dc2-4333-496f-b086-60f817dbe442</td>\n",
       "      <td>10</td>\n",
       "      <td>9</td>\n",
       "      <td>2022-03-02 19:16:36.496839</td>\n",
       "      <td>19</td>\n",
       "      <td>run_tile_atl08_ubuntu</td>\n",
       "      <td>lduncanson</td>\n",
       "      <td>maap-dps-worker-8gb</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    status  http_status_code                                job_id  dps_num  \\\n",
       "0  success               200  861893e1-81f7-45a6-bbb2-ffe1238cccd8        1   \n",
       "0  success               200  a23e7809-0ad7-4ce9-91df-3f27d10506bf        2   \n",
       "0  success               200  3adcfd47-f360-4417-94e4-67bb59bfe6d8        3   \n",
       "0  success               200  77a18f56-d8f0-49f7-b213-88797e1d36ab        4   \n",
       "0  success               200  ff00662b-cf07-494d-816f-25df49b1bf1a        5   \n",
       "0  success               200  e0376079-6b05-433f-b623-6a1cdbe5bc8e        6   \n",
       "0  success               200  e92c155a-583d-4d49-b13b-92a7a76f6d72        7   \n",
       "0  success               200  8f8fa321-518e-4cc5-b8d8-2e146f24f5df        8   \n",
       "0  success               200  3ce9d7c6-d2e9-46dd-ade6-8b98a4a19631        9   \n",
       "0  success               200  56e39dc2-4333-496f-b086-60f817dbe442       10   \n",
       "\n",
       "   tile_num                submit_time  dbs_job_hour                algo_id  \\\n",
       "0       131 2022-03-02 19:16:35.490640            19  run_tile_atl08_ubuntu   \n",
       "0       132 2022-03-02 19:16:35.565156            19  run_tile_atl08_ubuntu   \n",
       "0       133 2022-03-02 19:16:35.660410            19  run_tile_atl08_ubuntu   \n",
       "0         4 2022-03-02 19:16:35.757032            19  run_tile_atl08_ubuntu   \n",
       "0         5 2022-03-02 19:16:35.869175            19  run_tile_atl08_ubuntu   \n",
       "0         6 2022-03-02 19:16:35.983754            19  run_tile_atl08_ubuntu   \n",
       "0         7 2022-03-02 19:16:36.099745            19  run_tile_atl08_ubuntu   \n",
       "0       270 2022-03-02 19:16:36.299356            19  run_tile_atl08_ubuntu   \n",
       "0       271 2022-03-02 19:16:36.409069            19  run_tile_atl08_ubuntu   \n",
       "0         9 2022-03-02 19:16:36.496839            19  run_tile_atl08_ubuntu   \n",
       "\n",
       "         user          worker_type  \n",
       "0  lduncanson  maap-dps-worker-8gb  \n",
       "0  lduncanson  maap-dps-worker-8gb  \n",
       "0  lduncanson  maap-dps-worker-8gb  \n",
       "0  lduncanson  maap-dps-worker-8gb  \n",
       "0  lduncanson  maap-dps-worker-8gb  \n",
       "0  lduncanson  maap-dps-worker-8gb  \n",
       "0  lduncanson  maap-dps-worker-8gb  \n",
       "0  lduncanson  maap-dps-worker-8gb  \n",
       "0  lduncanson  maap-dps-worker-8gb  \n",
       "0  lduncanson  maap-dps-worker-8gb  "
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "job_results_list = []\n",
    "\n",
    "print(f\"# of input tiles for DPS: {len(DPS_INPUT_TILE_NUM_LIST)}\")\n",
    "for i, INPUT_TILE_NUM in enumerate(DPS_INPUT_TILE_NUM_LIST):\n",
    "\n",
    "    DPS_num = i+1\n",
    "    IDENTIFIER = 'run_tile_atl08'\n",
    "    ALGO_ID = f'{IDENTIFIER}_ubuntu'\n",
    "    USER = 'lduncanson'\n",
    "    WORKER_TYPE = 'maap-dps-worker-8gb'\n",
    "    \n",
    "    in_param_dict['in_tile_num'] = INPUT_TILE_NUM\n",
    "    \n",
    "    submit_result = maap.submitJob(\n",
    "            identifier=IDENTIFIER,\n",
    "            algo_id=ALGO_ID,\n",
    "            version='master',\n",
    "            username=USER, # username needs to be the same as whoever created the workspace\n",
    "            queue=WORKER_TYPE,\n",
    "            **in_param_dict\n",
    "        )\n",
    "    \n",
    "    # Build a dataframe of submission details\n",
    "    submit_result['dps_num'] = DPS_num\n",
    "    submit_result['tile_num'] = INPUT_TILE_NUM\n",
    "    submit_result['submit_time'] = datetime.datetime.now()\n",
    "    submit_result['dbs_job_hour'] =datetime.datetime.now().hour\n",
    "    submit_result['algo_id'] = ALGO_ID\n",
    "    submit_result['user'] = USER\n",
    "    submit_result['worker_type'] = WORKER_TYPE\n",
    "    job_results_list.append(pd.DataFrame([submit_result]))\n",
    "    \n",
    "    if DPS_num in [1, 100, 500, 1000, 3000, len(DPS_INPUT_TILE_NUM_LIST)]:\n",
    "        #print(f\"DPS run #: {DPS_num} | tile num: {INPUT_TILE_NUM} | job info: {submit_result}\") \n",
    "        print(f\"job info: {submit_result}\") \n",
    "    \n",
    "job_results_df = pd.concat(job_results_list)\n",
    "job_results_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "artistic-department",
   "metadata": {},
   "source": [
    "#### Quick check of a deep DPS dir to see what was returned from the run above"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "generous-swedish",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The data frame show you submitted 10 jobs. Check the returned results to see if the total returned = total submitted...\n",
      "For DPS job that returned results in hour 1, # tiles that ran: 0\n",
      "For DPS job that returned results in hour 2, # tiles that ran: 0\n",
      "For DPS job that returned results in hour 3, # tiles that ran: 0\n",
      "For DPS job that returned results in hour 4, # tiles that ran: 0\n",
      "For DPS job that returned results in hour 5, # tiles that ran: 0\n",
      "For DPS job that returned results in hour 6, # tiles that ran: 0\n",
      "For DPS job that returned results in hour 7, # tiles that ran: 0\n",
      "For DPS job that returned results in hour 8, # tiles that ran: 0\n",
      "For DPS job that returned results in hour 9, # tiles that ran: 0\n",
      "For DPS job that returned results in hour 10, # tiles that ran: 0\n",
      "For DPS job that returned results in hour 11, # tiles that ran: 0\n",
      "For DPS job that returned results in hour 12, # tiles that ran: 0\n",
      "For DPS job that returned results in hour 13, # tiles that ran: 0\n",
      "For DPS job that returned results in hour 14, # tiles that ran: 0\n",
      "For DPS job that returned results in hour 15, # tiles that ran: 0\n",
      "For DPS job that returned results in hour 16, # tiles that ran: 0\n",
      "For DPS job that returned results in hour 17, # tiles that ran: 0\n",
      "For DPS job that returned results in hour 18, # tiles that ran: 0\n",
      "For DPS job that returned results in hour 19, # tiles that ran: 0\n",
      "For DPS job that returned results in hour 20, # tiles that ran: 0\n",
      "For DPS job that returned results in hour 21, # tiles that ran: 0\n",
      "For DPS job that returned results in hour 22, # tiles that ran: 0\n",
      "For DPS job that returned results in hour 23, # tiles that ran: 0\n",
      "For DPS job that returned results in hour 24, # tiles that ran: 0\n"
     ]
    }
   ],
   "source": [
    "print(f\"The data frame show you submitted {len(job_results_df)} jobs. Check the returned results to see if the total returned = total submitted...\")\n",
    "for JOB_HOUR in range(1,25):\n",
    "    returned_results_list = glob.glob(f\"/projects/my-private-bucket/dps_output/run_tile_atl08_ubuntu/master/2022/03/02/{JOB_HOUR}/**/_stdout.txt\", recursive=True)\n",
    "    print(f\"For DPS job that returned results in hour {JOB_HOUR}, # tiles that ran: {len(returned_results_list)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "elegant-terrorist",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting xmltodict\n",
      "  Using cached xmltodict-0.12.0-py2.py3-none-any.whl (9.2 kB)\n",
      "Installing collected packages: xmltodict\n",
      "Successfully installed xmltodict-0.12.0\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "!pip install xmltodict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "median-universal",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[b'<wps:StatusInfo xmlns:ows=\"http://www.opengis.net/ows/2.0\" xmlns:schemaLocation=\"http://schemas.opengis.net/wps/2.0/wps.xsd\" xmlns:wps=\"http://www.opengis.net/wps/2.0\" xmlns:xsi=\"http://www.w3.org/2001/XMLSchema-instance\"><wps:JobID>861893e1-81f7-45a6-bbb2-ffe1238cccd8</wps:JobID><wps:Status>Failed</wps:Status></wps:StatusInfo>',\n",
       " b'<wps:StatusInfo xmlns:ows=\"http://www.opengis.net/ows/2.0\" xmlns:schemaLocation=\"http://schemas.opengis.net/wps/2.0/wps.xsd\" xmlns:wps=\"http://www.opengis.net/wps/2.0\" xmlns:xsi=\"http://www.w3.org/2001/XMLSchema-instance\"><wps:JobID>a23e7809-0ad7-4ce9-91df-3f27d10506bf</wps:JobID><wps:Status>Failed</wps:Status></wps:StatusInfo>',\n",
       " b'<wps:StatusInfo xmlns:ows=\"http://www.opengis.net/ows/2.0\" xmlns:schemaLocation=\"http://schemas.opengis.net/wps/2.0/wps.xsd\" xmlns:wps=\"http://www.opengis.net/wps/2.0\" xmlns:xsi=\"http://www.w3.org/2001/XMLSchema-instance\"><wps:JobID>3adcfd47-f360-4417-94e4-67bb59bfe6d8</wps:JobID><wps:Status>Failed</wps:Status></wps:StatusInfo>',\n",
       " b'<wps:StatusInfo xmlns:ows=\"http://www.opengis.net/ows/2.0\" xmlns:schemaLocation=\"http://schemas.opengis.net/wps/2.0/wps.xsd\" xmlns:wps=\"http://www.opengis.net/wps/2.0\" xmlns:xsi=\"http://www.w3.org/2001/XMLSchema-instance\"><wps:JobID>77a18f56-d8f0-49f7-b213-88797e1d36ab</wps:JobID><wps:Status>Failed</wps:Status></wps:StatusInfo>',\n",
       " b'<wps:StatusInfo xmlns:ows=\"http://www.opengis.net/ows/2.0\" xmlns:schemaLocation=\"http://schemas.opengis.net/wps/2.0/wps.xsd\" xmlns:wps=\"http://www.opengis.net/wps/2.0\" xmlns:xsi=\"http://www.w3.org/2001/XMLSchema-instance\"><wps:JobID>ff00662b-cf07-494d-816f-25df49b1bf1a</wps:JobID><wps:Status>Failed</wps:Status></wps:StatusInfo>',\n",
       " b'<wps:StatusInfo xmlns:ows=\"http://www.opengis.net/ows/2.0\" xmlns:schemaLocation=\"http://schemas.opengis.net/wps/2.0/wps.xsd\" xmlns:wps=\"http://www.opengis.net/wps/2.0\" xmlns:xsi=\"http://www.w3.org/2001/XMLSchema-instance\"><wps:JobID>e0376079-6b05-433f-b623-6a1cdbe5bc8e</wps:JobID><wps:Status>Failed</wps:Status></wps:StatusInfo>',\n",
       " b'<wps:StatusInfo xmlns:ows=\"http://www.opengis.net/ows/2.0\" xmlns:schemaLocation=\"http://schemas.opengis.net/wps/2.0/wps.xsd\" xmlns:wps=\"http://www.opengis.net/wps/2.0\" xmlns:xsi=\"http://www.w3.org/2001/XMLSchema-instance\"><wps:JobID>e92c155a-583d-4d49-b13b-92a7a76f6d72</wps:JobID><wps:Status>Failed</wps:Status></wps:StatusInfo>',\n",
       " b'<wps:StatusInfo xmlns:ows=\"http://www.opengis.net/ows/2.0\" xmlns:schemaLocation=\"http://schemas.opengis.net/wps/2.0/wps.xsd\" xmlns:wps=\"http://www.opengis.net/wps/2.0\" xmlns:xsi=\"http://www.w3.org/2001/XMLSchema-instance\"><wps:JobID>8f8fa321-518e-4cc5-b8d8-2e146f24f5df</wps:JobID><wps:Status>Failed</wps:Status></wps:StatusInfo>',\n",
       " b'<wps:StatusInfo xmlns:ows=\"http://www.opengis.net/ows/2.0\" xmlns:schemaLocation=\"http://schemas.opengis.net/wps/2.0/wps.xsd\" xmlns:wps=\"http://www.opengis.net/wps/2.0\" xmlns:xsi=\"http://www.w3.org/2001/XMLSchema-instance\"><wps:JobID>3ce9d7c6-d2e9-46dd-ade6-8b98a4a19631</wps:JobID><wps:Status>Failed</wps:Status></wps:StatusInfo>',\n",
       " b'<wps:StatusInfo xmlns:ows=\"http://www.opengis.net/ows/2.0\" xmlns:schemaLocation=\"http://schemas.opengis.net/wps/2.0/wps.xsd\" xmlns:wps=\"http://www.opengis.net/wps/2.0\" xmlns:xsi=\"http://www.w3.org/2001/XMLSchema-instance\"><wps:JobID>56e39dc2-4333-496f-b086-60f817dbe442</wps:JobID><wps:Status>Failed</wps:Status></wps:StatusInfo>']"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import xmltodict\n",
    "list_dicts = [maap.getJobStatus(job_id).content for job_id in job_results_df.job_id.to_list()]\n",
    "#print(xmltodict.unparse(list_dicts[0], pretty=True))\n",
    "#maap.listJobs(username='lduncanson').content\n",
    "list_dicts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "employed-consequence",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "need_df_fn = pd.read_csv(\"/projects/my-public-bucket/DPS_tile_lists/Need_ATL08_filt_tindex_master.csv\")\n",
    "INPUT_TILE_NUM_LIST = need_df_fn['tile_num'].values.astype(int).tolist()\n",
    "len(INPUT_TILE_NUM_LIST)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "prescribed-david",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div style=\"width:100%;\"><div style=\"position:relative;width:100%;height:0;padding-bottom:60%;\"><span style=\"color:#565656\">Make this Notebook Trusted to load map: File -> Trust Notebook</span><iframe src=\"about:blank\" style=\"position:absolute;width:100%;height:100%;left:0;top:0;border:none !important;\" data-html=%3C%21DOCTYPE%20html%3E%0A%3Chead%3E%20%20%20%20%0A%20%20%20%20%3Cmeta%20http-equiv%3D%22content-type%22%20content%3D%22text/html%3B%20charset%3DUTF-8%22%20/%3E%0A%20%20%20%20%0A%20%20%20%20%20%20%20%20%3Cscript%3E%0A%20%20%20%20%20%20%20%20%20%20%20%20L_NO_TOUCH%20%3D%20false%3B%0A%20%20%20%20%20%20%20%20%20%20%20%20L_DISABLE_3D%20%3D%20false%3B%0A%20%20%20%20%20%20%20%20%3C/script%3E%0A%20%20%20%20%0A%20%20%20%20%3Cstyle%3Ehtml%2C%20body%20%7Bwidth%3A%20100%25%3Bheight%3A%20100%25%3Bmargin%3A%200%3Bpadding%3A%200%3B%7D%3C/style%3E%0A%20%20%20%20%3Cstyle%3E%23map%20%7Bposition%3Aabsolute%3Btop%3A0%3Bbottom%3A0%3Bright%3A0%3Bleft%3A0%3B%7D%3C/style%3E%0A%20%20%20%20%3Cscript%20src%3D%22https%3A//cdn.jsdelivr.net/npm/leaflet%401.6.0/dist/leaflet.js%22%3E%3C/script%3E%0A%20%20%20%20%3Cscript%20src%3D%22https%3A//code.jquery.com/jquery-1.12.4.min.js%22%3E%3C/script%3E%0A%20%20%20%20%3Cscript%20src%3D%22https%3A//maxcdn.bootstrapcdn.com/bootstrap/3.2.0/js/bootstrap.min.js%22%3E%3C/script%3E%0A%20%20%20%20%3Cscript%20src%3D%22https%3A//cdnjs.cloudflare.com/ajax/libs/Leaflet.awesome-markers/2.0.2/leaflet.awesome-markers.js%22%3E%3C/script%3E%0A%20%20%20%20%3Clink%20rel%3D%22stylesheet%22%20href%3D%22https%3A//cdn.jsdelivr.net/npm/leaflet%401.6.0/dist/leaflet.css%22/%3E%0A%20%20%20%20%3Clink%20rel%3D%22stylesheet%22%20href%3D%22https%3A//maxcdn.bootstrapcdn.com/bootstrap/3.2.0/css/bootstrap.min.css%22/%3E%0A%20%20%20%20%3Clink%20rel%3D%22stylesheet%22%20href%3D%22https%3A//maxcdn.bootstrapcdn.com/bootstrap/3.2.0/css/bootstrap-theme.min.css%22/%3E%0A%20%20%20%20%3Clink%20rel%3D%22stylesheet%22%20href%3D%22https%3A//maxcdn.bootstrapcdn.com/font-awesome/4.6.3/css/font-awesome.min.css%22/%3E%0A%20%20%20%20%3Clink%20rel%3D%22stylesheet%22%20href%3D%22https%3A//cdnjs.cloudflare.com/ajax/libs/Leaflet.awesome-markers/2.0.2/leaflet.awesome-markers.css%22/%3E%0A%20%20%20%20%3Clink%20rel%3D%22stylesheet%22%20href%3D%22https%3A//cdn.jsdelivr.net/gh/python-visualization/folium/folium/templates/leaflet.awesome.rotate.min.css%22/%3E%0A%20%20%20%20%0A%20%20%20%20%20%20%20%20%20%20%20%20%3Cmeta%20name%3D%22viewport%22%20content%3D%22width%3Ddevice-width%2C%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20initial-scale%3D1.0%2C%20maximum-scale%3D1.0%2C%20user-scalable%3Dno%22%20/%3E%0A%20%20%20%20%20%20%20%20%20%20%20%20%3Cstyle%3E%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%23map_a59229428b57420ca402277806cd2cfc%20%7B%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20position%3A%20relative%3B%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20width%3A%20100.0%25%3B%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20height%3A%20100.0%25%3B%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20left%3A%200.0%25%3B%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20top%3A%200.0%25%3B%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%7D%0A%20%20%20%20%20%20%20%20%20%20%20%20%3C/style%3E%0A%20%20%20%20%20%20%20%20%0A%20%20%20%20%3Cscript%20src%3D%22https%3A//unpkg.com/leaflet-control-geocoder/dist/Control.Geocoder.js%22%3E%3C/script%3E%0A%20%20%20%20%3Clink%20rel%3D%22stylesheet%22%20href%3D%22https%3A//unpkg.com/leaflet-control-geocoder/dist/Control.Geocoder.css%22/%3E%0A%3C/head%3E%0A%3Cbody%3E%20%20%20%20%0A%20%20%20%20%0A%20%20%20%20%20%20%20%20%20%20%20%20%3Cdiv%20class%3D%22folium-map%22%20id%3D%22map_a59229428b57420ca402277806cd2cfc%22%20%3E%3C/div%3E%0A%20%20%20%20%20%20%20%20%0A%3C/body%3E%0A%3Cscript%3E%20%20%20%20%0A%20%20%20%20%0A%20%20%20%20%20%20%20%20%20%20%20%20var%20map_a59229428b57420ca402277806cd2cfc%20%3D%20L.map%28%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%22map_a59229428b57420ca402277806cd2cfc%22%2C%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%7B%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20center%3A%20%5B0%2C%200%5D%2C%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20crs%3A%20L.CRS.EPSG3857%2C%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20zoom%3A%201%2C%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20zoomControl%3A%20true%2C%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20preferCanvas%3A%20false%2C%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%7D%0A%20%20%20%20%20%20%20%20%20%20%20%20%29%3B%0A%0A%20%20%20%20%20%20%20%20%20%20%20%20%0A%0A%20%20%20%20%20%20%20%20%0A%20%20%20%20%0A%20%20%20%20%20%20%20%20%20%20%20%20var%20tile_layer_71e248959df746bb83d7788dd024be3e%20%3D%20L.tileLayer%28%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%22https%3A//%7Bs%7D.tile.openstreetmap.org/%7Bz%7D/%7Bx%7D/%7By%7D.png%22%2C%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%7B%22attribution%22%3A%20%22Data%20by%20%5Cu0026copy%3B%20%5Cu003ca%20href%3D%5C%22http%3A//openstreetmap.org%5C%22%5Cu003eOpenStreetMap%5Cu003c/a%5Cu003e%2C%20under%20%5Cu003ca%20href%3D%5C%22http%3A//www.openstreetmap.org/copyright%5C%22%5Cu003eODbL%5Cu003c/a%5Cu003e.%22%2C%20%22detectRetina%22%3A%20false%2C%20%22maxNativeZoom%22%3A%2018%2C%20%22maxZoom%22%3A%2018%2C%20%22minZoom%22%3A%200%2C%20%22noWrap%22%3A%20false%2C%20%22opacity%22%3A%201%2C%20%22subdomains%22%3A%20%22abc%22%2C%20%22tms%22%3A%20false%7D%0A%20%20%20%20%20%20%20%20%20%20%20%20%29.addTo%28map_a59229428b57420ca402277806cd2cfc%29%3B%0A%20%20%20%20%20%20%20%20%0A%20%20%20%20%0A%20%20%20%20%20%20%20%20%20%20%20%20L.Control.geocoder%28%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%7B%22collapsed%22%3A%20false%2C%20%22defaultMarkGeocode%22%3A%20true%2C%20%22position%22%3A%20%22topright%22%7D%0A%20%20%20%20%20%20%20%20%20%20%20%20%29.on%28%27markgeocode%27%2C%20function%28e%29%20%7B%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20map_a59229428b57420ca402277806cd2cfc.setView%28e.geocode.center%2C%2011%29%3B%0A%20%20%20%20%20%20%20%20%20%20%20%20%7D%29.addTo%28map_a59229428b57420ca402277806cd2cfc%29%3B%0A%0A%20%20%20%20%20%20%20%20%0A%3C/script%3E onload=\"this.contentDocument.open();this.contentDocument.write(    decodeURIComponent(this.getAttribute('data-html')));this.contentDocument.close();\" allowfullscreen webkitallowfullscreen mozallowfullscreen></iframe></div></div>"
      ],
      "text/plain": [
       "<folium.folium.Map at 0x7f2bc3f5c990>"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "DATE_START = '01-01' + 'T00:00:00Z' # SUMMER start\n",
    "DATE_END = '12-31' + 'T23:59:59Z' # SUMMER end\n",
    "version = 5\n",
    "\n",
    "date_filters = [f'{year}-{DATE_START},{year}-{DATE_END}' for year in YEARS]\n",
    "version = str(f'{version:03}')\n",
    "\n",
    "base_query = {\n",
    "'short_name':\"ATL08\",\n",
    "'version':version, \n",
    "'bounding_box':in_bbox\n",
    "}\n",
    "\n",
    "#q3 = [build_query(copy.copy(base_query), date_filter) for date_filter in date_filters]\n",
    "queries = [dict(base_query, temporal=date_filter) for date_filter in date_filters]\n",
    "print(f\"\\tSearching MAAP for granules using these parameters: \\n\\t{queries}\")\n",
    "\n",
    "# query CMR as many seasons as necessary\n",
    "result_chain = itertools.chain.from_iterable([maap.searchGranule(**query) for query in queries])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
