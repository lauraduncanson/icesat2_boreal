{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "incorrect-terror",
   "metadata": {},
   "outputs": [],
   "source": [
    "from maap.maap import MAAP\n",
    "maap = MAAP(maap_host='api.ops.maap-project.org')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "chicken-anxiety",
   "metadata": {},
   "source": [
    "# Launch DPS for tile_atl08.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "united-pulse",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/projects/.local/lib/python3.7/site-packages/geopandas/_compat.py:110: UserWarning: The Shapely GEOS version (3.8.0-CAPI-1.13.1 ) is incompatible with the GEOS version PyGEOS was compiled with (3.9.1-CAPI-1.14.2). Conversions between both will be slow.\n",
      "  shapely_geos_version, geos_capi_version_string\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting xmltodict\n",
      "  Using cached xmltodict-0.12.0-py2.py3-none-any.whl (9.2 kB)\n",
      "Installing collected packages: xmltodict\n",
      "Successfully installed xmltodict-0.12.0\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import geopandas\n",
    "import pandas as pd\n",
    "import glob\n",
    "import datetime\n",
    "!pip install xmltodict\n",
    "import xmltodict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "plain-surrey",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_stack_fn(stack_list_fn, in_tile_num):\n",
    "    # Find most recent topo/Landsat stack path for tile in list of stack paths from *tindex_master.csv\n",
    "    all_stacks_df = pd.read_csv(stack_list_fn)\n",
    "    stack_for_tile = all_stacks_df[all_stacks_df['location'].str.contains(\"_\"+str(in_tile_num))]\n",
    "    [print(i) for i in stack_for_tile.path.to_list()]\n",
    "    stack_for_tile_fn = stack_for_tile.path.to_list()[0]\n",
    "    if len(stack_for_tile)==0:\n",
    "        stack_for_tile_fn = None\n",
    "    return(stack_for_tile_fn)\n",
    "\n",
    "# nmt added: code that returns df of landsat locations and tile number\n",
    "# This is basically CountOutput.py\n",
    "def get_stack_df(dps_dir, TYPE, dps_year):\n",
    "    \n",
    "    if \"Landsat\" in TYPE:\n",
    "        root = f\"/projects/my-private-bucket/dps_output/do_landsat_stack_3-1-2_ubuntu/ops/{dps_year}/\"\n",
    "        ends_with_str = \"_dps.tif\"\n",
    "    if \"Topo\" in TYPE:\n",
    "        root = f\"/projects/my-private-bucket/dps_output/do_topo_stack_3-1-5_ubuntu/ops/{dps_year}/\"\n",
    "        ends_with_str = \"_stack.tif\"\n",
    "    if \"ATL08\" in TYPE:\n",
    "        root = f\"/projects/my-private-bucket/dps_output/run_extract_ubuntu/ops/{dps_year}/\"\n",
    "        ends_with_str = \"0m.csv\"\n",
    "            \n",
    "    df = pd.DataFrame(columns=['location', 'tile_num'])\n",
    "\n",
    "    for dir, subdir, files in os.walk(root):\n",
    "        for fname in files:\n",
    "            if fname.endswith(ends_with_str): \n",
    "                 \n",
    "                tile_num = fname.split('_')[1]\n",
    "                   \n",
    "                if \"ATL08\" in TYPE:\n",
    "                    df = df.append({'location':os.path.join(dir+\"/\", fname)},ignore_index=True)\n",
    "                else:\n",
    "                    df = df.append({'location':os.path.join(dir+\"/\", fname), 'tile_num':tile_num},ignore_index=True)\n",
    "        \n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "desperate-hartford",
   "metadata": {},
   "source": [
    "#### Set the names of the data frames to create"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "existing-arrival",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Topo and Landsat tindex_master csvs from build_tindex_master.py\n",
    "topo_tindex = \"/projects/my-public-bucket/DPS_tile_lists/Topo_tindex_master.csv\"\n",
    "landsat_tindex = \"/projects/my-public-bucket/DPS_tile_lists/Landsat_tindex_master.csv\"\n",
    "\n",
    "# Model-ready subset of tiles for which Topo and Landsat coincide\n",
    "model_ready_tiles_topo = \"/projects/my-public-bucket/DPS_tile_lists/model_ready_tiles_topo_paths.csv\"\n",
    "model_ready_tiles_landsat = \"/projects/my-public-bucket/DPS_tile_lists/model_ready_tiles_landsat_paths.csv\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ranking-hudson",
   "metadata": {},
   "source": [
    "## Make the data frames from build_tindex_master.py csvs for Topo and Landsat tiles\n",
    "python lib/build_tindex_master.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "composite-stage",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading existing...\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>local_path</th>\n",
       "      <th>tile_num</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>/projects/my-private-bucket/dps_output/do_topo...</td>\n",
       "      <td>421</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>/projects/my-private-bucket/dps_output/do_topo...</td>\n",
       "      <td>455</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>/projects/my-private-bucket/dps_output/do_topo...</td>\n",
       "      <td>456</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>/projects/my-private-bucket/dps_output/do_topo...</td>\n",
       "      <td>491</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>/projects/my-private-bucket/dps_output/do_topo...</td>\n",
       "      <td>492</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0                                         local_path  tile_num\n",
       "0           0  /projects/my-private-bucket/dps_output/do_topo...       421\n",
       "1           1  /projects/my-private-bucket/dps_output/do_topo...       455\n",
       "2           2  /projects/my-private-bucket/dps_output/do_topo...       456\n",
       "3           3  /projects/my-private-bucket/dps_output/do_topo...       491\n",
       "4           4  /projects/my-private-bucket/dps_output/do_topo...       492"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "if os.path.isfile(landsat_tindex) and os.path.isfile(topo_tindex):\n",
    "    print('Reading existing...')\n",
    "    ls8_df = pd.read_csv(landsat_tindex)\n",
    "    topo_df = pd.read_csv(topo_tindex)\n",
    "else:\n",
    "    s3_stem = 'https://s3.console.aws.amazon.com/s3/buckets/maap-ops-workspace/nathanmthomas'\n",
    "    local_stem = '/projects/my-private-bucket'\n",
    "\n",
    "    ls8_root =  s3_stem + '/dps_output/do_landsat_stack_3-1-2_ubuntu'\n",
    "    topo_root = s3_stem + '/dps_output/do_topo_stack_3-1-5_ubuntu'\n",
    "    \n",
    "    ls8_df = get_stack_df(ls8_root, \"Landsat\")\n",
    "    topo_df = get_stack_df(topo_root, \"Topo\")\n",
    "topo_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "dangerous-story",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'https://s3.console.aws.amazon.com/s3/buckets/maap-ops-workspace/nathanmthomas/dps_output/do_topo_stack_3-1-5_ubuntu/ops/2021/07/23/23/32/27/934649/Copernicus_3457_covars_cog_topo_stack.tif'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "topo_df = pd.read_csv(topo_tindex)\n",
    "topo_df[topo_df.tile_num == 3457].local_path.tolist()[0].replace('/projects/my-private-bucket', 'https://s3.console.aws.amazon.com/s3/buckets/maap-ops-workspace/nathanmthomas')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "extended-interview",
   "metadata": {},
   "source": [
    "## Get tile ids for which both Topo and Landsat stacks exist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "union-graduate",
   "metadata": {},
   "outputs": [],
   "source": [
    "# added by nmt: get filenames of co-incident landsat and topo\n",
    "if False:\n",
    "    topo_sub_df = pd.DataFrame(columns=['local_path','tile_num'])\n",
    "    ls8_sub_df = pd.DataFrame(columns=['local_path','tile_num'])\n",
    "\n",
    "    for i in range(len(ls8_df['tile_num'])):\n",
    "        ls_tile_num = ls8_df['tile_num'][i]\n",
    "        for j in range(len(topo_df['tile_num'])):\n",
    "            topo_tile_num = topo_df['tile_num'][j]\n",
    "            if ls_tile_num == topo_tile_num:\n",
    "                # Only need to choose one, but we'll do 2 and then check\n",
    "                ls8_sub_df = ls8_sub_df.append({'local_path':ls8_df['local_path'][i],'tile_num':ls8_df['tile_num'][i].astype(int)}, ignore_index=True)\n",
    "                topo_sub_df = topo_sub_df.append({'local_path':topo_df['local_path'][j],'tile_num':topo_df['tile_num'][j].astype(int)}, ignore_index=True)\n",
    "\n",
    "    #ls8_sub_df['tile_num'] = ls8_sub_df['tile_num'].astype(float, errors = 'raise')\n",
    "    print(ls8_sub_df.head())\n",
    "    print(topo_sub_df.head())\n",
    "    print(len(ls8_sub_df),len(topo_sub_df))\n",
    "\n",
    "    topo_sub_df.to_csv( model_ready_tiles_topo, index=False, encoding='utf-8-sig')\n",
    "    ls8_sub_df.to_csv( model_ready_tiles_landsat, index=False, encoding='utf-8-sig')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "usual-charge",
   "metadata": {},
   "source": [
    "#### Now you have a set of tile ids for which both Landsat and Topo stacks exist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "funky-oregon",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4465"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "topo_sub_df = pd.read_csv(\"/projects/my-public-bucket/DPS_tile_lists/model_ready_tiles_topo_paths.csv\")\n",
    "INPUT_TILE_NUM_LIST = topo_sub_df['tile_num'].values.astype(int).tolist()\n",
    "len(INPUT_TILE_NUM_LIST)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "collective-hierarchy",
   "metadata": {},
   "source": [
    "##### Test: get a subset of tile ids for test tiles (Norway and others in NA)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "id": "standard-tuesday",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "146"
      ]
     },
     "execution_count": 138,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "NORWAY_TILE_LIST = pd.read_csv('/projects/my-public-bucket/misc_files/norway_tiles.csv').layer.tolist()\n",
    "DELTA_TILE_LIST = [3365,3366,3367,3458,3460,3353,3354,3355]\n",
    "BONA_TILE_LIST  = [3270,3271,3272,3364,3456,3457,3458]\n",
    "HEALY_TILE_LIST = [3456,3457,3458,3551,3553,3645,3646,3647]\n",
    "\n",
    "INPUT_TEST_TILE_NUM_LIST = NORWAY_TILE_LIST + DELTA_TILE_LIST + BONA_TILE_LIST + HEALY_TILE_LIST\n",
    "\n",
    "len(INPUT_TEST_TILE_NUM_LIST)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cheap-monkey",
   "metadata": {},
   "source": [
    "#### Read in the latest tindex and compare with a previous set of completed tiles to see which ones still need to be run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "id": "portable-polish",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tiles completed: 106\n",
      "Tiles missing: 4325\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "4325"
      ]
     },
     "execution_count": 137,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "tiles_completed = pd.read_csv('/projects/my-public-bucket/DPS_tile_lists/ATL08_filt_tindex_master.csv')\n",
    "print(f'Tiles completed: {len(tiles_completed)}')\n",
    "tile_nums_missing = np.setdiff1d(INPUT_TILE_NUM_LIST, tiles_completed.tile_num)\n",
    "print(f'Tiles missing: {len(tile_nums_missing)}')\n",
    "INPUT_TILE_NUM_LIST = tile_nums_missing.tolist()\n",
    "len(INPUT_TILE_NUM_LIST)\n",
    "#print(INPUT_TILE_NUM_LIST)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "enabling-carter",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "46166"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tindex_master_fn = f'/projects/shared-buckets/lduncanson/DPS_tile_lists/ATL08_tindex_master.csv'\n",
    "tiles = pd.read_csv(tindex_master_fn)\n",
    "len(tiles)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "id": "recovered-pipeline",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# of tiles to run: 146\n",
      " [131, 132, 133, 4, 5, 6, 7, 270, 271, 9, 10, 272, 273, 11, 274, 12, 13, 275, 14, 16, 17, 18, 19, 20, 151, 152, 21, 153, 154, 416, 417, 25, 418, 26, 419, 27, 28, 29, 30, 31, 296, 297, 298, 36, 299, 37, 300, 38, 39, 301, 40, 41, 42, 174, 43, 175, 176, 177, 178, 48, 49, 50, 51, 52, 53, 54, 59, 60, 322, 61, 323, 62, 324, 325, 63, 326, 64, 327, 65, 197, 328, 198, 199, 200, 201, 72, 73, 74, 75, 76, 77, 26025, 221, 352, 222, 91, 353, 223, 92, 354, 224, 93, 355, 94, 356, 225, 357, 110, 111, 112, 26574, 113, 246, 247, 248, 249, 250, 384, 385, 386, 387, 388, 130, 3365, 3366, 3367, 3458, 3460, 3353, 3354, 3355, 3270, 3271, 3272, 3364, 3456, 3457, 3458, 3456, 3457, 3458, 3551, 3553, 3645, 3646, 3647]\n"
     ]
    }
   ],
   "source": [
    "TEST_DPS  = True\n",
    "\n",
    "if TEST_DPS:\n",
    "    DPS_INPUT_TILE_NUM_LIST = INPUT_TEST_TILE_NUM_LIST\n",
    "    \n",
    "    if False:\n",
    "        !python /projects/icesat2_boreal/lib/build_tindex_master_v2.py -t ATL08_filt -y 2022 -m 03 -o /projects/test_dps\n",
    "        t = pd.read_csv('/projects/test_dps/ATL08_filt_tindex_master.csv')\n",
    "        COMPLETED_TILES = t.tile_num.to_list()\n",
    "        NEED_TILES = list(set(DPS_INPUT_TILE_NUM_LIST) - set(COMPLETED_TILES))\n",
    "\n",
    "        print(NEED_TILES)\n",
    "        DPS_INPUT_TILE_NUM_LIST = NEED_TILES\n",
    "    \n",
    "else:\n",
    "    DPS_INPUT_TILE_NUM_LIST = INPUT_TILE_NUM_LIST\n",
    "    \n",
    "print(f\"# of tiles to run: {len(DPS_INPUT_TILE_NUM_LIST)}\\n\", DPS_INPUT_TILE_NUM_LIST)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "municipal-structure",
   "metadata": {},
   "source": [
    "#### Customize the DPS run: set up the parameters dictionary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "id": "every-jewelry",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Norway test 01\n",
    "# Just include sol_el so we can use sol_el < 5\n",
    "in_param_dict_norway01 = {\n",
    "                        'in_tile_num': '',\n",
    "                        'in_tile_fn': 'https://maap-ops-workspace.s3.amazonaws.com/shared/nathanmthomas/boreal_tiles_v003.gpkg',\n",
    "                        'in_tile_layer': 'boreal_tiles_v003',\n",
    "                        'csv_list_fn': 's3://maap-ops-workspace/shared/lduncanson/DPS_tile_lists/ATL08_tindex_master.csv',\n",
    "                        'topo_stack_list_fn': 's3://maap-ops-workspace/shared/nathanmthomas/DPS_tile_lists/Topo_tindex_master.csv',\n",
    "                        'landsat_stack_list_fn': 's3://maap-ops-workspace/shared/nathanmthomas/DPS_tile_lists/Landsat_tindex_master.csv',\n",
    "                        'years_list': '2019 2020 2021',\n",
    "                        'user_stacks': 'nathanmthomas',\n",
    "                        'user_atl08': 'lduncanson',\n",
    "                        'thresh_sol_el': 5,\n",
    "                        'v_ATL08': 4,\n",
    "                        'minmonth': 6,\n",
    "                        'maxmonth': 9,\n",
    "                        'LC_filter': False\n",
    "    }\n",
    "# Norway test 02\n",
    "# Use v005 ATL08, which will apply lc-based thresholds, extend to all months\n",
    "# NOTE!! make sure you manually update to use the correct filter in tile_atl08.py\n",
    "in_param_dict_norway02 = {\n",
    "                        'in_tile_num': '',\n",
    "                        'in_tile_fn': 'https://maap-ops-workspace.s3.amazonaws.com/shared/nathanmthomas/boreal_tiles_v003.gpkg',\n",
    "                        'in_tile_layer': 'boreal_tiles_v003',\n",
    "                        'csv_list_fn': 's3://maap-ops-workspace/shared/lduncanson/DPS_tile_lists/ATL08_tindex_master.csv',\n",
    "                        'topo_stack_list_fn': 's3://maap-ops-workspace/shared/nathanmthomas/DPS_tile_lists/Topo_tindex_master.csv',\n",
    "                        'landsat_stack_list_fn': 's3://maap-ops-workspace/shared/nathanmthomas/DPS_tile_lists/Landsat_tindex_master.csv',\n",
    "                        'years_list': '2019 2020 2021',\n",
    "                        'user_stacks': 'nathanmthomas',\n",
    "                        'user_atl08': 'lduncanson',\n",
    "                        'thresh_sol_el': 5,\n",
    "                        'v_ATL08': 5,\n",
    "                        'minmonth': 4,\n",
    "                        'maxmonth': 10,\n",
    "                        'LC_filter': True\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "id": "australian-scholarship",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'in_tile_num': '',\n",
       " 'in_tile_fn': 'https://maap-ops-workspace.s3.amazonaws.com/shared/nathanmthomas/boreal_tiles_v003.gpkg',\n",
       " 'in_tile_layer': 'boreal_tiles_v003',\n",
       " 'csv_list_fn': 's3://maap-ops-workspace/shared/lduncanson/DPS_tile_lists/ATL08_tindex_master.csv',\n",
       " 'topo_stack_list_fn': 's3://maap-ops-workspace/shared/nathanmthomas/DPS_tile_lists/Topo_tindex_master.csv',\n",
       " 'landsat_stack_list_fn': 's3://maap-ops-workspace/shared/nathanmthomas/DPS_tile_lists/Landsat_tindex_master.csv',\n",
       " 'years_list': '2019 2020 2021',\n",
       " 'user_stacks': 'nathanmthomas',\n",
       " 'user_atl08': 'lduncanson',\n",
       " 'thresh_sol_el': 5,\n",
       " 'v_ATL08': 5,\n",
       " 'minmonth': 4,\n",
       " 'maxmonth': 10,\n",
       " 'LC_filter': True}"
      ]
     },
     "execution_count": 141,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "in_param_dict = in_param_dict_norway02\n",
    "in_param_dict"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "annual-highland",
   "metadata": {},
   "source": [
    "## Run a DPS job across the list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "id": "administrative-elephant",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# of input tiles for DPS: 146\n",
      "DPS run #: 1\t| tile num: 131\t| submit status: success\t| job id: 2a8b4f23-1890-4e17-96cb-0b4d014ea3a0\n",
      "DPS run #: 25\t| tile num: 151\t| submit status: success\t| job id: fc80c2e2-1ff4-41c4-b37d-18d950788e35\n",
      "DPS run #: 50\t| tile num: 301\t| submit status: success\t| job id: ffeb0c34-6dd6-4751-afde-1dbff697e84e\n",
      "DPS run #: 100\t| tile num: 354\t| submit status: success\t| job id: e31b9914-e20a-4a6e-85bd-42ff9e3ad238\n",
      "DPS run #: 146\t| tile num: 3647\t| submit status: success\t| job id: 51db777e-4c83-40e5-bf1d-bf47ca352121\n",
      "Current time:\t202203120338\n",
      "CPU times: user 1.73 s, sys: 139 ms, total: 1.87 s\n",
      "Wall time: 34.7 s\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>status</th>\n",
       "      <th>http_status_code</th>\n",
       "      <th>job_id</th>\n",
       "      <th>dps_num</th>\n",
       "      <th>tile_num</th>\n",
       "      <th>submit_time</th>\n",
       "      <th>dbs_job_hour</th>\n",
       "      <th>algo_id</th>\n",
       "      <th>user</th>\n",
       "      <th>worker_type</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>success</td>\n",
       "      <td>200</td>\n",
       "      <td>2a8b4f23-1890-4e17-96cb-0b4d014ea3a0</td>\n",
       "      <td>1</td>\n",
       "      <td>131</td>\n",
       "      <td>2022-03-12 03:37:38.360146</td>\n",
       "      <td>3</td>\n",
       "      <td>run_tile_atl08_ubuntu</td>\n",
       "      <td>lduncanson</td>\n",
       "      <td>maap-dps-worker-8gb</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>success</td>\n",
       "      <td>200</td>\n",
       "      <td>a99f2eb7-fcb4-4542-84c1-81041f4c22ba</td>\n",
       "      <td>2</td>\n",
       "      <td>132</td>\n",
       "      <td>2022-03-12 03:37:38.444376</td>\n",
       "      <td>3</td>\n",
       "      <td>run_tile_atl08_ubuntu</td>\n",
       "      <td>lduncanson</td>\n",
       "      <td>maap-dps-worker-8gb</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>success</td>\n",
       "      <td>200</td>\n",
       "      <td>22a0fb26-0b03-436d-9ec8-f05537b2fa06</td>\n",
       "      <td>3</td>\n",
       "      <td>133</td>\n",
       "      <td>2022-03-12 03:37:38.546460</td>\n",
       "      <td>3</td>\n",
       "      <td>run_tile_atl08_ubuntu</td>\n",
       "      <td>lduncanson</td>\n",
       "      <td>maap-dps-worker-8gb</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>success</td>\n",
       "      <td>200</td>\n",
       "      <td>dd88b42e-4c4c-4558-a24e-26b742234a99</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>2022-03-12 03:37:38.723344</td>\n",
       "      <td>3</td>\n",
       "      <td>run_tile_atl08_ubuntu</td>\n",
       "      <td>lduncanson</td>\n",
       "      <td>maap-dps-worker-8gb</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>success</td>\n",
       "      <td>200</td>\n",
       "      <td>816d633a-fa22-4dc5-86bc-dde852eef2b2</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>2022-03-12 03:37:38.942003</td>\n",
       "      <td>3</td>\n",
       "      <td>run_tile_atl08_ubuntu</td>\n",
       "      <td>lduncanson</td>\n",
       "      <td>maap-dps-worker-8gb</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>success</td>\n",
       "      <td>200</td>\n",
       "      <td>ef733b08-8708-43ef-9cd2-6903333b9b59</td>\n",
       "      <td>142</td>\n",
       "      <td>3551</td>\n",
       "      <td>2022-03-12 03:38:11.665981</td>\n",
       "      <td>3</td>\n",
       "      <td>run_tile_atl08_ubuntu</td>\n",
       "      <td>lduncanson</td>\n",
       "      <td>maap-dps-worker-8gb</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>success</td>\n",
       "      <td>200</td>\n",
       "      <td>e9bf8480-c0b5-42d4-bbdf-75fb5af0930a</td>\n",
       "      <td>143</td>\n",
       "      <td>3553</td>\n",
       "      <td>2022-03-12 03:38:11.910037</td>\n",
       "      <td>3</td>\n",
       "      <td>run_tile_atl08_ubuntu</td>\n",
       "      <td>lduncanson</td>\n",
       "      <td>maap-dps-worker-8gb</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>success</td>\n",
       "      <td>200</td>\n",
       "      <td>c7304ea5-04ec-49f9-ba2d-52871f60fa3c</td>\n",
       "      <td>144</td>\n",
       "      <td>3645</td>\n",
       "      <td>2022-03-12 03:38:12.131826</td>\n",
       "      <td>3</td>\n",
       "      <td>run_tile_atl08_ubuntu</td>\n",
       "      <td>lduncanson</td>\n",
       "      <td>maap-dps-worker-8gb</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>success</td>\n",
       "      <td>200</td>\n",
       "      <td>43ada2ed-d001-4484-8543-dc6b65c82511</td>\n",
       "      <td>145</td>\n",
       "      <td>3646</td>\n",
       "      <td>2022-03-12 03:38:12.385556</td>\n",
       "      <td>3</td>\n",
       "      <td>run_tile_atl08_ubuntu</td>\n",
       "      <td>lduncanson</td>\n",
       "      <td>maap-dps-worker-8gb</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>success</td>\n",
       "      <td>200</td>\n",
       "      <td>51db777e-4c83-40e5-bf1d-bf47ca352121</td>\n",
       "      <td>146</td>\n",
       "      <td>3647</td>\n",
       "      <td>2022-03-12 03:38:12.639492</td>\n",
       "      <td>3</td>\n",
       "      <td>run_tile_atl08_ubuntu</td>\n",
       "      <td>lduncanson</td>\n",
       "      <td>maap-dps-worker-8gb</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>146 rows × 10 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     status  http_status_code                                job_id  dps_num  \\\n",
       "0   success               200  2a8b4f23-1890-4e17-96cb-0b4d014ea3a0        1   \n",
       "0   success               200  a99f2eb7-fcb4-4542-84c1-81041f4c22ba        2   \n",
       "0   success               200  22a0fb26-0b03-436d-9ec8-f05537b2fa06        3   \n",
       "0   success               200  dd88b42e-4c4c-4558-a24e-26b742234a99        4   \n",
       "0   success               200  816d633a-fa22-4dc5-86bc-dde852eef2b2        5   \n",
       "..      ...               ...                                   ...      ...   \n",
       "0   success               200  ef733b08-8708-43ef-9cd2-6903333b9b59      142   \n",
       "0   success               200  e9bf8480-c0b5-42d4-bbdf-75fb5af0930a      143   \n",
       "0   success               200  c7304ea5-04ec-49f9-ba2d-52871f60fa3c      144   \n",
       "0   success               200  43ada2ed-d001-4484-8543-dc6b65c82511      145   \n",
       "0   success               200  51db777e-4c83-40e5-bf1d-bf47ca352121      146   \n",
       "\n",
       "    tile_num                submit_time  dbs_job_hour                algo_id  \\\n",
       "0        131 2022-03-12 03:37:38.360146             3  run_tile_atl08_ubuntu   \n",
       "0        132 2022-03-12 03:37:38.444376             3  run_tile_atl08_ubuntu   \n",
       "0        133 2022-03-12 03:37:38.546460             3  run_tile_atl08_ubuntu   \n",
       "0          4 2022-03-12 03:37:38.723344             3  run_tile_atl08_ubuntu   \n",
       "0          5 2022-03-12 03:37:38.942003             3  run_tile_atl08_ubuntu   \n",
       "..       ...                        ...           ...                    ...   \n",
       "0       3551 2022-03-12 03:38:11.665981             3  run_tile_atl08_ubuntu   \n",
       "0       3553 2022-03-12 03:38:11.910037             3  run_tile_atl08_ubuntu   \n",
       "0       3645 2022-03-12 03:38:12.131826             3  run_tile_atl08_ubuntu   \n",
       "0       3646 2022-03-12 03:38:12.385556             3  run_tile_atl08_ubuntu   \n",
       "0       3647 2022-03-12 03:38:12.639492             3  run_tile_atl08_ubuntu   \n",
       "\n",
       "          user          worker_type  \n",
       "0   lduncanson  maap-dps-worker-8gb  \n",
       "0   lduncanson  maap-dps-worker-8gb  \n",
       "0   lduncanson  maap-dps-worker-8gb  \n",
       "0   lduncanson  maap-dps-worker-8gb  \n",
       "0   lduncanson  maap-dps-worker-8gb  \n",
       "..         ...                  ...  \n",
       "0   lduncanson  maap-dps-worker-8gb  \n",
       "0   lduncanson  maap-dps-worker-8gb  \n",
       "0   lduncanson  maap-dps-worker-8gb  \n",
       "0   lduncanson  maap-dps-worker-8gb  \n",
       "0   lduncanson  maap-dps-worker-8gb  \n",
       "\n",
       "[146 rows x 10 columns]"
      ]
     },
     "execution_count": 142,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "submit_results_df_list = []\n",
    "len_input_list = len(DPS_INPUT_TILE_NUM_LIST)\n",
    "print(f\"# of input tiles for DPS: {len_input_list}\")\n",
    "\n",
    "for i, INPUT_TILE_NUM in enumerate(DPS_INPUT_TILE_NUM_LIST):\n",
    "\n",
    "    DPS_num = i+1\n",
    "    IDENTIFIER = 'run_tile_atl08'\n",
    "    ALGO_ID = f'{IDENTIFIER}_ubuntu'\n",
    "    USER = 'lduncanson'\n",
    "    WORKER_TYPE = 'maap-dps-worker-8gb'\n",
    "    \n",
    "    in_param_dict['in_tile_num'] = INPUT_TILE_NUM\n",
    "    \n",
    "    submit_result = maap.submitJob(\n",
    "            identifier=IDENTIFIER,\n",
    "            algo_id=ALGO_ID,\n",
    "            version='master',\n",
    "            username=USER, # username needs to be the same as whoever created the workspace\n",
    "            queue=WORKER_TYPE,\n",
    "            **in_param_dict\n",
    "        )\n",
    "    \n",
    "    # Build a dataframe of submission details\n",
    "    submit_result['dps_num'] = DPS_num\n",
    "    submit_result['tile_num'] = INPUT_TILE_NUM\n",
    "    submit_result['submit_time'] = datetime.datetime.now()\n",
    "    submit_result['dbs_job_hour'] =datetime.datetime.now().hour\n",
    "    submit_result['algo_id'] = ALGO_ID\n",
    "    submit_result['user'] = USER\n",
    "    submit_result['worker_type'] = WORKER_TYPE\n",
    "    \n",
    "    # Append to a list of data frames of submission results\n",
    "    submit_results_df_list.append(pd.DataFrame([submit_result]))\n",
    "    \n",
    "    if DPS_num in [1, 25, 50, 100, 500, 1000, 1500, 2000, 3000, 5000, 7000, 9000, 11000, 13000, 15000, 17000, 19000, 21000, 24000, len_input_list]:\n",
    "        print(f\"DPS run #: {DPS_num}\\t| tile num: {INPUT_TILE_NUM}\\t| submit status: {submit_result['status']}\\t| job id: {submit_result['job_id']}\") \n",
    "\n",
    "# Build a final submission results df and save\n",
    "submit_results_df = pd.concat(submit_results_df_list)\n",
    "nowtime = pd.Timestamp.now().strftime('%Y%m%d%H%M')\n",
    "print(f\"Current time:\\t{nowtime}\")\n",
    "submit_results_df.to_csv(f'/projects/my-public-bucket/DPS_{IDENTIFIER}_submission_results_{len_input_list}_{nowtime}.csv')\n",
    "submit_results_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fifty-corner",
   "metadata": {},
   "source": [
    "After almost any DPS job, you have to assess what succeeded and failed. This involves:\n",
    "1. building a table of job status based on job ids captured in the job_results_df from the DPS run chunk (this takes 40 mins for ~47k jobs) --> this tells you how many jobs failed\n",
    "2. merging the job status table with the job results df --> this tells you which specific granules (or tile nums) failed\n",
    "3. building another input list of granules for a follow-up DPS\n",
    "## Assess DPS results\n",
    "Build a table of job status based on job id - how many jobs failed?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "id": "automotive-charger",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Count total jobs:\t146\n",
      "Count pending jobs:\t0\n",
      "Count running jobs:\t0\n",
      "Count succeeded jobs:\t0\n",
      "Count failed jobs:\t146\n",
      "% of failed jobs:\t100.0\n",
      "CPU times: user 1.51 s, sys: 143 ms, total: 1.66 s\n",
      "Wall time: 4.1 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "def BUILD_TABLE_JOBSTATUS(submit_results_df):\n",
    "    import xmltodict\n",
    "    df = pd.concat([pd.DataFrame(xmltodict.parse(maap.getJobStatus(job_id).content)).transpose() for job_id in submit_results_df.job_id.to_list()])\n",
    "    return df\n",
    "\n",
    "job_status_df = BUILD_TABLE_JOBSTATUS(submit_results_df)\n",
    "#print(job_status_df.head())\n",
    "\n",
    "num_jobs = submit_results_df.shape[0]\n",
    "z = submit_results_df.merge(job_status_df, how='left', left_on='job_id',  right_on='wps:JobID')\n",
    "\n",
    "print(f'Count total jobs:\\t{num_jobs}')\n",
    "print(f\"Count pending jobs:\\t{z[z['wps:Status'] =='Accepted'].shape[0]}\")\n",
    "print(f\"Count running jobs:\\t{z[z['wps:Status'] =='Running'].shape[0]}\")\n",
    "print(f\"Count succeeded jobs:\\t{z[z['wps:Status'] =='Succeeded'].shape[0]}\")\n",
    "print(f\"Count failed jobs:\\t{z[z['wps:Status'] =='Failed'].shape[0]}\")\n",
    "print(f\"% of failed jobs:\\t{round(z[z['wps:Status'] =='Failed'].shape[0] / ( z[z['wps:Status'] =='Failed'].shape[0] + z[z['wps:Status'] =='Succeeded'].shape[0] ), 4) * 100}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "id": "subject-viewer",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "OrderedDict([('wps:Result',\n",
       "              OrderedDict([('@xmlns:ows', 'http://www.opengis.net/ows/2.0'),\n",
       "                           ('@xmlns:schemaLocation',\n",
       "                            'http://schemas.opengis.net/wps/2.0/wps.xsd'),\n",
       "                           ('@xmlns:wps', 'http://www.opengis.net/wps/2.0'),\n",
       "                           ('@xmlns:xsi',\n",
       "                            'http://www.w3.org/2001/XMLSchema-instance'),\n",
       "                           ('wps:JobID',\n",
       "                            '06d93201-6296-42b4-a039-20f6ad0956d4'),\n",
       "                           ('wps:Output',\n",
       "                            OrderedDict([('@id',\n",
       "                                          'output-2022-03-12T01:38:29.587754'),\n",
       "                                         ('wps:Data',\n",
       "                                          ['http://maap-ops-workspace.s3-website-us-west-2.amazonaws.com/lduncanson/dps_output/run_tile_atl08_ubuntu/master/2022/03/12/01/38/29/587754',\n",
       "                                           's3://s3.us-west-2.amazonaws.com:80/maap-ops-workspace/lduncanson/dps_output/run_tile_atl08_ubuntu/master/2022/03/12/01/38/29/587754',\n",
       "                                           'https://s3.console.aws.amazon.com/s3/buckets/maap-ops-workspace/lduncanson/dps_output/run_tile_atl08_ubuntu/master/2022/03/12/01/38/29/587754/?region=us-east-1&tab=overview'])]))]))])"
      ]
     },
     "execution_count": 128,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xmltodict.parse(maap.getJobResult(z[z['wps:Status'] =='Succeeded'].iloc[1].job_id).content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "id": "durable-closure",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "OrderedDict([('wps:Result',\n",
       "              OrderedDict([('@xmlns:ows', 'http://www.opengis.net/ows/2.0'),\n",
       "                           ('@xmlns:schemaLocation',\n",
       "                            'http://schemas.opengis.net/wps/2.0/wps.xsd'),\n",
       "                           ('@xmlns:wps', 'http://www.opengis.net/wps/2.0'),\n",
       "                           ('@xmlns:xsi',\n",
       "                            'http://www.w3.org/2001/XMLSchema-instance'),\n",
       "                           ('wps:JobID',\n",
       "                            '2a8b4f23-1890-4e17-96cb-0b4d014ea3a0'),\n",
       "                           ('wps:Output',\n",
       "                            OrderedDict([('@id', 'traceback'),\n",
       "                                         ('wps:Data',\n",
       "                                          \"activate does not accept more than one argument:\\n['/app/icesat2_boreal/dps/alg_2-4/run_tile_atl08.sh', '131', 'boreal_tiles_v003', 's3://maap-ops-workspace/shared/lduncanson/DPS_tile_lists/ATL08_tindex_master.csv', 's3://maap-ops-workspace/shared/nathanmthomas/DPS_tile_lists/Topo_tindex_master.csv', 's3://maap-ops-workspace/shared/nathanmthomas/DPS_tile_lists/Landsat_tindex_master.csv', '2019 2020 2021', 'nathanmthomas', 'lduncanson', '5', '5', '4', '10', 'True']\\n\\n+ /app/icesat2_boreal/dps/alg_2-4/run_tile_atl08.sh 131 boreal_tiles_v003 s3://maap-ops-workspace/shared/lduncanson/DPS_tile_lists/ATL08_tindex_master.csv s3://maap-ops-workspace/shared/nathanmthomas/DPS_tile_lists/Topo_tindex_master.csv s3://maap-ops-workspace/shared/nathanmthomas/DPS_tile_lists/Landsat_tindex_master.csv '2019 2020 2021' nathanmthomas lduncanson 5 5 4 10 True\\n/home/ops/.local/lib/python3.9/site-packages/geopandas/_compat.py:106: UserWarning: The Shapely GEOS version (3.10.2-CAPI-1.16.0) is incompatible with the GEOS version PyGEOS was compiled with (3.10.1-CAPI-1.16.0). Conversions between both will be slow.\\n  warnings.warn(\\nusage: tile_atl08.py [-h] [-in_tile_num IN_TILE_NUM] [-in_tile_fn IN_TILE_FN]\\n                     [-in_tile_layer IN_TILE_LAYER]\\n                     [-in_tile_id_col IN_TILE_ID_COL]\\n                     [-csv_list_fn CSV_LIST_FN]\\n                     [-topo_stack_list_fn TOPO_STACK_LIST_FN]\\n                     [-landsat_stack_list_fn LANDSAT_STACK_LIST_FN]\\n                     [-user_stacks USER_STACKS] [-user_atl08 USER_ATL08]\\n                     [-minmonth MINMONTH] [-maxmonth MAXMONTH]\\n                     [-thresh_sol_el THRESH_SOL_EL]\\n                     [-atl08_cols_list ATL08_COLS_LIST [ATL08_COLS_LIST ...]]\\n                     [-list_lc_h_can_thresh LIST_LC_H_CAN_THRESH [LIST_LC_H_CAN_THRESH ...]]\\n                     [-topo_cols_list TOPO_COLS_LIST [TOPO_COLS_LIST ...]]\\n                     [-landsat_cols_list LANDSAT_COLS_LIST [LANDSAT_COLS_LIST ...]]\\n                     [-o OUTDIR] [-dps_dir_csv DPS_DIR_CSV]\\n                     [-years_list YEARS_LIST [YEARS_LIST ...]]\\n                     [-v_ATL08 V_ATL08] [-N_OBS_SAMPLE N_OBS_SAMPLE]\\n                     [--do_30m] [--extract_covars] [--do_dps] [--TEST]\\n                     [--DEBUG] [-LC_filter LC_FILTER]\\ntile_atl08.py: error: unrecognized arguments: --updated_filters\\n+ cp _stderr.txt _alt_traceback.txt\")]))]))])"
      ]
     },
     "execution_count": 151,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xmltodict.parse(maap.getJobResult(z[z['wps:Status'] =='Failed'].iloc[0].job_id).content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "paperback-somewhere",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/projects/.local/lib/python3.7/site-packages/geopandas/_compat.py:110: UserWarning: The Shapely GEOS version (3.8.0-CAPI-1.13.1 ) is incompatible with the GEOS version PyGEOS was compiled with (3.9.1-CAPI-1.14.2). Conversions between both will be slow.\n",
      "  shapely_geos_version, geos_capi_version_string\n",
      "\n",
      "Building a list of tiles:  ATL08_filt\n",
      "\n",
      "Output dir:  /projects/test_dps\n",
      "/projects/icesat2_boreal/lib/build_tindex_master_v2.py:154: FutureWarning: The default value of regex will change from True to False in a future version.\n",
      "  df['tile_num'] = df['file'].str.split('_', expand=True)[7].str.replace('.csv','')\n",
      "# of duplicate tiles: 4\n",
      "Final # of tiles: 103\n",
      "df shape :                                              s3_path  ... tile_num\n",
      "0  s3://maap-ops-workspace/lduncanson/dps_output/...  ...     0054\n",
      "2  s3://maap-ops-workspace/lduncanson/dps_output/...  ...     0043\n",
      "4  s3://maap-ops-workspace/lduncanson/dps_output/...  ...     0031\n",
      "6  s3://maap-ops-workspace/lduncanson/dps_output/...  ...     0042\n",
      "8  s3://maap-ops-workspace/lduncanson/dps_output/...  ...     0052\n",
      "\n",
      "[5 rows x 4 columns]\n",
      "Writing tindex master csv: /projects/test_dps/ATL08_filt_tindex_master.csv\n"
     ]
    }
   ],
   "source": [
    "!python /projects/icesat2_boreal/lib/build_tindex_master_v2.py -t ATL08_filt -y 2022 -m 3 -o /projects/test_dps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "biological-access",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[387, 388, 5, 6, 7, 10, 14, 16, 275, 21, 25, 27, 28, 29, 416, 37, 38, 296, 26025, 299, 300, 301, 48, 177, 50, 178, 60, 198, 3270, 72, 326, 327, 328, 26574, 354, 355, 356, 357, 247]\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "id": "adapted-mapping",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-LC_filter True --extract_covars --do_30m --do_dps -years_list 2019 2020 2021 -o /projects/my-public-bucket/atl08_filt_covar_tiles -in_tile_num 131 -in_tile_fn /projects/shared-buckets/nathanmthomas/boreal_tiles_v003.gpkg -in_tile_layer boreal_tiles_v003 -in_tile_id_col tile_num -csv_list_fn /projects/shared-buckets/lduncanson/DPS_tile_lists/ATL08_tindex_master.csv -topo_stack_list_fn /projects/shared-buckets/nathanmthomas/DPS_tile_lists/Topo_tindex_master.csv -landsat_stack_list_fn /projects/shared-buckets/nathanmthomas/DPS_tile_lists/Landsat_tindex_master.csv -user_stacks nathanmthomas -user_atl08 lduncanson -thresh_sol_el 5 -v_ATL08 5 -minmonth 4 -maxmonth 10\n",
      "/projects/.local/lib/python3.7/site-packages/geopandas/_compat.py:110: UserWarning: The Shapely GEOS version (3.8.0-CAPI-1.13.1 ) is incompatible with the GEOS version PyGEOS was compiled with (3.9.1-CAPI-1.14.2). Conversions between both will be slow.\n",
      "  shapely_geos_version, geos_capi_version_string\n",
      "\n",
      "Land cover filtering set to: True\n",
      "\n",
      "Working on tile:\t 131\n",
      "From layer:\t\t boreal_tiles_v003\n",
      "In vector file:\t\t /projects/shared-buckets/nathanmthomas/boreal_tiles_v003.gpkg\n",
      "ATL08 version:\t\t 5\n",
      "Season start:\t\t 04-01\n",
      "Season end:\t\t 10-31\n",
      "Years:\t\t\t [2019, 2020, 2021]\n",
      "ATL08 bin length:\t 30m\n",
      "\n",
      "Doing MAAP query by tile bounds to find all intersecting ATL08 \n",
      "\tTILE_NUM: 131 (13.542284675000083,63.85506319420587,16.20544971460586,64.97513449757871)\n",
      "\tSearching MAAP for granules using these parameters: \n",
      "\t[{'short_name': 'ATL08', 'version': '005', 'bounding_box': '13.542284675000083,63.85506319420587,16.20544971460586,64.97513449757871', 'limit': 10000, 'temporal': '2019-04-01T00:00:00Z,2019-10-31T23:59:59Z'}, {'short_name': 'ATL08', 'version': '005', 'bounding_box': '13.542284675000083,63.85506319420587,16.20544971460586,64.97513449757871', 'limit': 10000, 'temporal': '2020-04-01T00:00:00Z,2020-10-31T23:59:59Z'}, {'short_name': 'ATL08', 'version': '005', 'bounding_box': '13.542284675000083,63.85506319420587,16.20544971460586,64.97513449757871', 'limit': 10000, 'temporal': '2021-04-01T00:00:00Z,2021-10-31T23:59:59Z'}]\n",
      "\t\t# ATL08 for tile 131: 195\n",
      "\n",
      "This is either a DPS job (for which the CSV has an s3 path, or the CSV exists locally.)\n",
      "\n",
      "Reading existing list of ATL08 CSVs: /projects/shared-buckets/lduncanson/DPS_tile_lists/ATL08_tindex_master.csv\n",
      "\tDoing 30m ATL08 data?  True\n",
      "\tFind ATL08 CSVs you expect for a tile based on the h5 granule search...\n",
      "\t\t# of all ATL08 granules for tile: 195\n",
      "\t\t# of all_atl08_csvs: 46166\n",
      "\t# of ATL08 CSV found for tile 131: 158\n",
      "\t# of ATL08 CSV NOT found for tile 131: 37\n",
      "Creating pandas data frame...\n",
      "\n",
      "Filtering by tile: 131\n",
      "[13.542284675000083, 16.20544971460586, 63.85506319420587, 64.97513449757871]\n",
      "Bounds clipped 67410 obs. down to 8432 obs.\n",
      "Bounds clipped 33050 obs. down to 1581 obs.\n",
      "Bounds clipped 39560 obs. down to 0 obs.\n",
      "Bounds clipped 50324 obs. down to 3208 obs.\n",
      "Bounds clipped 95567 obs. down to 11660 obs.\n",
      "Bounds clipped 111142 obs. down to 2070 obs.\n",
      "Bounds clipped 105092 obs. down to 811 obs.\n",
      "Bounds clipped 110665 obs. down to 8897 obs.\n",
      "Bounds clipped 8143 obs. down to 0 obs.\n",
      "Bounds clipped 34114 obs. down to 0 obs.\n",
      "Bounds clipped 47439 obs. down to 666 obs.\n",
      "^C\n",
      "Traceback (most recent call last):\n",
      "  File \"/projects/icesat2_boreal/lib/tile_atl08.py\", line 386, in <module>\n",
      "    main()\n",
      "  File \"/projects/icesat2_boreal/lib/tile_atl08.py\", line 308, in main\n",
      "    atl08 = pd.concat([  FilterUtils.filter_atl08_bounds_clip(pd.read_csv(f), tile['geom_4326']) for f in all_atl08_csvs_FOUND ], sort=False, ignore_index=True)\n",
      "  File \"/projects/icesat2_boreal/lib/tile_atl08.py\", line 308, in <listcomp>\n",
      "    atl08 = pd.concat([  FilterUtils.filter_atl08_bounds_clip(pd.read_csv(f), tile['geom_4326']) for f in all_atl08_csvs_FOUND ], sort=False, ignore_index=True)\n",
      "  File \"/projects/.local/lib/python3.7/site-packages/pandas/io/parsers.py\", line 610, in read_csv\n",
      "    return _read(filepath_or_buffer, kwds)\n",
      "  File \"/projects/.local/lib/python3.7/site-packages/pandas/io/parsers.py\", line 468, in _read\n",
      "    return parser.read(nrows)\n",
      "  File \"/projects/.local/lib/python3.7/site-packages/pandas/io/parsers.py\", line 1057, in read\n",
      "    index, columns, col_dict = self._engine.read(nrows)\n",
      "  File \"/projects/.local/lib/python3.7/site-packages/pandas/io/parsers.py\", line 2061, in read\n",
      "    data = self._reader.read(nrows)\n",
      "  File \"pandas/_libs/parsers.pyx\", line 756, in pandas._libs.parsers.TextReader.read\n",
      "  File \"pandas/_libs/parsers.pyx\", line 771, in pandas._libs.parsers.TextReader._read_low_memory\n",
      "  File \"pandas/_libs/parsers.pyx\", line 827, in pandas._libs.parsers.TextReader._read_rows\n",
      "  File \"pandas/_libs/parsers.pyx\", line 814, in pandas._libs.parsers.TextReader._tokenize_rows\n",
      "  File \"pandas/_libs/parsers.pyx\", line 1943, in pandas._libs.parsers.raise_parser_error\n",
      "  File \"/projects/.local/lib/python3.7/site-packages/s3fs/core.py\", line 1938, in _fetch_range\n",
      "    req_kw=self.req_kw,\n",
      "  File \"/projects/.local/lib/python3.7/site-packages/s3fs/core.py\", line 2081, in _fetch_range\n",
      "    return sync(fs.loop, resp[\"Body\"].read)\n",
      "  File \"/projects/.local/lib/python3.7/site-packages/fsspec/asyn.py\", line 59, in sync\n",
      "    if event.wait(1):\n",
      "  File \"/opt/conda/lib/python3.7/threading.py\", line 552, in wait\n",
      "    signaled = self._cond.wait(timeout)\n",
      "  File \"/opt/conda/lib/python3.7/threading.py\", line 300, in wait\n",
      "    gotit = waiter.acquire(True, timeout)\n",
      "KeyboardInterrupt\n",
      "CPU times: user 480 ms, sys: 165 ms, total: 645 ms\n",
      "Wall time: 38.3 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "TILE_NUM = 131 #NEED_TILES[6]\n",
    "args = f\"\\\n",
    "-LC_filter True \\\n",
    "--extract_covars \\\n",
    "--do_30m \\\n",
    "--do_dps \\\n",
    "-years_list 2019 2020 2021 \\\n",
    "-o /projects/my-public-bucket/atl08_filt_covar_tiles \\\n",
    "-in_tile_num {TILE_NUM} \\\n",
    "-in_tile_fn /projects/shared-buckets/nathanmthomas/boreal_tiles_v003.gpkg \\\n",
    "-in_tile_layer boreal_tiles_v003 \\\n",
    "-in_tile_id_col tile_num \\\n",
    "-csv_list_fn /projects/shared-buckets/lduncanson/DPS_tile_lists/ATL08_tindex_master.csv \\\n",
    "-topo_stack_list_fn /projects/shared-buckets/nathanmthomas/DPS_tile_lists/Topo_tindex_master.csv \\\n",
    "-landsat_stack_list_fn /projects/shared-buckets/nathanmthomas/DPS_tile_lists/Landsat_tindex_master.csv \\\n",
    "-user_stacks nathanmthomas \\\n",
    "-user_atl08 lduncanson \\\n",
    "-thresh_sol_el 5 \\\n",
    "-v_ATL08 5 -minmonth 4 -maxmonth 10\"\n",
    "print(args)\n",
    "!python /projects/icesat2_boreal/lib/tile_atl08.py $args"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
