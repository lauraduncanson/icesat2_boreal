{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "handy-eleven",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: xmltodict in /opt/conda/lib/python3.7/site-packages (0.12.0)\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "from maap.maap import MAAP\n",
    "maap = MAAP(maap_host='api.ops.maap-project.org')\n",
    "!pip install xmltodict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "dying-representation",
   "metadata": {},
   "outputs": [
    {
     "ename": "ExpatError",
     "evalue": "not well-formed (invalid token): line 1, column 0",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mExpatError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-53-9317fc6c8048>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mxmltodict\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mxmltodict\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparse\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmaap\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlistAlgorithms\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcontent\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/xmltodict.py\u001b[0m in \u001b[0;36mparse\u001b[0;34m(xml_input, encoding, expat, process_namespaces, namespace_separator, disable_entities, **kwargs)\u001b[0m\n\u001b[1;32m    325\u001b[0m         \u001b[0mparser\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mParseFile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mxml_input\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    326\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 327\u001b[0;31m         \u001b[0mparser\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mParse\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mxml_input\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    328\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mhandler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    329\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mExpatError\u001b[0m: not well-formed (invalid token): line 1, column 0"
     ]
    }
   ],
   "source": [
    "import xmltodict\n",
    "xmltodict.parse(maap.listAlgorithms().content)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "different-tennessee",
   "metadata": {},
   "source": [
    "# Launch DPS for extract_filter_atl08.py\n",
    "using the rebinned 30m h5 granules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "twenty-independence",
   "metadata": {},
   "outputs": [],
   "source": [
    "from os import path\n",
    "import os, glob\n",
    "import datetime\n",
    "import pandas as pd\n",
    "import geopandas as gpd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "oriented-adapter",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/projects/icesat2_boreal/dps/alg_2-3\n"
     ]
    }
   ],
   "source": [
    "curr_dir = wk_dir = os.path.dirname(os.path.realpath('__file__'))\n",
    "print(curr_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "configured-spending",
   "metadata": {},
   "source": [
    "## Test extract_filter_atl08.py code on Test Data\n",
    "We are running extract_filter_atl08.py (but *FILTERING* is turned off):\n",
    "\n",
    "python /projects/icesat2_boreal/lib/extract_filter_atl08.py -o \"/projects/test_data/test_data_30m\" -i \"/projects/my-private-bucket/dps_output/run_rebinning_ubuntu/master/2022/02/25/18/51/17/542274/ATL08_30m_20190721220156_03640403_005_01.h5\" --no-filter-qual --do_30m\n",
    "\n",
    "python /projects/icesat2_boreal/lib/extract_filter_atl08.py -o \"/projects/test_data/test_data_30m\" -i \"https://maap-ops-workspace.s3.amazonaws.com.com/lduncanson/dps_output/run_rebinning_ubuntu/master/2022/02/25/18/51/17/542274/ATL08_30m_20190721220156_03640403_005_01.h5\" --no-filter-qual --do_30m\n",
    "\n",
    "python lib/extract_filter_atl08.py -i \"path/to/h5file\" -o \"path/of/out/dir\" --no-filter-qual --do_30m"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "knowing-criterion",
   "metadata": {},
   "source": [
    "### Build the input DPS list of granules - s3fs implementation\n",
    "by finding h5 granules that dont yet have csvs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "id": "respiratory-toilet",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Matching extracted csv to ATL08 30m h5 granules..\n",
      "Finding the null matches (the granules that still need extracted csvs...\n",
      "# of extractions still needed:\t13067\n",
      "\n",
      "CPU times: user 1min 3s, sys: 479 ms, total: 1min 3s\n",
      "Wall time: 1min 47s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "import s3fs\n",
    "s3 = s3fs.S3FileSystem()\n",
    "bucket = \"s3://maap-ops-workspace\"\n",
    "searchkey_h5_list = [f'lduncanson/dps_output/run_rebinning_ubuntu/master/2022/03/{DAY}/**/*.h5' for DAY in ['03','04','05']]\n",
    "searchkey_csv_list = [f'lduncanson/dps_output/run_extract_filter_atl08_ubuntu/master/2022/03/{DAY}/**/*.csv' for DAY in ['06','07','08', '09', '10','11']]\n",
    "\n",
    "# Concat list of lists to data frame\n",
    "atl0830m_h5_path_df = pd.concat([pd.DataFrame(s3.glob(os.path.join(bucket, searchkey)), columns=['maap_path']) for searchkey in searchkey_h5_list])\n",
    "atl0830m_csv_path_df = pd.concat([pd.DataFrame(s3.glob(os.path.join(bucket, searchkey)), columns=['maap_path']) for searchkey in searchkey_csv_list])\n",
    "\n",
    "#Convert data frame to list\n",
    "ATL08_h5_GRANULE_LIST = [i.replace(\"maap-ops-workspace\", \"https://maap-ops-workspace.s3.amazonaws.com\") for i in atl0830m_h5_path_df.maap_path.to_list()]\n",
    "ATL08_csv_GRANULE_LIST  = [i.replace(\"maap-ops-workspace\", \"https://maap-ops-workspace.s3.amazonaws.com\") for i in atl0830m_csv_path_df.maap_path.to_list()]\n",
    "\n",
    "grans = [os.path.split(i)[-1].replace('.h5','') for i in atl0830m_h5_path_df.maap_path.to_list()]\n",
    "ATL08_h5_GRANULE_df = pd.DataFrame({'h5_path': ATL08_h5_GRANULE_LIST, 'granule_name': grans})\n",
    "\n",
    "csvs  = [os.path.split(i)[-1].replace('_30m.csv','') for i in atl0830m_csv_path_df.maap_path.to_list()]\n",
    "ATL08_csv_GRANULE_df = pd.DataFrame({'csv_path': ATL08_csv_GRANULE_LIST, 'granule_name': csvs})\n",
    "\n",
    "print('Matching extracted csv to ATL08 30m h5 granules..')\n",
    "merged = ATL08_h5_GRANULE_df.merge(ATL08_csv_GRANULE_df, how='left', on='granule_name')\n",
    "\n",
    "print('Finding the null matches (the granules that still need extracted csvs...')\n",
    "INPUT_ATL08_GRANULE_LIST = merged[merged.csv_path.isnull()].h5_path.to_list()\n",
    "print(f'# of extractions still needed:\\t{len(INPUT_ATL08_GRANULE_LIST)}\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "id": "hybrid-approach",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running DPS on the 1250 SUBSET list of input\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'https://maap-ops-workspace.s3.amazonaws.com/lduncanson/dps_output/run_rebinning_ubuntu/master/2022/03/04/15/17/30/861947/ATL08_30m_20190110224045_02060206_005_01.h5'"
      ]
     },
     "execution_count": 141,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "TEST_DPS  = False\n",
    "\n",
    "if TEST_DPS:\n",
    "    print('Running DPS on a SUBSET list of input')\n",
    "    DPS_INPUT_ATL08_GRANULE_LIST = INPUT_ATL08_GRANULE_LIST[-100:]\n",
    "else:\n",
    "    LIST_SIZE = 1250\n",
    "    print(f'Running DPS on the {LIST_SIZE} SUBSET list of input')\n",
    "    DPS_INPUT_ATL08_GRANULE_LIST = INPUT_ATL08_GRANULE_LIST[0:LIST_SIZE]\n",
    "    \n",
    "DPS_INPUT_ATL08_GRANULE_LIST[-1]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "equipped-extraction",
   "metadata": {},
   "source": [
    "## Run a DPS job across the list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "id": "challenging-japan",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DPS run #: 1\t| granule name: ATL08_30m_20181014051811_02380106_005_01.h5\t| submit status: success\t| job id: 8bd4093e-dfb3-4b79-9bd9-5a9f2bce106c\n",
      "DPS run #: 100\t| granule name: ATL08_30m_20181211175710_11320103_005_01.h5\t| submit status: success\t| job id: 65520c63-7e3b-488f-b581-662fd459fab1\n",
      "DPS run #: 500\t| granule name: ATL08_30m_20181204211244_10270106_005_01.h5\t| submit status: success\t| job id: db520ebf-3909-44cf-b6ed-8014e92b1870\n",
      "DPS run #: 1000\t| granule name: ATL08_30m_20190107050052_01490205_005_01.h5\t| submit status: success\t| job id: 234bc566-e7b0-4ab9-9582-c8962e2e49ab\n",
      "DPS run #: 1250\t| granule name: ATL08_30m_20190110224045_02060206_005_01.h5\t| submit status: success\t| job id: ba82bb75-0c47-4043-9894-c35c5f0b1bc6\n",
      "CPU times: user 15 s, sys: 1.11 s, total: 16.1 s\n",
      "Wall time: 5min 26s\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>status</th>\n",
       "      <th>http_status_code</th>\n",
       "      <th>job_id</th>\n",
       "      <th>dps_num</th>\n",
       "      <th>tile_num</th>\n",
       "      <th>submit_time</th>\n",
       "      <th>dbs_job_hour</th>\n",
       "      <th>algo_id</th>\n",
       "      <th>user</th>\n",
       "      <th>worker_type</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>success</td>\n",
       "      <td>200</td>\n",
       "      <td>8bd4093e-dfb3-4b79-9bd9-5a9f2bce106c</td>\n",
       "      <td>1</td>\n",
       "      <td>https://maap-ops-workspace.s3.amazonaws.com/ld...</td>\n",
       "      <td>2022-03-09 21:19:47.634868</td>\n",
       "      <td>21</td>\n",
       "      <td>run_extract_filter_atl08_ubuntu</td>\n",
       "      <td>lduncanson</td>\n",
       "      <td>maap-dps-worker-8gb</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>success</td>\n",
       "      <td>200</td>\n",
       "      <td>7c8bd09e-46ee-4549-9385-03c0fd83d043</td>\n",
       "      <td>2</td>\n",
       "      <td>https://maap-ops-workspace.s3.amazonaws.com/ld...</td>\n",
       "      <td>2022-03-09 21:19:47.728010</td>\n",
       "      <td>21</td>\n",
       "      <td>run_extract_filter_atl08_ubuntu</td>\n",
       "      <td>lduncanson</td>\n",
       "      <td>maap-dps-worker-8gb</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>success</td>\n",
       "      <td>200</td>\n",
       "      <td>13456b8d-5afd-4247-8e72-17c60531a477</td>\n",
       "      <td>3</td>\n",
       "      <td>https://maap-ops-workspace.s3.amazonaws.com/ld...</td>\n",
       "      <td>2022-03-09 21:19:47.913966</td>\n",
       "      <td>21</td>\n",
       "      <td>run_extract_filter_atl08_ubuntu</td>\n",
       "      <td>lduncanson</td>\n",
       "      <td>maap-dps-worker-8gb</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>success</td>\n",
       "      <td>200</td>\n",
       "      <td>36478d22-df34-4606-8fdc-bc195a2faba0</td>\n",
       "      <td>4</td>\n",
       "      <td>https://maap-ops-workspace.s3.amazonaws.com/ld...</td>\n",
       "      <td>2022-03-09 21:19:48.044203</td>\n",
       "      <td>21</td>\n",
       "      <td>run_extract_filter_atl08_ubuntu</td>\n",
       "      <td>lduncanson</td>\n",
       "      <td>maap-dps-worker-8gb</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>success</td>\n",
       "      <td>200</td>\n",
       "      <td>376995d4-003a-4d67-ba47-f9d13f70d7e3</td>\n",
       "      <td>5</td>\n",
       "      <td>https://maap-ops-workspace.s3.amazonaws.com/ld...</td>\n",
       "      <td>2022-03-09 21:19:48.349161</td>\n",
       "      <td>21</td>\n",
       "      <td>run_extract_filter_atl08_ubuntu</td>\n",
       "      <td>lduncanson</td>\n",
       "      <td>maap-dps-worker-8gb</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>success</td>\n",
       "      <td>200</td>\n",
       "      <td>cedd3848-2d80-44bb-9afc-db1a3055e2c8</td>\n",
       "      <td>1246</td>\n",
       "      <td>https://maap-ops-workspace.s3.amazonaws.com/ld...</td>\n",
       "      <td>2022-03-09 21:25:12.172719</td>\n",
       "      <td>21</td>\n",
       "      <td>run_extract_filter_atl08_ubuntu</td>\n",
       "      <td>lduncanson</td>\n",
       "      <td>maap-dps-worker-8gb</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>success</td>\n",
       "      <td>200</td>\n",
       "      <td>586cf020-f161-448c-95dc-04a755041785</td>\n",
       "      <td>1247</td>\n",
       "      <td>https://maap-ops-workspace.s3.amazonaws.com/ld...</td>\n",
       "      <td>2022-03-09 21:25:12.373812</td>\n",
       "      <td>21</td>\n",
       "      <td>run_extract_filter_atl08_ubuntu</td>\n",
       "      <td>lduncanson</td>\n",
       "      <td>maap-dps-worker-8gb</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>success</td>\n",
       "      <td>200</td>\n",
       "      <td>744b5db9-41c7-4436-852d-7c955ca1ec2a</td>\n",
       "      <td>1248</td>\n",
       "      <td>https://maap-ops-workspace.s3.amazonaws.com/ld...</td>\n",
       "      <td>2022-03-09 21:25:12.578534</td>\n",
       "      <td>21</td>\n",
       "      <td>run_extract_filter_atl08_ubuntu</td>\n",
       "      <td>lduncanson</td>\n",
       "      <td>maap-dps-worker-8gb</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>success</td>\n",
       "      <td>200</td>\n",
       "      <td>83d27441-49ba-4d16-aef2-133cc25b74f9</td>\n",
       "      <td>1249</td>\n",
       "      <td>https://maap-ops-workspace.s3.amazonaws.com/ld...</td>\n",
       "      <td>2022-03-09 21:25:12.847587</td>\n",
       "      <td>21</td>\n",
       "      <td>run_extract_filter_atl08_ubuntu</td>\n",
       "      <td>lduncanson</td>\n",
       "      <td>maap-dps-worker-8gb</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>success</td>\n",
       "      <td>200</td>\n",
       "      <td>ba82bb75-0c47-4043-9894-c35c5f0b1bc6</td>\n",
       "      <td>1250</td>\n",
       "      <td>https://maap-ops-workspace.s3.amazonaws.com/ld...</td>\n",
       "      <td>2022-03-09 21:25:13.062855</td>\n",
       "      <td>21</td>\n",
       "      <td>run_extract_filter_atl08_ubuntu</td>\n",
       "      <td>lduncanson</td>\n",
       "      <td>maap-dps-worker-8gb</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1250 rows × 10 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     status  http_status_code                                job_id  dps_num  \\\n",
       "0   success               200  8bd4093e-dfb3-4b79-9bd9-5a9f2bce106c        1   \n",
       "0   success               200  7c8bd09e-46ee-4549-9385-03c0fd83d043        2   \n",
       "0   success               200  13456b8d-5afd-4247-8e72-17c60531a477        3   \n",
       "0   success               200  36478d22-df34-4606-8fdc-bc195a2faba0        4   \n",
       "0   success               200  376995d4-003a-4d67-ba47-f9d13f70d7e3        5   \n",
       "..      ...               ...                                   ...      ...   \n",
       "0   success               200  cedd3848-2d80-44bb-9afc-db1a3055e2c8     1246   \n",
       "0   success               200  586cf020-f161-448c-95dc-04a755041785     1247   \n",
       "0   success               200  744b5db9-41c7-4436-852d-7c955ca1ec2a     1248   \n",
       "0   success               200  83d27441-49ba-4d16-aef2-133cc25b74f9     1249   \n",
       "0   success               200  ba82bb75-0c47-4043-9894-c35c5f0b1bc6     1250   \n",
       "\n",
       "                                             tile_num  \\\n",
       "0   https://maap-ops-workspace.s3.amazonaws.com/ld...   \n",
       "0   https://maap-ops-workspace.s3.amazonaws.com/ld...   \n",
       "0   https://maap-ops-workspace.s3.amazonaws.com/ld...   \n",
       "0   https://maap-ops-workspace.s3.amazonaws.com/ld...   \n",
       "0   https://maap-ops-workspace.s3.amazonaws.com/ld...   \n",
       "..                                                ...   \n",
       "0   https://maap-ops-workspace.s3.amazonaws.com/ld...   \n",
       "0   https://maap-ops-workspace.s3.amazonaws.com/ld...   \n",
       "0   https://maap-ops-workspace.s3.amazonaws.com/ld...   \n",
       "0   https://maap-ops-workspace.s3.amazonaws.com/ld...   \n",
       "0   https://maap-ops-workspace.s3.amazonaws.com/ld...   \n",
       "\n",
       "                  submit_time  dbs_job_hour                          algo_id  \\\n",
       "0  2022-03-09 21:19:47.634868            21  run_extract_filter_atl08_ubuntu   \n",
       "0  2022-03-09 21:19:47.728010            21  run_extract_filter_atl08_ubuntu   \n",
       "0  2022-03-09 21:19:47.913966            21  run_extract_filter_atl08_ubuntu   \n",
       "0  2022-03-09 21:19:48.044203            21  run_extract_filter_atl08_ubuntu   \n",
       "0  2022-03-09 21:19:48.349161            21  run_extract_filter_atl08_ubuntu   \n",
       "..                        ...           ...                              ...   \n",
       "0  2022-03-09 21:25:12.172719            21  run_extract_filter_atl08_ubuntu   \n",
       "0  2022-03-09 21:25:12.373812            21  run_extract_filter_atl08_ubuntu   \n",
       "0  2022-03-09 21:25:12.578534            21  run_extract_filter_atl08_ubuntu   \n",
       "0  2022-03-09 21:25:12.847587            21  run_extract_filter_atl08_ubuntu   \n",
       "0  2022-03-09 21:25:13.062855            21  run_extract_filter_atl08_ubuntu   \n",
       "\n",
       "          user          worker_type  \n",
       "0   lduncanson  maap-dps-worker-8gb  \n",
       "0   lduncanson  maap-dps-worker-8gb  \n",
       "0   lduncanson  maap-dps-worker-8gb  \n",
       "0   lduncanson  maap-dps-worker-8gb  \n",
       "0   lduncanson  maap-dps-worker-8gb  \n",
       "..         ...                  ...  \n",
       "0   lduncanson  maap-dps-worker-8gb  \n",
       "0   lduncanson  maap-dps-worker-8gb  \n",
       "0   lduncanson  maap-dps-worker-8gb  \n",
       "0   lduncanson  maap-dps-worker-8gb  \n",
       "0   lduncanson  maap-dps-worker-8gb  \n",
       "\n",
       "[1250 rows x 10 columns]"
      ]
     },
     "execution_count": 142,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "submit_results_df_list = []\n",
    "len_input_list = len(DPS_INPUT_ATL08_GRANULE_LIST)\n",
    "\n",
    "for i, INPUT_ATL08_GRANULE in enumerate(DPS_INPUT_ATL08_GRANULE_LIST):\n",
    "\n",
    "    DPS_num = i+1\n",
    "    IDENTIFIER = 'run_extract_filter_atl08'\n",
    "    ALGO_ID = f'{IDENTIFIER}_ubuntu'\n",
    "    USER = 'lduncanson'\n",
    "    WORKER_TYPE = 'maap-dps-worker-8gb'\n",
    "    \n",
    "    in_param_dict = {\n",
    "                        'input_file': INPUT_ATL08_GRANULE\n",
    "                    }\n",
    "\n",
    "    submit_result = maap.submitJob(\n",
    "            identifier=IDENTIFIER,\n",
    "            algo_id=ALGO_ID,\n",
    "            version='master',\n",
    "            username=USER, # username needs to be the same as whoever created the workspace\n",
    "            queue=WORKER_TYPE,\n",
    "            **in_param_dict\n",
    "        )\n",
    "    \n",
    "    # Build a dataframe of submission details\n",
    "    submit_result['dps_num'] = DPS_num\n",
    "    submit_result['tile_num'] = INPUT_ATL08_GRANULE\n",
    "    submit_result['submit_time'] = datetime.datetime.now()\n",
    "    submit_result['dbs_job_hour'] = datetime.datetime.now().hour\n",
    "    submit_result['algo_id'] = ALGO_ID\n",
    "    submit_result['user'] = USER\n",
    "    submit_result['worker_type'] = WORKER_TYPE\n",
    "    \n",
    "    # Append to a list of data frames of submission results\n",
    "    submit_results_df_list.append(pd.DataFrame([submit_result]))\n",
    "    \n",
    "    if DPS_num in [1, 100, 500, 1000, 1500, 2000, 3000, 5000, 7000, 9000, 11000, 13000, 15000, 17000, 19000, 21000, 24000, len_input_list]:\n",
    "        print(f\"DPS run #: {DPS_num}\\t| granule name: {os.path.basename(INPUT_ATL08_GRANULE)}\\t| submit status: {submit_result['status']}\\t| job id: {submit_result['job_id']}\") \n",
    "\n",
    "# Build a final submission results df and save\n",
    "submit_results_df = pd.concat(submit_results_df_list)\n",
    "nowtime = pd.Timestamp.now().strftime('%Y%m%d%H%M')\n",
    "submit_results_df.to_csv(f'/projects/my-public-bucket/DPS_{IDENTIFIER}_submission_results_{len_input_list}_{nowtime}.csv')\n",
    "submit_results_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "confused-passport",
   "metadata": {},
   "source": [
    "After almost any DPS job, you have to assess what succeeded and failed. This involves:\n",
    "1. building a table of job status based on job ids captured in the job_results_df from the DPS run chunk (this takes 40 mins for ~47k jobs) --> this tells you how many jobs failed\n",
    "2. merging the job status table with the job results df --> this tells you which specific granules (or tile nums) failed\n",
    "3. building another input list of granules for a follow-up DPS\n",
    "## Assess DPS results\n",
    "Build a table of job status based on job id - how many jobs failed?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "id": "electoral-basic",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Count total jobs:\t1250\n",
      "Count pending jobs:\t0\n",
      "Count running jobs:\t43\n",
      "Count succeeded jobs:\t828\n",
      "Count failed jobs:\t379\n",
      "% of failed jobs:\t31.4\n",
      "CPU times: user 13.6 s, sys: 1.04 s, total: 14.6 s\n",
      "Wall time: 37.8 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "def BUILD_TABLE_JOBSTATUS(submit_results_df):\n",
    "    import xmltodict\n",
    "    df = pd.concat([pd.DataFrame(xmltodict.parse(maap.getJobStatus(job_id).content)).transpose() for job_id in submit_results_df.job_id.to_list()])\n",
    "    return df\n",
    "\n",
    "job_status_df = BUILD_TABLE_JOBSTATUS(submit_results_df)\n",
    "#print(job_status_df.head())\n",
    "\n",
    "num_jobs = submit_results_df.shape[0]\n",
    "z = submit_results_df.merge(job_status_df, how='left', left_on='job_id', right_on='wps:JobID')\n",
    "\n",
    "print(f'Count total jobs:\\t{num_jobs}')\n",
    "print(f\"Count pending jobs:\\t{z[z['wps:Status'] =='Accepted'].shape[0]}\")\n",
    "print(f\"Count running jobs:\\t{z[z['wps:Status'] =='Running'].shape[0]}\")\n",
    "print(f\"Count succeeded jobs:\\t{z[z['wps:Status'] =='Succeeded'].shape[0]}\")\n",
    "print(f\"Count failed jobs:\\t{z[z['wps:Status'] =='Failed'].shape[0]}\")\n",
    "print(f\"% of failed jobs:\\t{round(z[z['wps:Status'] =='Failed'].shape[0] / ( z[z['wps:Status'] =='Failed'].shape[0] + z[z['wps:Status'] =='Succeeded'].shape[0] ), 4) * 100}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "id": "chemical-performer",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "OrderedDict([('wps:Result',\n",
       "              OrderedDict([('@xmlns:ows', 'http://www.opengis.net/ows/2.0'),\n",
       "                           ('@xmlns:schemaLocation',\n",
       "                            'http://schemas.opengis.net/wps/2.0/wps.xsd'),\n",
       "                           ('@xmlns:wps', 'http://www.opengis.net/wps/2.0'),\n",
       "                           ('@xmlns:xsi',\n",
       "                            'http://www.w3.org/2001/XMLSchema-instance'),\n",
       "                           ('wps:JobID',\n",
       "                            '2d3a47e4-14e3-4c2d-ae42-43bbda466407'),\n",
       "                           ('wps:Output',\n",
       "                            OrderedDict([('@id', 'traceback'),\n",
       "                                         ('wps:Data',\n",
       "                                          'Traceback (most recent call last):\\n  File \"/home/ops/verdi/ops/hysds-0.3.11/hysds/job_worker.py\", line 1126, in run_job\\n    raise RuntimeError(\"Got non-zero exit code: {}\".format(status))\\nRuntimeError: Got non-zero exit code: 143')]))]))])"
      ]
     },
     "execution_count": 134,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xmltodict.parse(maap.getJobResult(z[z['wps:Status'] =='Failed'].iloc[0].job_id).content)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "divine-glucose",
   "metadata": {},
   "source": [
    "##### Pick a job and manually test - does it produce output as expected?\n",
    "if so, then AWS had some issue during the DPS: contact MAAP dev about this"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "creative-consumer",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Written by:\n",
      "\tNathan Thomas\t| @Nmt28\n",
      "\tPaul Montesano\t| paul.m.montesano@nasa.gov\n",
      "\n",
      "Min lat: 45.0\n",
      "Max lat: 75.0\n",
      "Min lon: -180.0\n",
      "Max lon: 180.0\n",
      "Month range: 6-9\n",
      "\n",
      "ATL08 granule name: \tATL08_30m_20210714235338_03261206_005_01\n",
      "Input dir: \t\t/projects/my-private-bucket/dps_output/run_rebinning_ubuntu/master/2022/03/05/04/51/06/341661\n",
      "\n",
      "Segment length: 30m\n",
      "Find src nodata value using max of h_can: \tnan\n",
      "\n",
      "Building pandas dataframe...\n",
      "Setting pandas df nodata values to np.nan for some basic eval.\n",
      "# of ATL08 obs: \t\t211006\n",
      "# of ATL08 obs (can pho.>=0): \t77997\n",
      "# of ATL08 obs (toc pho.>=0): \t77997\n",
      "# of ATL08 obs (h_can>=0): \t77905\n",
      "# of ATL08 obs (h_can<0): \t92\n",
      "Setting out pandas df nodata values: \t3.4028234663852886e+38\n",
      "Quality Filtering: \t[OFF] (do downstream)\n",
      "Geographic Filtering: \t[ON] xmin = -180.0, xmax = 180.0, ymin = 45.0, ymax = 75.0\n",
      "Creating CSV: \t\t/projects/my-public-bucket/test_output/ATL08_30m_20210714235338_03261206_005_01_30m.csv\n"
     ]
    }
   ],
   "source": [
    "f = fails_df.iloc[1].tile_num.replace('https://maap-ops-workspace.s3.amazonaws.com/lduncanson','/projects/my-private-bucket')\n",
    "!python /projects/icesat2_boreal/dps/alg_2-3/extract_filter_atl08.py --i $f --no-filter-qual --do_30m -o /projects/my-public-bucket/test_output"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "sweet-duplicate",
   "metadata": {},
   "source": [
    "### Compile granules of the fails for another DPS batch (Round2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "id": "hundred-graduate",
   "metadata": {},
   "outputs": [],
   "source": [
    "def chunks(lst, n):\n",
    "    \"\"\"Yield successive n-sized chunks from lst.\"\"\"\n",
    "    for i in range(0, len(lst), n):\n",
    "        yield lst[i:i + n]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "id": "residential-pointer",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5000 5000 5000 5000 280\n"
     ]
    }
   ],
   "source": [
    "import pprint\n",
    "DPS_INPUT_ATL08_GRANULE_LIST_1, DPS_INPUT_ATL08_GRANULE_LIST_2, DPS_INPUT_ATL08_GRANULE_LIST_3, DPS_INPUT_ATL08_GRANULE_LIST_4, DPS_INPUT_ATL08_GRANULE_LIST_5 = list(chunks(DPS_INPUT_ATL08_GRANULE_LIST, 5000))\n",
    "print(\n",
    "    len(DPS_INPUT_ATL08_GRANULE_LIST_1), len(DPS_INPUT_ATL08_GRANULE_LIST_2), len(DPS_INPUT_ATL08_GRANULE_LIST_3), len(DPS_INPUT_ATL08_GRANULE_LIST_4), len(DPS_INPUT_ATL08_GRANULE_LIST_5)\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "authorized-programmer",
   "metadata": {},
   "source": [
    "### Examine output of DPS - but replace glob.glob with s3.glob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "completed-cabin",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For DPS job that returned results in hour 20, # granules that ran: 10\n"
     ]
    }
   ],
   "source": [
    "#print(f\"The data frame show you submitted {len(job_results_df)} jobs. Check the returned results to see if the total returned = total submitted...\")\n",
    "for JOB_HOUR in range(20,21):\n",
    "    returned_results_list = glob.glob(f\"/projects/my-private-bucket/dps_output/run_extract_filter_atl08_ubuntu/master/2022/03/04/{JOB_HOUR}/**/*.csv\", recursive=True)\n",
    "    print(f\"For DPS job that returned results in hour {JOB_HOUR}, # granules that ran: {len(returned_results_list)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "facial-canyon",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating pandas data frame...\n"
     ]
    }
   ],
   "source": [
    "# Merge all files in the list\n",
    "print(\"Creating pandas data frame...\")\n",
    "atl08_gdf = pd.concat((pd.read_csv(f) for f in returned_results_list ), sort=False, ignore_index=True) # <--generator is (), list is []\n",
    "atl08_gdf = gpd.GeoDataFrame(atl08_gdf, geometry=gpd.points_from_xy(atl08_gdf.lon, atl08_gdf.lat), crs='epsg:4326')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "everyday-dining",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>fid</th>\n",
       "      <th>lon</th>\n",
       "      <th>lat</th>\n",
       "      <th>dt</th>\n",
       "      <th>orb_orient</th>\n",
       "      <th>orb_num</th>\n",
       "      <th>rgt</th>\n",
       "      <th>gt</th>\n",
       "      <th>segid_beg</th>\n",
       "      <th>segid_end</th>\n",
       "      <th>...</th>\n",
       "      <th>asr</th>\n",
       "      <th>h_dif_ref</th>\n",
       "      <th>ter_flg</th>\n",
       "      <th>ph_rem_flg</th>\n",
       "      <th>dem_rem_flg</th>\n",
       "      <th>seg_wmask</th>\n",
       "      <th>lyr_flg</th>\n",
       "      <th>seg_cover</th>\n",
       "      <th>granule_name</th>\n",
       "      <th>geometry</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>14887</td>\n",
       "      <td>75.620664</td>\n",
       "      <td>45.000490</td>\n",
       "      <td>b'2019-04-08T02:04:27.000000Z'</td>\n",
       "      <td>0</td>\n",
       "      <td>3125</td>\n",
       "      <td>150</td>\n",
       "      <td>b'gt1r'</td>\n",
       "      <td>249813.842915</td>\n",
       "      <td>249817.842915</td>\n",
       "      <td>...</td>\n",
       "      <td>0.158199</td>\n",
       "      <td>-1.342682</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>48</td>\n",
       "      <td>ATL08_30m_20190408015557_01500302_005_01.h5</td>\n",
       "      <td>POINT (75.62066 45.00049)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>14888</td>\n",
       "      <td>75.620628</td>\n",
       "      <td>45.000758</td>\n",
       "      <td>b'2019-04-08T02:04:27.000000Z'</td>\n",
       "      <td>0</td>\n",
       "      <td>3125</td>\n",
       "      <td>150</td>\n",
       "      <td>b'gt1r'</td>\n",
       "      <td>249815.336919</td>\n",
       "      <td>249819.336919</td>\n",
       "      <td>...</td>\n",
       "      <td>0.158199</td>\n",
       "      <td>-1.342682</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>48</td>\n",
       "      <td>ATL08_30m_20190408015557_01500302_005_01.h5</td>\n",
       "      <td>POINT (75.62063 45.00076)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>14889</td>\n",
       "      <td>75.620401</td>\n",
       "      <td>45.002371</td>\n",
       "      <td>b'2019-04-08T02:04:27.000000Z'</td>\n",
       "      <td>0</td>\n",
       "      <td>3125</td>\n",
       "      <td>150</td>\n",
       "      <td>b'gt1r'</td>\n",
       "      <td>249824.331298</td>\n",
       "      <td>249828.331298</td>\n",
       "      <td>...</td>\n",
       "      <td>0.158199</td>\n",
       "      <td>-1.073212</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>42</td>\n",
       "      <td>ATL08_30m_20190408015557_01500302_005_01.h5</td>\n",
       "      <td>POINT (75.62040 45.00237)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>14890</td>\n",
       "      <td>75.620364</td>\n",
       "      <td>45.002640</td>\n",
       "      <td>b'2019-04-08T02:04:27.000000Z'</td>\n",
       "      <td>0</td>\n",
       "      <td>3125</td>\n",
       "      <td>150</td>\n",
       "      <td>b'gt1r'</td>\n",
       "      <td>249825.830880</td>\n",
       "      <td>249829.830880</td>\n",
       "      <td>...</td>\n",
       "      <td>0.158199</td>\n",
       "      <td>-1.073212</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>42</td>\n",
       "      <td>ATL08_30m_20190408015557_01500302_005_01.h5</td>\n",
       "      <td>POINT (75.62036 45.00264)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>14891</td>\n",
       "      <td>75.620291</td>\n",
       "      <td>45.003178</td>\n",
       "      <td>b'2019-04-08T02:04:27.000000Z'</td>\n",
       "      <td>0</td>\n",
       "      <td>3125</td>\n",
       "      <td>150</td>\n",
       "      <td>b'gt1r'</td>\n",
       "      <td>249828.830880</td>\n",
       "      <td>249832.830880</td>\n",
       "      <td>...</td>\n",
       "      <td>0.129356</td>\n",
       "      <td>-1.743439</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>24</td>\n",
       "      <td>ATL08_30m_20190408015557_01500302_005_01.h5</td>\n",
       "      <td>POINT (75.62029 45.00318)</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 56 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     fid        lon        lat                              dt  orb_orient  \\\n",
       "0  14887  75.620664  45.000490  b'2019-04-08T02:04:27.000000Z'           0   \n",
       "1  14888  75.620628  45.000758  b'2019-04-08T02:04:27.000000Z'           0   \n",
       "2  14889  75.620401  45.002371  b'2019-04-08T02:04:27.000000Z'           0   \n",
       "3  14890  75.620364  45.002640  b'2019-04-08T02:04:27.000000Z'           0   \n",
       "4  14891  75.620291  45.003178  b'2019-04-08T02:04:27.000000Z'           0   \n",
       "\n",
       "   orb_num  rgt       gt      segid_beg      segid_end  ...       asr  \\\n",
       "0     3125  150  b'gt1r'  249813.842915  249817.842915  ...  0.158199   \n",
       "1     3125  150  b'gt1r'  249815.336919  249819.336919  ...  0.158199   \n",
       "2     3125  150  b'gt1r'  249824.331298  249828.331298  ...  0.158199   \n",
       "3     3125  150  b'gt1r'  249825.830880  249829.830880  ...  0.158199   \n",
       "4     3125  150  b'gt1r'  249828.830880  249832.830880  ...  0.129356   \n",
       "\n",
       "   h_dif_ref  ter_flg  ph_rem_flg  dem_rem_flg  seg_wmask  lyr_flg  seg_cover  \\\n",
       "0  -1.342682        1           0            0          0        0         48   \n",
       "1  -1.342682        1           0            0          0        0         48   \n",
       "2  -1.073212        1           0            0          0        0         42   \n",
       "3  -1.073212        1           0            0          0        0         42   \n",
       "4  -1.743439        1           0            0          0        0         24   \n",
       "\n",
       "                                  granule_name                   geometry  \n",
       "0  ATL08_30m_20190408015557_01500302_005_01.h5  POINT (75.62066 45.00049)  \n",
       "1  ATL08_30m_20190408015557_01500302_005_01.h5  POINT (75.62063 45.00076)  \n",
       "2  ATL08_30m_20190408015557_01500302_005_01.h5  POINT (75.62040 45.00237)  \n",
       "3  ATL08_30m_20190408015557_01500302_005_01.h5  POINT (75.62036 45.00264)  \n",
       "4  ATL08_30m_20190408015557_01500302_005_01.h5  POINT (75.62029 45.00318)  \n",
       "\n",
       "[5 rows x 56 columns]"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "atl08_gdf.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "federal-optimum",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "512"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.system( \"python /projects/icesat2_boreal/lib/build_tindex_master.py -t ATL08 -dps_year 2022 -m 3 --start_day '04' --outdir /projects/my-public-bucket/test_output\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
