{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "lonely-acrobat",
   "metadata": {},
   "outputs": [],
   "source": [
    "from maap.maap import MAAP\n",
    "maap = MAAP(maap_host='api.ops.maap-project.org')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "curious-agriculture",
   "metadata": {},
   "source": [
    "# Launch DPS for mapBoreal.R"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "cellular-warehouse",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import geopandas\n",
    "import pandas as pd\n",
    "import json\n",
    "\n",
    "def local_to_s3(url, user='lduncanson'):\n",
    "    ''' A Function to convert local paths to s3 urls'''\n",
    "    return url.replace('/projects/my-private-bucket', f's3://maap-ops-workspace/{user}')\n",
    "def local_to_https(url, user='lduncanson'):\n",
    "    ''' A Function to convert local paths to https urls'''\n",
    "    return url.replace('/projects/my-private-bucket', f'https://s3.console.aws.amazon.com/s3/buckets/maap-ops-workspace/{user}')\n",
    "def local_to_https_uswest2(url, user='lduncanson'):\n",
    "    ''' A Function to convert local paths to https us-west-s urls'''\n",
    "    return url.replace('/projects/my-private-bucket', f'https://maap-ops-workspace.s3.us-west-2.amazonaws.com/{user}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "numeric-afghanistan",
   "metadata": {},
   "outputs": [],
   "source": [
    "atl08_filt_tindex_master =   pd.read_csv('s3://maap-ops-workspace/shared/lduncanson/DPS_tile_lists/ATL08_filt_tindex_master.csv')\n",
    "topo_tindex_master =         pd.read_csv('s3://maap-ops-workspace/shared/nathanmthomas/DPS_tile_lists/Topo_tindex_master.csv')\n",
    "landsat_tindex_master =      pd.read_csv('s3://maap-ops-workspace/shared/nathanmthomas/DPS_tile_lists/Landsat_tindex_master.csv')\n",
    "\n",
    "# Convert al local_paths to s3\n",
    "#.. for data produced by 'lduncanson' workspace\n",
    "atl08_filt_tindex_master['https'] = [local_to_https_uswest2(local_path, user='lduncanson') for local_path in atl08_filt_tindex_master['local_path']]\n",
    "\n",
    "#.. for data produced by 'nathanmthomas' workspace\n",
    "for tindex_master in [topo_tindex_master, landsat_tindex_master]:\n",
    "    tindex_master['https'] = [local_to_https_uswest2(local_path, user='nathanmthomas') for local_path in tindex_master['local_path']]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "occupied-pepper",
   "metadata": {},
   "source": [
    "# Use the ATL08 filtered tindex master list to tell you which tiles you'll run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "tight-runner",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3968\n",
      "3940\n"
     ]
    }
   ],
   "source": [
    "INPUT_TILE_NUM_LIST = atl08_filt_tindex_master['tile_num'].values.astype(int).tolist()\n",
    "print(len(INPUT_TILE_NUM_LIST))\n",
    "\n",
    "# Remove duplicate tile nums\n",
    "INPUT_TILE_NUM_LIST = list(set(INPUT_TILE_NUM_LIST))\n",
    "\n",
    "print(len(INPUT_TILE_NUM_LIST))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "applicable-pocket",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "https://maap-ops-workspace.s3.us-west-2.amazonaws.com/lduncanson/dps_output/run_tile_atl08_ubuntu/master/2021/10/09/05/15/08/304917/atl08_004_30m_filt_topo_landsat_20211009_0009.csv\n",
      "https://maap-ops-workspace.s3.us-west-2.amazonaws.com/nathanmthomas/dps_output/do_topo_stack_3-1-5_ubuntu/ops/2021/09/15/18/10/34/658640/Copernicus_9_covars_cog_topo_stack.tif\n",
      "https://maap-ops-workspace.s3.us-west-2.amazonaws.com/nathanmthomas/dps_output/do_landsat_stack_3-1-2_ubuntu/ops/2021/09/14/19/20/02/503587/Landsat8_9_comp_cog_2015-2020_dps.tif\n"
     ]
    }
   ],
   "source": [
    "# Check retrieval of s3 path with a tle_num\n",
    "in_atl08_https =  atl08_filt_tindex_master['https'].loc[atl08_filt_tindex_master['tile_num'] == INPUT_TILE_NUM_LIST[0]].tolist()[0]\n",
    "in_topo_https = topo_tindex_master['https'].loc[topo_tindex_master['tile_num'] == INPUT_TILE_NUM_LIST[0]].tolist()[0]\n",
    "in_landsat_https = landsat_tindex_master['https'].loc[landsat_tindex_master['tile_num'] == INPUT_TILE_NUM_LIST[0]].tolist()[0]\n",
    "print(in_atl08_https)\n",
    "print(in_topo_https)\n",
    "print(in_landsat_https)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "broad-verse",
   "metadata": {},
   "source": [
    "## Get files for boreal biomass models & boreal wide sample\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "greatest-perth",
   "metadata": {},
   "outputs": [],
   "source": [
    "bio_models_https = 'https://s3.console.aws.amazon.com/s3/buckets/maap-ops-workspace/lduncanson/my-private-bucket/bio_models.tar'\n",
    "\n",
    "train_data_https = 'https://maap-ops-workspace.s3.us-west-2.amazonaws.com/lduncanson/boreal_train_data_v2.csv'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "committed-restriction",
   "metadata": {},
   "source": [
    "## Run a DPS job"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "dominican-denver",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DPS run num: 1, tile num: 9, job info: {'status': 'success', 'http_status_code': 200, 'job_id': '3f8a16ab-684a-4141-bf0a-27744ffd1d9f'}\n",
      "DPS job status: <Response [200]>\n",
      "DPS run num: 5, tile num: 17, job info: {'status': 'success', 'http_status_code': 200, 'job_id': '4c95fc86-2e4a-41d5-baf9-ed3b454cf889'}\n",
      "DPS job status: <Response [200]>\n",
      "DPS run num: 10, tile num: 25, job info: {'status': 'success', 'http_status_code': 200, 'job_id': 'dfa6e430-48d8-4953-b30e-f03c819c6212'}\n",
      "DPS job status: <Response [200]>\n",
      "DPS run num: 15, tile num: 30, job info: {'status': 'success', 'http_status_code': 200, 'job_id': 'de1808c4-d9b5-4f39-bdef-f814cd463699'}\n",
      "DPS job status: <Response [200]>\n",
      "DPS run num: 20, tile num: 37, job info: {'status': 'success', 'http_status_code': 200, 'job_id': 'aef94e86-b8b9-4228-9b14-a82345b5194a'}\n",
      "DPS job status: <Response [200]>\n",
      "DPS run num: 25, tile num: 42, job info: {'status': 'success', 'http_status_code': 200, 'job_id': 'e8eee4d3-0db6-49ce-b205-4e6103eae6aa'}\n",
      "DPS job status: <Response [200]>\n",
      "DPS run num: 50, tile num: 71, job info: {'status': 'success', 'http_status_code': 200, 'job_id': '3913b663-6979-4852-93ca-934e0aff108d'}\n",
      "DPS job status: <Response [200]>\n",
      "DPS run num: 75, tile num: 100, job info: {'status': 'success', 'http_status_code': 200, 'job_id': '178e7902-1cff-4c58-92b0-f51a27b02d90'}\n",
      "DPS job status: <Response [200]>\n",
      "DPS run num: 100, tile num: 128, job info: {'status': 'success', 'http_status_code': 200, 'job_id': '8fe75971-1ff0-4bc3-9bd6-c16b31b80cb3'}\n",
      "DPS job status: <Response [200]>\n",
      "DPS run num: 200, tile num: 237, job info: {'status': 'success', 'http_status_code': 200, 'job_id': 'af51c58d-b08d-41d8-9f69-b52a5865743d'}\n",
      "DPS job status: <Response [200]>\n",
      "DPS run num: 500, tile num: 597, job info: {'status': 'success', 'http_status_code': 200, 'job_id': '019b364e-966c-4cae-9395-5387ae16fed2'}\n",
      "DPS job status: <Response [200]>\n",
      "DPS run num: 1000, tile num: 1155, job info: {'status': 'success', 'http_status_code': 200, 'job_id': 'fa10d431-eec1-4bf8-b0fc-2093459d9294'}\n",
      "DPS job status: <Response [200]>\n",
      "DPS run num: 2000, tile num: 2300, job info: {'status': 'success', 'http_status_code': 200, 'job_id': '90560e8d-2c7f-41d0-a330-ad8962222228'}\n",
      "DPS job status: <Response [200]>\n",
      "DPS run num: 3000, tile num: 3327, job info: {'status': 'success', 'http_status_code': 200, 'job_id': 'b19afc8e-a363-4139-815f-8c52c3406043'}\n",
      "DPS job status: <Response [200]>\n",
      "DPS run num: 3500, tile num: 3845, job info: {'status': 'success', 'http_status_code': 200, 'job_id': '69243aa1-306a-4a18-9e70-617a2c43874e'}\n",
      "DPS job status: <Response [200]>\n",
      "DPS run num: 3940, tile num: 4546, job info: {'status': 'success', 'http_status_code': 200, 'job_id': 'b1b2e6da-5566-4aa4-83cf-5b8b4a21a508'}\n",
      "DPS job status: <Response [200]>\n"
     ]
    }
   ],
   "source": [
    "RUN_DPS  = True\n",
    "\n",
    "if RUN_DPS:\n",
    "    ##################################\n",
    "    #Test DPS submission on a single file\n",
    "    #for i, INPUT_TILE_NUM in enumerate(INPUT_TILE_NUM_LIST):\n",
    "    for i, INPUT_TILE_NUM in enumerate(INPUT_TILE_NUM_LIST):\n",
    "        DPS_num = i+1\n",
    "        \n",
    "        # Get the s3 paths of the corresponding input filenames with an input tile_num\n",
    "        in_atl08_https =  atl08_filt_tindex_master['https'].loc[atl08_filt_tindex_master['tile_num'] == INPUT_TILE_NUM].tolist()[0]\n",
    "        in_topo_https = topo_tindex_master['https'].loc[topo_tindex_master['tile_num'] == INPUT_TILE_NUM].tolist()[0]\n",
    "        in_landsat_https = landsat_tindex_master['https'].loc[landsat_tindex_master['tile_num'] == INPUT_TILE_NUM].tolist()[0]\n",
    "        \n",
    "        #print(in_atl08_https) \n",
    "        #print(in_topo_https)\n",
    "        #print(in_landsat_https)\n",
    "        \n",
    "        if True:\n",
    "            in_param_dict = {\n",
    "                                    'in_atl08_fn': f\"input/{os.path.basename(in_atl08_https)}\",\n",
    "                                    'in_topo_fn': f\"input/{os.path.basename(in_topo_https)}\",\n",
    "                                    'in_landsat_fn': f\"input/{os.path.basename(in_landsat_https)}\",\n",
    "                                    'in_atl08_fn_url': in_atl08_https,\n",
    "                                    'in_topo_fn_url': in_topo_https,\n",
    "                                    'in_landsat_fn_url': in_landsat_https,\n",
    "                                    'DO_SLOPE_VALID_MASK': 'TRUE',\n",
    "                                    'in_atl08_sample_fn':f\"input/{os.path.basename(train_data_https)}\",\n",
    "                                    'in_atl08_sample_url':train_data_https,\n",
    "                                    'in_tile_num': INPUT_TILE_NUM,\n",
    "                                    'in_tile_fn_url': 'https://maap-ops-workspace.s3.amazonaws.com/shared/nathanmthomas/boreal_grid_albers90k_gpkg.gpkg',\n",
    "                                    'in_tile_fn': 'input/boreal_grid_albers90k_gpkg.gpkg'\n",
    "                }\n",
    "\n",
    "            submit_result = maap.submitJob(\n",
    "                    identifier='run_boreal_biomass',\n",
    "                    algo_id='run_boreal_biomass_ubuntu',\n",
    "                    version='master',\n",
    "                    username='lduncanson', # username needs to be the same as whoever created the workspace\n",
    "                    queue='maap-dps-worker-32gb',\n",
    "                    **in_param_dict\n",
    "                )\n",
    "\n",
    "            #submit_result = 'submit test'\n",
    "            if DPS_num in [1, 5, 10, 15, 20, 25, 50, 75, 100,200, 500,1000,2000, 3000,3500, 4000, len(INPUT_TILE_NUM_LIST)]:\n",
    "                print(f\"DPS run num: {DPS_num}, tile num: {INPUT_TILE_NUM}, job info: {submit_result}\") \n",
    "                print(f\"DPS job status: {maap.getJobStatus(submit_result.get('job_id')) }\" )\n",
    "        else:\n",
    "            print(f\"Tile num: {INPUT_TILE_NUM}\")\n",
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "mental-proposal",
   "metadata": {},
   "source": [
    "## Get another list just of missing tiles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "concerned-ladder",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3953\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "3953"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "need_tindex_master = pd.read_csv('/projects/my-public-bucket/DPS_tile_lists/Need_AGB_tindex_master.csv')\n",
    "print(len(need_tindex_master))\n",
    "\n",
    "INPUT_TILE_NUM_LIST = need_tindex_master.tile_num.tolist()\n",
    "\n",
    "# Remove duplicate tile nums\n",
    "INPUT_TILE_NUM_LIST = list(set(INPUT_TILE_NUM_LIST))\n",
    "\n",
    "len(INPUT_TILE_NUM_LIST)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
