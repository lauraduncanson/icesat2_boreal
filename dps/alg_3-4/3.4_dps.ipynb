{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "hybrid-stations",
   "metadata": {},
   "outputs": [],
   "source": [
    "from maap.maap import MAAP\n",
    "maap = MAAP(maap_host='api.ops.maap-project.org')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "premier-stylus",
   "metadata": {},
   "source": [
    "# Launch DPS for mapBoreal.R"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "saving-conversation",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/projects/.local/lib/python3.7/site-packages/geopandas/_compat.py:110: UserWarning: The Shapely GEOS version (3.8.0-CAPI-1.13.1 ) is incompatible with the GEOS version PyGEOS was compiled with (3.9.1-CAPI-1.14.2). Conversions between both will be slow.\n",
      "  shapely_geos_version, geos_capi_version_string\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import geopandas\n",
    "import pandas as pd\n",
    "import json\n",
    "\n",
    "def local_to_s3(url, user='lduncanson'):\n",
    "    ''' A Function to convert local paths to s3 urls'''\n",
    "    return url.replace('/projects/my-private-bucket', f's3://maap-ops-workspace/{user}')\n",
    "def local_to_https(url, user='lduncanson'):\n",
    "    ''' A Function to convert local paths to https urls'''\n",
    "    return url.replace('/projects/my-private-bucket', f'https://s3.console.aws.amazon.com/s3/buckets/maap-ops-workspace/{user}')\n",
    "def local_to_https_uswest2(url, user='lduncanson'):\n",
    "    ''' A Function to convert local paths to https us-west-s urls'''\n",
    "    return url.replace('/projects/my-private-bucket', f'https://maap-ops-workspace.s3.us-west-2.amazonaws.com/{user}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "soviet-green",
   "metadata": {},
   "outputs": [],
   "source": [
    "atl08_filt_tindex_master =   pd.read_csv('s3://maap-ops-workspace/shared/lduncanson/DPS_tile_lists/ATL08_filt_tindex_master.csv')\n",
    "topo_tindex_master =         pd.read_csv('s3://maap-ops-workspace/shared/nathanmthomas/DPS_tile_lists/Topo_tindex_master.csv')\n",
    "landsat_tindex_master =      pd.read_csv('s3://maap-ops-workspace/shared/nathanmthomas/DPS_tile_lists/Landsat_tindex_master.csv')\n",
    "\n",
    "# Convert al local_paths to s3\n",
    "#.. for data produced by 'lduncanson' workspace\n",
    "atl08_filt_tindex_master['https'] = [local_to_https_uswest2(local_path, user='lduncanson') for local_path in atl08_filt_tindex_master['local_path']]\n",
    "\n",
    "#.. for data produced by 'nathanmthomas' workspace\n",
    "for tindex_master in [topo_tindex_master, landsat_tindex_master]:\n",
    "    tindex_master['https'] = [local_to_https_uswest2(local_path, user='nathanmthomas') for local_path in tindex_master['local_path']]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "growing-catch",
   "metadata": {},
   "source": [
    "# Use the ATL08 filtered tindex master list to tell you which tiles you'll run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "quality-arizona",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "106\n",
      "[42, 199, 200, 223, 224, 386, 387, 11, 49, 111, 112, 131]\n",
      "106\n",
      "12\n"
     ]
    }
   ],
   "source": [
    "INPUT_TILE_NUM_LIST = atl08_filt_tindex_master['tile_num'].values.astype(int).tolist()\n",
    "print(len(INPUT_TILE_NUM_LIST))\n",
    "\n",
    "# Remove duplicate tile nums\n",
    "INPUT_TILE_NUM_LIST = list(set(INPUT_TILE_NUM_LIST))\n",
    "\n",
    "# Filter to only tiles of interest\n",
    "TEST_INPUT_TILE_NUM_LIST = [42, 199, 200, 223, 224, 386, 387, 11, 49, 111, 112, 131]\n",
    "#TEST_INPUT_TILE_NUM_LIST = [49]\n",
    "\n",
    "print(TEST_INPUT_TILE_NUM_LIST)\n",
    "print(len(INPUT_TILE_NUM_LIST))\n",
    "\n",
    "#for test, set\n",
    "INPUT_TILE_NUM_LIST = TEST_INPUT_TILE_NUM_LIST\n",
    "print(len(INPUT_TILE_NUM_LIST))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "dated-chicken",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "https://maap-ops-workspace.s3.us-west-2.amazonaws.com/lduncanson/dps_output/run_tile_atl08_ubuntu/master/2022/02/08/20/54/44/327852/atl08_004_30m_filt_topo_landsat_20220208_0042.csv\n",
      "https://maap-ops-workspace.s3.us-west-2.amazonaws.com/nathanmthomas/dps_output/do_topo_stack_3-1-5_ubuntu/ops/2021/09/15/18/18/44/208345/Copernicus_42_covars_cog_topo_stack.tif\n",
      "https://maap-ops-workspace.s3.us-west-2.amazonaws.com/nathanmthomas/dps_output/do_landsat_stack_3-1-2_ubuntu/ops/2021/09/14/19/10/42/604491/Landsat8_42_comp_cog_2015-2020_dps.tif\n"
     ]
    }
   ],
   "source": [
    "# Check retrieval of s3 path with a tle_num\n",
    "in_atl08_https =  atl08_filt_tindex_master['https'].loc[atl08_filt_tindex_master['tile_num'] == INPUT_TILE_NUM_LIST[0]].tolist()[0]\n",
    "in_topo_https = topo_tindex_master['https'].loc[topo_tindex_master['tile_num'] == INPUT_TILE_NUM_LIST[0]].tolist()[0]\n",
    "in_landsat_https = landsat_tindex_master['https'].loc[landsat_tindex_master['tile_num'] == INPUT_TILE_NUM_LIST[0]].tolist()[0]\n",
    "print(in_atl08_https)\n",
    "print(in_topo_https)\n",
    "print(in_landsat_https)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "contemporary-weekend",
   "metadata": {},
   "source": [
    "## Get files for boreal biomass models & boreal wide sample\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "foster-portfolio",
   "metadata": {},
   "outputs": [],
   "source": [
    "bio_models_https = 'https://s3.console.aws.amazon.com/s3/buckets/maap-ops-workspace/lduncanson/my-private-bucket/bio_models.tar'\n",
    "\n",
    "train_data_https = 'https://maap-ops-workspace.s3.us-west-2.amazonaws.com/lduncanson/boreal_train_data_v3.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "physical-mustang",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "invalid-infrared",
   "metadata": {},
   "source": [
    "## Test from Terminal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "combined-times",
   "metadata": {},
   "outputs": [],
   "source": [
    "# put latest test data in a test folder (outside repo)\n",
    "# Terminal:\n",
    "                           \n",
    "# file 1: /projects/testing/input/atl08_004_30m_filt_topo_landsat_20220208_0042.csv\n",
    "# file 2: /projects/shared-buckets/nathanmthomas/alg_34_testing/Copernicus_42_covars_cog_topo_stack.tif\n",
    "# file 3: /projects/shared-buckets/nathanmthomas/alg_34_testing/Landsat8_42_comp_cog_2015-2020_dps.tif\n",
    "#file 4: /projects/my-private-bucket/boreal_train_data_v3.csv\n",
    "#file 5: /projects/my-private-bucket/bio_models.tar\n",
    "#file 6: 42\n",
    "# file 7:\n",
    "\n",
    "# ./run_boreal_biomass.sh file1 file2 file3 file4 file5 file6 file7\n",
    "#ATL08_CSV= /projects/testing/input/atl08_004_30m_filt_topo_landsat_20220208_0042.csv\n",
    "#TOPO_TIF=/projects/shared-buckets/nathanmthomas/alg_34_testing/Copernicus_42_covars_cog_topo_stack.tif\n",
    "#LANDSAT_TIF= /projects/shared-buckets/nathanmthomas/alg_34_testing/Landsat8_42_comp_cog_2015-2020_dps.tif\n",
    "#DO_SLOPE_VALID_MASK= 'TRUE'\n",
    "#ATL08_SAMPLE_CSV=/projects/my-private-bucket/boreal_train_data_v3.csv\n",
    "#in_tile_num=42\n",
    "#in_tile_fn=/projects/shared-buckets/nathanmthomas/boreal_grid_albers90k_gpkg.gpkg\n",
    "\n",
    "#python /projects/icesat2_boreal/dps/alg_3-4/merge_neighbors_atl08.py -in_tile_num 42 -in_tile_fn /projects/shared-buckets/nathanmthomas/boreal_grid_albers90k_gpkg.gpkg -in_tile_field layer -csv_list_fn s3://maap-ops-workspace/shared/lduncanson/DPS_tile_lists/ATL08_filt_tindex_master.csv -out_dir /projects/testing/output/\n",
    "#echo $cmd\n",
    "#eval $cmd\n",
    "\n",
    "# Set the output merged CSV name to a var\n",
    "#MERGED_ATL08_CSV=$(ls ${OUTPUTDIR}/atl08_004_30m_filt_merge_neighbors* | head -1)\n",
    "\n",
    "# Run mapBoreal with merged CSV as input\n",
    "#conda activate r-with-gdal\n",
    "#Rscript /projects/icesat2_boreal/dps/alg_3-4/mapBoreal.R /projects/testing/output/atl08_004_30m_filt_merge_neighbors_0042.csv /projects/shared-buckets/nathanmthomas/alg_34_testing/Copernicus_42_covars_cog_topo_stack.tif /projects/shared-buckets/nathanmthomas/alg_34_testing/Landsat8_42_comp_cog_2015-2020_dps.tif 'TRUE' /projects/my-private-bucket/boreal_train_data_v3.csv\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "varying-output",
   "metadata": {},
   "source": [
    "## Run a DPS job"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "expanded-lotus",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DPS run num: 1, tile num: 42, job info: {'status': 'success', 'http_status_code': 200, 'job_id': '8e6e5c8d-a39c-493e-bec0-db5dfc35a58f'}\n",
      "DPS job status: <Response [200]>\n",
      "DPS run num: 2, tile num: 199, job info: {'status': 'success', 'http_status_code': 200, 'job_id': '36b33d1e-95a2-41ba-b685-d2578292171f'}\n",
      "DPS job status: <Response [200]>\n",
      "DPS run num: 3, tile num: 200, job info: {'status': 'success', 'http_status_code': 200, 'job_id': 'b62a5911-9733-4013-a79d-69b6023a3449'}\n",
      "DPS job status: <Response [200]>\n",
      "DPS run num: 4, tile num: 223, job info: {'status': 'success', 'http_status_code': 200, 'job_id': '93882a9c-621a-4920-b68f-831eee928471'}\n",
      "DPS job status: <Response [200]>\n",
      "DPS run num: 5, tile num: 224, job info: {'status': 'success', 'http_status_code': 200, 'job_id': '5f72ff09-ac90-433f-a9ec-d63456f630e7'}\n",
      "DPS job status: <Response [200]>\n",
      "DPS run num: 6, tile num: 386, job info: {'status': 'success', 'http_status_code': 200, 'job_id': '0b7e8d02-877e-4510-9ede-8a3faf289022'}\n",
      "DPS job status: <Response [200]>\n",
      "DPS run num: 7, tile num: 387, job info: {'status': 'success', 'http_status_code': 200, 'job_id': 'b5b19b37-a991-4ac6-9270-83d1888b6d7b'}\n",
      "DPS job status: <Response [200]>\n",
      "DPS run num: 8, tile num: 11, job info: {'status': 'success', 'http_status_code': 200, 'job_id': '30411bf8-8f73-44be-a4ad-0808b1a8c150'}\n",
      "DPS job status: <Response [200]>\n",
      "DPS run num: 9, tile num: 49, job info: {'status': 'success', 'http_status_code': 200, 'job_id': '8029b043-3bb7-404e-b6a5-49c1253d6f31'}\n",
      "DPS job status: <Response [200]>\n",
      "DPS run num: 10, tile num: 111, job info: {'status': 'success', 'http_status_code': 200, 'job_id': '72b48153-b139-4d12-96f4-3e05856471b5'}\n",
      "DPS job status: <Response [200]>\n",
      "DPS run num: 12, tile num: 131, job info: {'status': 'success', 'http_status_code': 200, 'job_id': 'f33dd2d9-d618-4d9a-94b1-2862396c328b'}\n",
      "DPS job status: <Response [200]>\n"
     ]
    }
   ],
   "source": [
    "RUN_DPS  = True\n",
    "\n",
    "if RUN_DPS:\n",
    "    ##################################\n",
    "    #Test DPS submission on a single file\n",
    "    #for i, INPUT_TILE_NUM in enumerate(INPUT_TILE_NUM_LIST):\n",
    "    for i, INPUT_TILE_NUM in enumerate(INPUT_TILE_NUM_LIST):\n",
    "        DPS_num = i+1\n",
    "        \n",
    "        # Get the s3 paths of the corresponding input filenames with an input tile_num\n",
    "        in_atl08_https =  atl08_filt_tindex_master['https'].loc[atl08_filt_tindex_master['tile_num'] == INPUT_TILE_NUM].tolist()[0]\n",
    "        in_topo_https = topo_tindex_master['https'].loc[topo_tindex_master['tile_num'] == INPUT_TILE_NUM].tolist()[0]\n",
    "        in_landsat_https = landsat_tindex_master['https'].loc[landsat_tindex_master['tile_num'] == INPUT_TILE_NUM].tolist()[0]\n",
    "        \n",
    "        #print(in_atl08_https) \n",
    "        #print(in_topo_https)\n",
    "        #print(in_landsat_https)\n",
    "        \n",
    "        if True:\n",
    "            in_param_dict = {\n",
    "                                    'in_atl08_fn': f\"input/{os.path.basename(in_atl08_https)}\",\n",
    "                                    'in_topo_fn': f\"input/{os.path.basename(in_topo_https)}\",\n",
    "                                    'in_landsat_fn': f\"input/{os.path.basename(in_landsat_https)}\",\n",
    "                                    'in_atl08_fn_url': in_atl08_https,\n",
    "                                    'in_topo_fn_url': in_topo_https,\n",
    "                                    'in_landsat_fn_url': in_landsat_https,\n",
    "                                    'DO_SLOPE_VALID_MASK': 'TRUE',\n",
    "                                    'in_atl08_sample_fn':f\"input/{os.path.basename(train_data_https)}\",\n",
    "                                    'in_atl08_sample_url':train_data_https,\n",
    "                                    'in_tile_num': INPUT_TILE_NUM,\n",
    "                                    'in_tile_fn_url': 'https://maap-ops-workspace.s3.amazonaws.com/shared/nathanmthomas/boreal_grid_albers90k_gpkg.gpkg',\n",
    "                                    'in_tile_fn': 'input/boreal_grid_albers90k_gpkg.gpkg'\n",
    "                }\n",
    "\n",
    "            submit_result = maap.submitJob(\n",
    "                    identifier='run_boreal_biomass',\n",
    "                    algo_id='run_boreal_biomass_v2_ubuntu',\n",
    "                    version='master',\n",
    "                    username='lduncanson', # username needs to be the same as whoever created the workspace\n",
    "                    queue='maap-dps-worker-32gb',\n",
    "                    **in_param_dict\n",
    "                )\n",
    "\n",
    "            #submit_result = 'submit test'\n",
    "            if DPS_num in [1,2, 3, 4, 5,6, 7, 8, 9, 10, 15, 20, 25, 50, 75, 100,200, 500,1000,2000, 3000,3500, 4000, len(INPUT_TILE_NUM_LIST)]:\n",
    "                print(f\"DPS run num: {DPS_num}, tile num: {INPUT_TILE_NUM}, job info: {submit_result}\") \n",
    "                print(f\"DPS job status: {maap.getJobStatus(submit_result.get('job_id')) }\" )\n",
    "        else:\n",
    "            print(f\"Tile num: {INPUT_TILE_NUM}\")\n",
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "funny-entry",
   "metadata": {},
   "source": [
    "## Get other lists just of missing tiles (various ways)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "better-twins",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "19\n",
      "7\n"
     ]
    }
   ],
   "source": [
    "need_tindex_master = pd.read_csv('/projects/my-public-bucket/DPS_tile_lists/Need_AGB_tindex_master.csv')\n",
    "print(len(need_tindex_master))\n",
    "\n",
    "INPUT_TILE_NUM_LIST = need_tindex_master.tile_num.tolist()\n",
    "\n",
    "# Remove duplicate tile nums\n",
    "INPUT_TILE_NUM_LIST = list(set(INPUT_TILE_NUM_LIST))\n",
    "\n",
    "print(len(INPUT_TILE_NUM_LIST))\n",
    "\n",
    "INPUT_TILE_NUM_LIST_NEED = INPUT_TILE_NUM_LIST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "packed-joshua",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "11"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "weird_tiles = [4304, 4305, 4221, 4220, 1785, 1718, 1720, 1661, 1257, 1318, 1317]\n",
    "werid_tiles = [1255, 1196, 949, 1062, 1063, 1005, 950, 1004]\n",
    "INPUT_TILE_NUM_LIST = weird_tiles\n",
    "len(INPUT_TILE_NUM_LIST)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "broad-preserve",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "45\n",
      "[978, 988, 978, 988, 1263, 1261, 1264, 794, 2932, 3190, 3012, 3014, 3360, 3017, 378, 765, 812, 821, 764, 861, 1302, 1308, 1469, 2894, 2883, 2965, 2976, 3327, 3321, 3510, 3509, 4372, 4440, 4477, 2994, 1406, 2840, 411, 380, 3335, 2495, 4403, 2906, 2907, 2814]\n"
     ]
    }
   ],
   "source": [
    "# Get all boreal tiles\n",
    "ATL08_filt_tindex_master =   pd.read_csv('s3://maap-ops-workspace/shared/lduncanson/DPS_tile_lists/ATL08_filt_tindex_master.csv')\n",
    "boreal_tile_index_path = '/projects/shared-buckets/nathanmthomas/boreal_grid_albers90k_gpkg.gpkg'\n",
    "boreal_tile_index = geopandas.read_file(boreal_tile_index_path)\n",
    "boreal_tile_index.rename(columns={\"layer\":\"tile_num\"}, inplace=True)\n",
    "boreal_tile_index[\"tile_num\"] = boreal_tile_index[\"tile_num\"].astype(int)\n",
    "\n",
    "bad_tiles = [3540,3634,3728,3823,3916,4004] #Dropping the tiles near antimeridian that reproject poorly.\n",
    "select_needs = [3360,2994,3190,2840,3012,3014,3017,2932,1261,1263,1264,988,978,794, 380,378,411,821,861,\n",
    "                812,765,764,1308,1302,1469,1406,2495,2883,2965,3321,3509,3510,3327,3335,2976,2906,2907,2894,2814,4253,4293,4403,4440,4408,4372,4477,3986]\n",
    "\n",
    "# Remove bad tiles\n",
    "boreal_tile_index = boreal_tile_index[~boreal_tile_index['tile_num'].isin(bad_tiles)]\n",
    "    \n",
    "#print(boreal_tile_index.head())\n",
    "tile_matches_select_needs = boreal_tile_index.merge(ATL08_filt_tindex_master[ATL08_filt_tindex_master['tile_num'].isin(select_needs)], how='right', on='tile_num')\n",
    "print(len(tile_matches_select_needs))\n",
    "select_needs_filt = print([t for t in tile_matches_select_needs.tile_num])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "upset-decade",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "45\n",
      "4\n",
      "[3986 4253 4293 4408]\n",
      "70\n",
      "[  65  106  127  250  361  417  493  566  568  618  741  753  786  798\n",
      "  801  830  848  876  877  927 1273 1287 1318 1402 1438 1439 1440 1604\n",
      " 1848 1850 1852 1936 2425 2426 2952 3124 3355 3540 3542 3634 3728 3823\n",
      " 3845 3846 3895 3916 4004 4007 4018 4083 4176 4204 4250 4256 4307 4325\n",
      " 4342 4395 4417 4444 4450 4451 4463 4467 4468 4483 4499 4510 4527 4534]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "70"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#select_needs_filt = [978, 988, 978, 988, 1263, 1261, 1264, 794, 2932, 3190, 3012, 3014, 3360, 3017, 378, 765, 812, 821, 764, 861, 1302, 1308, 1469, 2894, 2883, 2965, 2976, 3327, 3321, 3510, 3509, 4372, 4440, 4477, 2994, 1406, 2840, 411, 380, 3335, 2495, 4403, 2906, 2907, 2814]\n",
    "\n",
    "print(len(select_needs_filt))\n",
    "\n",
    "import numpy as np\n",
    "tile_nums_missing_but_wont_run = np.setdiff1d(select_needs, select_needs_filt)\n",
    "print(len(tile_nums_missing_but_wont_run))\n",
    "print(tile_nums_missing_but_wont_run)\n",
    "\n",
    "tile_nums_missing_periphery = np.setdiff1d(INPUT_TILE_NUM_LIST_NEED, select_needs_filt)\n",
    "print(len(tile_nums_missing_periphery))\n",
    "print(tile_nums_missing_periphery)\n",
    "INPUT_TILE_NUM_LIST = tile_nums_missing_periphery\n",
    "len(INPUT_TILE_NUM_LIST)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "cross-binding",
   "metadata": {},
   "outputs": [],
   "source": [
    "INPUT_TILE_NUM_LIST = [4440,4372,4477]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "developed-throat",
   "metadata": {},
   "source": [
    "## Send output cog.tif tiles somewhere"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "usual-manufacturer",
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "out_files = glob.glob(\"/projects/my-private-bucket/dps_output/run_boreal_biomass_ubuntu/master/2022/02/baseline_run/**/*cog.tif\", recursive=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "worst-orlando",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['/projects/my-private-bucket/dps_output/run_boreal_biomass_ubuntu/master/2022/02/baseline_run/02/23/49/35/272239/boreal_agb_20220202_0200_cog.tif', '/projects/my-private-bucket/dps_output/run_boreal_biomass_ubuntu/master/2022/02/baseline_run/03/01/42/37/290043/boreal_agb_20220203_0224_cog.tif', '/projects/my-private-bucket/dps_output/run_boreal_biomass_ubuntu/master/2022/02/baseline_run/03/01/52/46/430279/boreal_agb_20220203_0387_cog.tif', '/projects/my-private-bucket/dps_output/run_boreal_biomass_ubuntu/master/2022/02/baseline_run/03/02/21/50/348844/boreal_agb_20220203_0386_cog.tif', '/projects/my-private-bucket/dps_output/run_boreal_biomass_ubuntu/master/2022/02/baseline_run/03/03/01/42/237812/boreal_agb_20220203_0199_cog.tif', '/projects/my-private-bucket/dps_output/run_boreal_biomass_ubuntu/master/2022/02/baseline_run/03/03/06/47/336472/boreal_agb_20220203_0223_cog.tif', '/projects/my-private-bucket/dps_output/run_boreal_biomass_ubuntu/master/2022/02/baseline_run/03/03/08/52/152954/boreal_agb_20220203_0042_cog.tif', '/projects/my-private-bucket/dps_output/run_boreal_biomass_ubuntu/master/2022/02/baseline_run/03/06/47/53/128079/boreal_agb_20220203_0111_cog.tif', '/projects/my-private-bucket/dps_output/run_boreal_biomass_ubuntu/master/2022/02/baseline_run/03/06/59/17/037689/boreal_agb_20220203_0112_cog.tif', '/projects/my-private-bucket/dps_output/run_boreal_biomass_ubuntu/master/2022/02/baseline_run/03/07/25/06/085526/boreal_agb_20220203_0049_cog.tif']\n"
     ]
    }
   ],
   "source": [
    "print(out_files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "welsh-tours",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
