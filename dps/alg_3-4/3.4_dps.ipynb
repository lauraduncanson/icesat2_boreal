{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "helpful-event",
   "metadata": {},
   "outputs": [],
   "source": [
    "from maap.maap import MAAP\n",
    "maap = MAAP(maap_host='api.ops.maap-project.org')\n",
    "#!pip install -U -r /projects/icesat2_boreal/dps/requirements_main.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "editorial-house",
   "metadata": {},
   "source": [
    "# Launch DPS for mapBoreal.R"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "cross-massachusetts",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: xmltodict in /opt/conda/lib/python3.7/site-packages (0.13.0)\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: You are using pip version 22.0.3; however, version 22.3.1 is available.\n",
      "You should consider upgrading via the '/opt/conda/bin/python -m pip install --upgrade pip' command.\u001b[0m\u001b[33m\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import geopandas\n",
    "import pandas as pd\n",
    "import json\n",
    "import datetime\n",
    "!pip install xmltodict\n",
    "import xmltodict\n",
    "\n",
    "def local_to_s3(url, user='lduncanson'):\n",
    "    ''' A Function to convert local paths to s3 urls'''\n",
    "    return url.replace('/projects/my-private-bucket', f's3://maap-ops-workspace/{user}')\n",
    "def local_to_https(url, user='lduncanson'):\n",
    "    ''' A Function to convert local paths to https urls'''\n",
    "    return url.replace('/projects/my-private-bucket', f'https://s3.console.aws.amazon.com/s3/buckets/maap-ops-workspace/{user}')\n",
    "def local_to_https_uswest2(url, user='lduncanson'):\n",
    "    ''' A Function to convert local paths to https us-west-s urls'''\n",
    "    return url.replace('/projects/my-private-bucket', f'https://maap-ops-workspace.s3.us-west-2.amazonaws.com/{user}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "previous-driving",
   "metadata": {},
   "outputs": [],
   "source": [
    "#atl08_filt_tindex_master =   pd.read_csv('s3://maap-ops-workspace/lduncanson/dps_output/run_tile_atl08_ubuntu/master/2022/03/ATL08_filt_tindex_master.csv')\n",
    "\n",
    "#atl08_filt_tindex_master =   pd.read_csv('s3://maap-ops-workspace/shared/nathanmthomas/DPS_tile_lists/ATL08_filt_tindex_master.csv')\n",
    "#my-public-bucket/DPS_tile_lists/fall2022/ATL08_filt_tindex_master.csv\n",
    "atl08_filt_tindex_master =   pd.read_csv('/projects/shared-buckets/lduncanson/DPS_tile_lists/fall2022/ATL08_filt_tindex_master.csv')\n",
    "topo_tindex_master =         pd.read_csv('/projects/shared-buckets/nathanmthomas/DPS_tile_lists/Topo_tindex_master.csv')\n",
    "landsat_tindex_master =      pd.read_csv('/projects/shared-buckets/nathanmthomas/DPS_tile_lists/HLS/fall2022/HLS_stack_2022_v2/HLS_tindex_master.csv')\n",
    "lc_tindex_master = pd.read_csv('/projects/shared-buckets/nathanmthomas/DPS_tile_lists/09/LC_tindex_master.csv')\n",
    "\n",
    "\n",
    "# Convert al local_paths to s3\n",
    "#.. for data produced by 'lduncanson' workspace\n",
    "atl08_filt_tindex_master['https'] = [local_to_https_uswest2(local_path, user='lduncanson') for local_path in atl08_filt_tindex_master['local_path']]\n",
    "\n",
    "#.. for data produced by 'nathanmthomas' workspace\n",
    "for tindex_master in [topo_tindex_master, landsat_tindex_master, lc_tindex_master]:\n",
    "    tindex_master['https'] = [local_to_https_uswest2(local_path, user='nathanmthomas') for local_path in tindex_master['local_path']]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "hollywood-clause",
   "metadata": {},
   "source": [
    "# Use the ATL08 filtered tindex master list to tell you which tiles you'll run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "wireless-consortium",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "127\n",
      "4881\n"
     ]
    }
   ],
   "source": [
    "\n",
    "NORWAY_TILE_LIST = pd.read_csv('/projects/my-public-bucket/misc_files/norway_tiles.csv').layer.tolist()\n",
    "\n",
    "#NORWAY_TILE_LIST = [42,199,200,223,224,386,387,11,49,111,112,131]\n",
    "\n",
    "DELTA_TILE_LIST = [3459]\n",
    "\n",
    "BONA_TILE_LIST  = [3364,3365]\n",
    "\n",
    "HEALY_TILE_LIST = [3552]\n",
    "\n",
    "INPUT_EXPERIMENT_TILE_NUM_LIST = NORWAY_TILE_LIST + DELTA_TILE_LIST + BONA_TILE_LIST + HEALY_TILE_LIST\n",
    "#INPUT_EXPERIMENT_TILE_NUM_LIST = NORWAY_TILE_LIST\n",
    "#DPS_INPUT_TILE_NUM_LIST = INPUT_EXPERIMENT_TILE_NUM_LIST\n",
    "#len(DPS_INPUT_TILE_NUM_LIST)\n",
    "\n",
    "#ALASKA_TILE_LIST =  list(range(3268,3272+1))+\\\n",
    "#                    list(range(3361,3366+1))+\\\n",
    "#                    list(range(3454,3459+1))+\\\n",
    "#                    list(range(3549,3555+1))+\\\n",
    "#                    list(range(3643,3648+1))\n",
    "\n",
    "INPUT_EXPERIMENT_TILE_NUM_LIST = NORWAY_TILE_LIST + DELTA_TILE_LIST + BONA_TILE_LIST + HEALY_TILE_LIST\n",
    "print(len(INPUT_EXPERIMENT_TILE_NUM_LIST))\n",
    "DPS_INPUT_TILE_NUM_LIST = INPUT_EXPERIMENT_TILE_NUM_LIST\n",
    "\n",
    "FULL_TILE_LIST = atl08_filt_tindex_master['tile_num']\n",
    "\n",
    "DPS_INPUT_TILE_NUM_LIST = [639, 640, 726, 727, 373, 405]\n",
    "\n",
    "DPS_INPUT_TILE_NUM_LIST = FULL_TILE_LIST\n",
    "DPS_INPUT_TILE_NUM_LIST = [3082,2918, 1854, 1789, 1262,34210, 33975,37,148,169,446,162,629,1761, 2651, 2970, 3604, 4080]\n",
    "DPS_INPUT_TILE_NUM_LIST = [1050, 1105, 34210, 4245, 24959, 23828]\n",
    "DPS_INPUT_TILE_NUM_LIST = INPUT_EXPERIMENT_TILE_NUM_LIST\n",
    "\n",
    "DPS_INPUT_TILE_NUM_LIST = [639, 640, 726, 727, 373, 405, 42]\n",
    "\n",
    "DPS_INPUT_TILE_NUM_LIST = FULL_TILE_LIST\n",
    "\n",
    "\n",
    "\n",
    "print(len(DPS_INPUT_TILE_NUM_LIST))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "southeast-equipment",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "https://maap-ops-workspace.s3.us-west-2.amazonaws.com/lduncanson/dps_output/run_tile_atl08_ubuntu/tile_atl08/2022/10/28/15/35/23/844340/atl08_005_30m_filt_topo_landsat_20221028_37077.csv\n",
      "https://maap-ops-workspace.s3.us-west-2.amazonaws.com/nathanmthomas/dps_output/do_topo_stack_3-1-5_ubuntu/master/2022/03/21/14/34/11/573782/Copernicus_37077_covars_cog_topo_stack.tif\n",
      "https://maap-ops-workspace.s3.us-west-2.amazonaws.com/nathanmthomas/dps_output/do_HLS_stack_3-1-2_ubuntu/HLS_stack_2022_v2/2022/10/18/17/39/09/607785/HLS_37077_06-01_09-15_2019_2021.tif\n",
      "https://maap-ops-workspace.s3.us-west-2.amazonaws.com/nathanmthomas/dps_output/run_build_stack_ubuntu/master/2022/09/15/17/20/27/167470/esa_worldcover_v100_2020_37077_cog.tif\n"
     ]
    }
   ],
   "source": [
    "# Check retrieval of s3 path with a tle_num\n",
    "in_atl08_https =  atl08_filt_tindex_master['https'].loc[atl08_filt_tindex_master['tile_num'] == DPS_INPUT_TILE_NUM_LIST[0]].tolist()[0]\n",
    "in_topo_https = topo_tindex_master['https'].loc[topo_tindex_master['tile_num'] == DPS_INPUT_TILE_NUM_LIST[0]].tolist()[0]\n",
    "in_landsat_https = landsat_tindex_master['https'].loc[landsat_tindex_master['tile_num'] == DPS_INPUT_TILE_NUM_LIST[0]].tolist()[0]\n",
    "in_lc_https = lc_tindex_master['https'].loc[lc_tindex_master['tile_num'] == DPS_INPUT_TILE_NUM_LIST[0]].tolist()[0]\n",
    "\n",
    "print(in_atl08_https)\n",
    "print(in_topo_https)\n",
    "print(in_landsat_https)\n",
    "print(in_lc_https)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "constitutional-piano",
   "metadata": {},
   "source": [
    "## Get files for boreal biomass models & boreal wide sample\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "empty-mills",
   "metadata": {},
   "outputs": [],
   "source": [
    "bio_models_https = 'https://s3.console.aws.amazon.com/s3/buckets/maap-ops-workspace/lduncanson/my-private-bucket/bio_models.tar'\n",
    "\n",
    "train_data_https = 'https://maap-ops-workspace.s3.us-west-2.amazonaws.com/lduncanson/boreal_train_data_v8.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "marine-generator",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'https://s3.console.aws.amazon.com/s3/buckets/maap-ops-workspace/lduncanson/my-private-bucket/bio_models.tar'"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bio_models_https"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "romantic-nitrogen",
   "metadata": {},
   "source": [
    "## Test from Terminal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "occupational-melbourne",
   "metadata": {},
   "outputs": [],
   "source": [
    "# put latest test data in a test folder (outside repo)\n",
    "# Terminal:\n",
    "                           \n",
    "# file 1: /projects/testing/input/atl08_004_30m_filt_topo_landsat_20220208_0042.csv\n",
    "# file 2: /projects/shared-buckets/nathanmthomas/alg_34_testing/Copernicus_42_covars_cog_topo_stack.tif\n",
    "# file 3: /projects/shared-buckets/nathanmthomas/alg_34_testing/Landsat8_42_comp_cog_2015-2020_dps.tif\n",
    "#file 4: /projects/my-private-bucket/boreal_train_data_v3.csv\n",
    "#file 5: /projects/my-private-bucket/bio_models.tar\n",
    "#file 6: 42\n",
    "# file 7:\n",
    "\n",
    "# ./run_boreal_biomass.sh file1 file2 file3 file4 file5 file6 file7\n",
    "#ATL08_CSV= /projects/testing/input/atl08_005_30m_filt_topo_landsat_20220322_0042.csv\n",
    "#TOPO_TIF=/projects/shared-buckets/nathanmthomas/alg_34_testing/Copernicus_42_covars_cog_topo_stack.tif\n",
    "#LANDSAT_TIF= /projects/shared-buckets/nathanmthomas/alg_34_testing/Landsat8_42_comp_cog_2015-2020_dps.tif\n",
    "#DO_SLOPE_VALID_MASK= 'TRUE'\n",
    "#ATL08_SAMPLE_CSV=/projects/my-private-bucket/boreal_train_data_v3.csv\n",
    "#in_tile_num=42\n",
    "#in_tile_fn=/projects/shared-buckets/nathanmthomas/boreal_grid_albers90k_gpkg.gpkg\n",
    "\n",
    "#python /projects/icesat2_boreal/lib/merge_neighbors_atl08.py -in_tile_num 42 -in_tile_fn /projects/shared-buckets/nathanmthomas/boreal_tiles_v003.gpkg -in_tile_field 'tile_num' -csv_list_fn s3://maap-ops-workspace/shared/lduncanson/DPS_tile_lists/ATL08_filt_tindex_master.csv -out_dir /projects/testing/output/\n",
    "#echo $cmd\n",
    "#eval $cmd\n",
    "\n",
    "# Set the output merged CSV name to a var\n",
    "#MERGED_ATL08_CSV=$(ls ${OUTPUTDIR}/atl08_005_30m_filt_merge_neighbors* | head -1)\n",
    "\n",
    "# Run mapBoreal with merged CSV as input\n",
    "#conda activate r-with-gdal\n",
    "\n",
    "\n",
    "#Rscript /projects/icesat2_boreal/lib/mapBoreal.R /projects/testing/output/atl08_004_30m_filt_merge_neighbors_0042.csv /projects/shared-buckets/nathanmthomas/alg_34_testing/Copernicus_42_covars_cog_topo_stack.tif /projects/shared-buckets/nathanmthomas/alg_34_testing/HLS_42_06-01_09-15_2019_2021.tif 'TRUE' /projects/my-private-bucket/boreal_train_data_v4.csv 2 2 100 300 5 TRUE 50 3000 \n",
    "\n",
    "#test swapping for terra\n",
    "#Rscript /projects/icesat2_boreal/lib/mapBoreal_speedy.R /projects/testing/output/atl08_004_30m_filt_merge_neighbors_0042.csv /projects/shared-buckets/nathanmthomas/alg_34_testing/Copernicus_42_covars_cog_topo_stack.tif /projects/shared-buckets/nathanmthomas/alg_34_testing/HLS_42_06-01_09-15_2019_2021.tif 'TRUE' /projects/my-private-bucket/boreal_train_data_v4.csv 3 2 100 300 5 TRUE 100 3000 /projects/shared-buckets/nathanmthomas/analyze_agb/input_zones/wwf_circumboreal_Dissolve_reprj.geojson \n",
    "\n",
    "# of tiles to run: 115\n",
    "# [3585, 4108, 1037, 28176, 4112, 31762, 1050, 2075, 28702, 31263, 29223, 29739, 30252, 3117, 30763, 3120, 2614, 2618, 2619, 1615, 1105, 1617, 2142, 612, 2148, 2149, 2151, 2152, 2153, 1146, 1662, 1159, 1672, 2698, 34443, 26280, 2217, 2223, 2224, 33975, 1721, 3770, 3771, 1214, 1731, 1733, 26827, 2779, 3301, 3302, 27368, 745, 3307, 1273, 2301, 27908, 1798, 1799, 1800, 3861, 28440, 3865, 31513, 28963, 31014, 29481, 2859, 29996, 30508, 1334, 4411, 3393, 3395, 2375, 3399, 1865, 1866, 1867, 2378, 2379, 2380, 2381, 3400, 3951, 3952, 34674, 3954, 2942, 895, 2944, 1933, 1934, 1937, 1938, 2457, 3486, 34210, 931, 1448, 26554, 4034, 4035, 1999, 981, 3029, 3030, 2009, 2010, 2011, 27098, 991, 992, 993, 2533, 27638]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "vertical-proceeding",
   "metadata": {},
   "outputs": [],
   "source": [
    "# test of tile 1927\n",
    "#ATL08_CSV= /projects/testing/input/atl08_005_30m_filt_topo_landsat_20220418_1927.csv\n",
    "#TOPO_TIF=/projects/shared-buckets/nathanmthomas/alg_34_testing/Copernicus_1927_covars_cog_topo_stack.tif \n",
    "#LANDSAT_TIF= /projects/shared-buckets/nathanmthomas/alg_34_testing/HLS_1927_06-15_09-01_2019_2021.tif\n",
    "#DO_SLOPE_VALID_MASK= 'TRUE'\n",
    "#ATL08_SAMPLE_CSV=/projects/my-private-bucket/boreal_train_data_v4.csv\n",
    "#in_tile_num=42\n",
    "#in_tile_fn=/projects/shared-buckets/nathanmthomas/boreal_grid_albers90k_gpkg.gpkg\n",
    "\n",
    "#python /projects/icesat2_boreal/lib/merge_neighbors_atl08.py -in_tile_num 1927 -in_tile_fn /projects/shared-buckets/nathanmthomas/boreal_tiles_v003.gpkg -in_tile_field 'tile_num' -csv_list_fn /projects/my-public-bucket/DPS_tile_lists/ATL08_filt_tindex_master.csv -out_dir /projects/testing/output/\n",
    "#echo $cmd\n",
    "#eval $cmd\n",
    "\n",
    "# Set the output merged CSV name to a var\n",
    "#MERGED_ATL08_CSV=$(ls ${OUTPUTDIR}/atl08_005_30m_filt_merge_neighbors* | head -1)\n",
    "\n",
    "# Run mapBoreal with merged CSV as input\n",
    "#conda activate r-with-gdal\n",
    "\n",
    "\n",
    "#Rscript /projects/icesat2_boreal/lib/mapBoreal.R /projects/testing/output/atl08_004_30m_filt_merge_neighbors_0042.csv /projects/shared-buckets/nathanmthomas/alg_34_testing/Copernicus_42_covars_cog_topo_stack.tif /projects/shared-buckets/nathanmthomas/alg_34_testing/HLS_726_06-15_09-01_2019_2021.tif 'TRUE' /projects/my-private-bucket/boreal_train_data_v5.csv 2 2 100 300 5 TRUE 50 3000 \n",
    "\n",
    "#test swapping for terra\n",
    "#Rscript /projects/icesat2_boreal/lib/mapBoreal_speedy.R /projects/shared-buckets/nathanmthomas/atl08_004_30m_filt_merge_neighbors_3885.csv /projects/shared-buckets/nathanmthomas/alg_34_testing/Copernicus_3585_covars_cog_topo_stack.tif /projects/shared-buckets/nathanmthomas/alg_34_testing/HLS_727_06-15_09-01_2019_2021.tif 'TRUE' /projects/my-private-bucket/boreal_train_data_v5.csv 2 2 100 300 5 TRUE 100 3000 /projects/shared-buckets/nathanmthomas/analyze_agb/input_zones/wwf_circumboreal_Dissolve_reprj.geojson \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "abroad-bishop",
   "metadata": {},
   "outputs": [],
   "source": [
    "#test on tile 727 and 726\n",
    "#python /projects/icesat2_boreal/lib/merge_neighbors_atl08.py -in_tile_num 727 -in_tile_fn /projects/shared-buckets/nathanmthomas/boreal_tiles_v003.gpkg -in_tile_field 'tile_num' -csv_list_fn s3://maap-ops-workspace/shared/lduncanson/DPS_tile_lists/ATL08_filt_tindex_master.csv -out_dir /projects/testing/output/\n",
    "       \n",
    "#python /projects/icesat2_boreal/lib/merge_neighbors_atl08.py -in_tile_num 726 -in_tile_fn /projects/shared-buckets/nathanmthomas/boreal_tiles_v003.gpkg -in_tile_field 'tile_num' -csv_list_fn s3://maap-ops-workspace/shared/lduncanson/DPS_tile_lists/ATL08_filt_tindex_master.csv -out_dir /projects/testing/output/    \n",
    "\n",
    "## Rscript /projects/icesat2_boreal/lib/mapBoreal_speedy.R /projects/testing/output/atl08_004_30m_filt_merge_neighbors_0726.csv /projects/shared-buckets/nathanmthomas/alg_34_testing/Copernicus_726_covars_cog_topo_stack.tif /projects/shared-buckets/nathanmthomas/alg_34_testing/HLS_726_06-15_09-01_2019_2021.tif 'TRUE' /projects/my-private-bucket/boreal_train_data_v7.csv 2 2 130 250 5 TRUE 50 5000 /projects/shared-buckets/nathanmthomas/analyze_agb/input_zones/wwf_circumboreal_Dissolve_reprj.geojson \n",
    "\n",
    "## Rscript /projects/icesat2_boreal/lib/mapBoreal_speedy.R /projects/testing/output/atl08_004_30m_filt_merge_neighbors_0727.csv /projects/shared-buckets/nathanmthomas/alg_34_testing/Copernicus_727_covars_cog_topo_stack.tif /projects/shared-buckets/nathanmthomas/alg_34_testing/HLS_727_06-15_09-01_2019_2021.tif 'TRUE' /projects/my-private-bucket/boreal_train_data_v7.csv 2 2 130 250 5 TRUE 50 5000 /projects/shared-buckets/nathanmthomas/analyze_agb/input_zones/wwf_circumboreal_Dissolve_reprj.geojson \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "crucial-infrastructure",
   "metadata": {},
   "source": [
    "## register via terminal\n",
    "python /projects/register-algorithm.py /projects/icesat2_boreal/dps/alg_3-4/algorithm_config.yaml"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "coastal-hybrid",
   "metadata": {},
   "source": [
    "## Commit with Tag for running\n",
    "1) Add version name as a map_boreal_2022_v2 or whatever is appropriate - both to this notebook and algorithm config yaml\n",
    "\n",
    "2) follow git instructions (every time!!):\n",
    "git add changes\n",
    "git commit -m 'message'\n",
    "git tag -f map_boreal_2022_v3\n",
    "\n",
    "git push\n",
    "git push dps\n",
    "git push origin -f map_boreal_2022_v3\n",
    "git push dps -f map_boreal_2022_v3\n",
    "\n",
    "3) if it looks weird check git log to make sure tag is at same place as origin and dps\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "effective-violence",
   "metadata": {},
   "source": [
    "## Run a DPS job\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "adjacent-jordan",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# of input tiles for DPS: 4881\n",
      "DPS run #: 1\t| tile num: 37077\t| submit status: success\t| job id: f1c058b2-7fd1-4ee5-858b-07f4ff19252c\n",
      "DPS run #: 2\t| tile num: 3573\t| submit status: success\t| job id: 9c203a0b-466c-48ac-890e-8ea077e58f67\n",
      "DPS run #: 25\t| tile num: 3690\t| submit status: success\t| job id: d50577eb-0964-44fd-a332-9e0bc10a1770\n",
      "DPS run #: 50\t| tile num: 3819\t| submit status: success\t| job id: d6aed47a-5a83-41d1-9b91-efa69fe8ce0a\n",
      "DPS run #: 100\t| tile num: 1657\t| submit status: success\t| job id: 8dd0432b-2dda-4c20-a852-7737ccb8150e\n",
      "DPS run #: 500\t| tile num: 2398\t| submit status: success\t| job id: 9bf51bd3-5daf-4b72-bdb4-2a043cd5da1b\n",
      "DPS run #: 1000\t| tile num: 39464\t| submit status: success\t| job id: 5a13e40a-74b1-4c69-a832-1cd6e6ef9c2a\n",
      "DPS run #: 1500\t| tile num: 469\t| submit status: success\t| job id: 2a58e515-9210-4ef1-b1f7-403d9a97c6e1\n",
      "DPS run #: 2000\t| tile num: 3264\t| submit status: success\t| job id: 5c2c76d9-f33a-42b4-8634-317c812ce23c\n",
      "DPS run #: 3000\t| tile num: 1304\t| submit status: success\t| job id: 2ab90f9b-56d7-4a48-a94b-de4829c5cdbf\n",
      "Current time:\t202211112104\n",
      "CPU times: user 1min 8s, sys: 4.25 s, total: 1min 12s\n",
      "Wall time: 36min 30s\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>status</th>\n",
       "      <th>http_status_code</th>\n",
       "      <th>job_id</th>\n",
       "      <th>dps_num</th>\n",
       "      <th>tile_num</th>\n",
       "      <th>submit_time</th>\n",
       "      <th>dbs_job_hour</th>\n",
       "      <th>algo_id</th>\n",
       "      <th>user</th>\n",
       "      <th>worker_type</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>success</td>\n",
       "      <td>200</td>\n",
       "      <td>f1c058b2-7fd1-4ee5-858b-07f4ff19252c</td>\n",
       "      <td>1</td>\n",
       "      <td>37077</td>\n",
       "      <td>2022-11-11 20:28:07.656146</td>\n",
       "      <td>20</td>\n",
       "      <td>run_boreal_biomass_quick_v2_ubuntu</td>\n",
       "      <td>lduncanson</td>\n",
       "      <td>maap-dps-worker-32gb</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>success</td>\n",
       "      <td>200</td>\n",
       "      <td>9c203a0b-466c-48ac-890e-8ea077e58f67</td>\n",
       "      <td>2</td>\n",
       "      <td>3573</td>\n",
       "      <td>2022-11-11 20:28:07.724709</td>\n",
       "      <td>20</td>\n",
       "      <td>run_boreal_biomass_quick_v2_ubuntu</td>\n",
       "      <td>lduncanson</td>\n",
       "      <td>maap-dps-worker-32gb</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>success</td>\n",
       "      <td>200</td>\n",
       "      <td>1417c932-594e-4e27-b84d-6895e1d42e7c</td>\n",
       "      <td>3</td>\n",
       "      <td>26574</td>\n",
       "      <td>2022-11-11 20:28:07.806822</td>\n",
       "      <td>20</td>\n",
       "      <td>run_boreal_biomass_quick_v2_ubuntu</td>\n",
       "      <td>lduncanson</td>\n",
       "      <td>maap-dps-worker-32gb</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>success</td>\n",
       "      <td>200</td>\n",
       "      <td>05d8621f-8d31-43d3-9354-267809c5f7c6</td>\n",
       "      <td>4</td>\n",
       "      <td>28187</td>\n",
       "      <td>2022-11-11 20:28:07.929625</td>\n",
       "      <td>20</td>\n",
       "      <td>run_boreal_biomass_quick_v2_ubuntu</td>\n",
       "      <td>lduncanson</td>\n",
       "      <td>maap-dps-worker-32gb</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>success</td>\n",
       "      <td>200</td>\n",
       "      <td>94fa3c56-aeee-4b9c-9c43-c5ed3bb861fd</td>\n",
       "      <td>5</td>\n",
       "      <td>23548</td>\n",
       "      <td>2022-11-11 20:28:08.328174</td>\n",
       "      <td>20</td>\n",
       "      <td>run_boreal_biomass_quick_v2_ubuntu</td>\n",
       "      <td>lduncanson</td>\n",
       "      <td>maap-dps-worker-32gb</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>success</td>\n",
       "      <td>200</td>\n",
       "      <td>fdca183b-a29b-440d-9b5c-ac168ade9edb</td>\n",
       "      <td>4877</td>\n",
       "      <td>3364</td>\n",
       "      <td>2022-11-11 21:04:33.864843</td>\n",
       "      <td>21</td>\n",
       "      <td>run_boreal_biomass_quick_v2_ubuntu</td>\n",
       "      <td>lduncanson</td>\n",
       "      <td>maap-dps-worker-32gb</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>success</td>\n",
       "      <td>200</td>\n",
       "      <td>7c300dc8-c2df-4111-b13c-7099179f0855</td>\n",
       "      <td>4878</td>\n",
       "      <td>3856</td>\n",
       "      <td>2022-11-11 21:04:34.127113</td>\n",
       "      <td>21</td>\n",
       "      <td>run_boreal_biomass_quick_v2_ubuntu</td>\n",
       "      <td>lduncanson</td>\n",
       "      <td>maap-dps-worker-32gb</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>success</td>\n",
       "      <td>200</td>\n",
       "      <td>427d4288-f54b-47ed-88aa-a88f963385ba</td>\n",
       "      <td>4879</td>\n",
       "      <td>3538</td>\n",
       "      <td>2022-11-11 21:04:34.350369</td>\n",
       "      <td>21</td>\n",
       "      <td>run_boreal_biomass_quick_v2_ubuntu</td>\n",
       "      <td>lduncanson</td>\n",
       "      <td>maap-dps-worker-32gb</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>success</td>\n",
       "      <td>200</td>\n",
       "      <td>8f5be63f-adca-41b9-9c75-5857588f26d4</td>\n",
       "      <td>4880</td>\n",
       "      <td>3074</td>\n",
       "      <td>2022-11-11 21:04:34.554496</td>\n",
       "      <td>21</td>\n",
       "      <td>run_boreal_biomass_quick_v2_ubuntu</td>\n",
       "      <td>lduncanson</td>\n",
       "      <td>maap-dps-worker-32gb</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>success</td>\n",
       "      <td>200</td>\n",
       "      <td>6d80e3f1-3a0b-4664-b243-85eb4c850c3a</td>\n",
       "      <td>4881</td>\n",
       "      <td>3900</td>\n",
       "      <td>2022-11-11 21:04:34.730186</td>\n",
       "      <td>21</td>\n",
       "      <td>run_boreal_biomass_quick_v2_ubuntu</td>\n",
       "      <td>lduncanson</td>\n",
       "      <td>maap-dps-worker-32gb</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4881 rows × 10 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     status  http_status_code                                job_id  dps_num  \\\n",
       "0   success               200  f1c058b2-7fd1-4ee5-858b-07f4ff19252c        1   \n",
       "0   success               200  9c203a0b-466c-48ac-890e-8ea077e58f67        2   \n",
       "0   success               200  1417c932-594e-4e27-b84d-6895e1d42e7c        3   \n",
       "0   success               200  05d8621f-8d31-43d3-9354-267809c5f7c6        4   \n",
       "0   success               200  94fa3c56-aeee-4b9c-9c43-c5ed3bb861fd        5   \n",
       "..      ...               ...                                   ...      ...   \n",
       "0   success               200  fdca183b-a29b-440d-9b5c-ac168ade9edb     4877   \n",
       "0   success               200  7c300dc8-c2df-4111-b13c-7099179f0855     4878   \n",
       "0   success               200  427d4288-f54b-47ed-88aa-a88f963385ba     4879   \n",
       "0   success               200  8f5be63f-adca-41b9-9c75-5857588f26d4     4880   \n",
       "0   success               200  6d80e3f1-3a0b-4664-b243-85eb4c850c3a     4881   \n",
       "\n",
       "    tile_num                submit_time  dbs_job_hour  \\\n",
       "0      37077 2022-11-11 20:28:07.656146            20   \n",
       "0       3573 2022-11-11 20:28:07.724709            20   \n",
       "0      26574 2022-11-11 20:28:07.806822            20   \n",
       "0      28187 2022-11-11 20:28:07.929625            20   \n",
       "0      23548 2022-11-11 20:28:08.328174            20   \n",
       "..       ...                        ...           ...   \n",
       "0       3364 2022-11-11 21:04:33.864843            21   \n",
       "0       3856 2022-11-11 21:04:34.127113            21   \n",
       "0       3538 2022-11-11 21:04:34.350369            21   \n",
       "0       3074 2022-11-11 21:04:34.554496            21   \n",
       "0       3900 2022-11-11 21:04:34.730186            21   \n",
       "\n",
       "                               algo_id        user           worker_type  \n",
       "0   run_boreal_biomass_quick_v2_ubuntu  lduncanson  maap-dps-worker-32gb  \n",
       "0   run_boreal_biomass_quick_v2_ubuntu  lduncanson  maap-dps-worker-32gb  \n",
       "0   run_boreal_biomass_quick_v2_ubuntu  lduncanson  maap-dps-worker-32gb  \n",
       "0   run_boreal_biomass_quick_v2_ubuntu  lduncanson  maap-dps-worker-32gb  \n",
       "0   run_boreal_biomass_quick_v2_ubuntu  lduncanson  maap-dps-worker-32gb  \n",
       "..                                 ...         ...                   ...  \n",
       "0   run_boreal_biomass_quick_v2_ubuntu  lduncanson  maap-dps-worker-32gb  \n",
       "0   run_boreal_biomass_quick_v2_ubuntu  lduncanson  maap-dps-worker-32gb  \n",
       "0   run_boreal_biomass_quick_v2_ubuntu  lduncanson  maap-dps-worker-32gb  \n",
       "0   run_boreal_biomass_quick_v2_ubuntu  lduncanson  maap-dps-worker-32gb  \n",
       "0   run_boreal_biomass_quick_v2_ubuntu  lduncanson  maap-dps-worker-32gb  \n",
       "\n",
       "[4881 rows x 10 columns]"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "submit_results_df_list = []\n",
    "len_input_list = len(DPS_INPUT_TILE_NUM_LIST)\n",
    "print(f\"# of input tiles for DPS: {len_input_list}\")\n",
    "\n",
    "for i, INPUT_TILE_NUM in enumerate(DPS_INPUT_TILE_NUM_LIST):\n",
    "\n",
    "    DPS_num = i+1\n",
    "    IDENTIFIER = 'run_boreal_biomass_quick_v2'\n",
    "    ALGO_ID = f'{IDENTIFIER}_ubuntu'\n",
    "    USER = 'lduncanson'\n",
    "    WORKER_TYPE = 'maap-dps-worker-32gb'\n",
    "    \n",
    "    # Maybe we're using an input tile list that isnt built directly from an ATL08_filt CSV\n",
    "    # so, check if we have filtered ATL08 for this tile:\n",
    "    if INPUT_TILE_NUM in atl08_filt_tindex_master['tile_num'].to_list():\n",
    "        \n",
    "        # Get the s3 paths of the corresponding input filenames with an input tile_num\n",
    "        in_atl08_https =  atl08_filt_tindex_master['https'].loc[atl08_filt_tindex_master['tile_num'] == INPUT_TILE_NUM].tolist()[0]\n",
    "        in_topo_https = topo_tindex_master['https'].loc[topo_tindex_master['tile_num'] == INPUT_TILE_NUM].tolist()[0]\n",
    "        in_landsat_https = landsat_tindex_master['https'].loc[landsat_tindex_master['tile_num'] == INPUT_TILE_NUM].tolist()[0]\n",
    "        in_lc_https = lc_tindex_master['https'].loc[lc_tindex_master['tile_num'] == INPUT_TILE_NUM].tolist()[0]\n",
    " \n",
    "    else:\n",
    "        print(f\"No filtered ATL08 for tile {INPUT_TILE_NUM}. Moving on..\" )\n",
    "        continue\n",
    "    \n",
    "    # iters is the number of iterations of RH model fits; set to low (2-5) to test, 30-50 for production\n",
    "    # 30 yields run times ~4 hours\n",
    "        \n",
    "    # ppside is the number of subtile splits. 2=4 subtiles, 3=9 subtiles\n",
    "    # increasing ppside reduces memory, increases length to completion\n",
    "    \n",
    "    # minDOY is the min possible DOY to search for tile training data. The default is set to May 1\n",
    "    # If sufficient data are found in growing season, minDOY will not be used\n",
    "    \n",
    "    # maxDOY is the max possible DOY to search for tile training data. The default is Sept 30.\n",
    "    \n",
    "    # max_sol_el is the max solar elevation possible to search. The default is 0\n",
    "    \n",
    "    # expand_training as TRUE sets iterative searching for training data up to min_n, starting with solar_el<0 and growing season and then:\n",
    "    # searches solar_el up to max_sol_el then\n",
    "    # searches iteratively one month later after growing season until maxDOY then\n",
    "    # searches iteratively one month earlier before growing season until minDOY\n",
    "    # if expand_training=FALSE the growing season sol_el<0 will be taken, and if none, no data will return\n",
    "    \n",
    "    # min_n is the tile training number desired, that expand_training will search until it is fulfilled (or the max available)\n",
    "    \n",
    "    #local_train_perc is the percent tile training data vs. boreal-wide training data. 100 = all local, 0 = all boreal wide\n",
    "    \n",
    "    \n",
    "    in_param_dict = {\n",
    "                                    'in_atl08_fn': 's3://maap-ops-workspace/shared/lduncanson/DPS_tile_lists/fall2022/ATL08_filt_tindex_master.csv',\n",
    "                                    #'in_atl08_fn': f\"input/{os.path.basename(in_atl08_https)}\",\n",
    "                                    'in_topo_fn': f\"input/{os.path.basename(in_topo_https)}\",\n",
    "                                    'in_landsat_fn': f\"input/{os.path.basename(in_landsat_https)}\",\n",
    "                                    'in_lc_fn': f\"input/{os.path.basename(in_lc_https)}\",\n",
    "                                    'in_atl08_fn_url': in_atl08_https,\n",
    "                                    'in_topo_fn_url': in_topo_https,\n",
    "                                    'in_landsat_fn_url': in_landsat_https,\n",
    "                                    'in_lc_fn_url': in_lc_https,\n",
    "                                    'DO_SLOPE_VALID_MASK': 'TRUE',\n",
    "                                    'in_atl08_sample_fn':f\"input/{os.path.basename(train_data_https)}\",\n",
    "                                    'in_atl08_sample_url':train_data_https,\n",
    "                                    'in_tile_num': INPUT_TILE_NUM,\n",
    "                                    'in_tile_fn_url': 'https://maap-ops-workspace.s3.amazonaws.com/shared/nathanmthomas/boreal_tiles_v003.gpkg',\n",
    "                                    'in_tile_fn': 'input/boreal_tiles_v003.gpkg',\n",
    "                                    'in_tile_field': 'tile_num',\n",
    "                                    'iters': 31,\n",
    "                                    'ppside': 2,\n",
    "                                    'minDOY':130,\n",
    "                                    'maxDOY':250,\n",
    "                                    'max_sol_el':5,\n",
    "                                    'expand_training': 'TRUE',\n",
    "                                    'local_train_perc': 100,\n",
    "                                    'min_n': 5000, \n",
    "                                    'boreal_vect': 'https://maap-ops-workspace.s3.us-west-2.amazonaws.com/shared/nathanmthomas/analyze_agb/input_zones/wwf_circumboreal_Dissolve_reprj.geojson',\n",
    "                                    'boreal_vect_fn': 'input/wwf_circumboreal_Dissolve_reprj.geojson'\n",
    "                }\n",
    "    \n",
    "    submit_result = maap.submitJob(\n",
    "            identifier=IDENTIFIER,\n",
    "            algo_id=ALGO_ID,\n",
    "            version='map_boreal_2022_v3',\n",
    "            username=USER, # username needs to be the same as whoever created the workspace\n",
    "            queue=WORKER_TYPE,\n",
    "            **in_param_dict\n",
    "        )\n",
    "\n",
    "    # Build a dataframe of submission details\n",
    "    submit_result['dps_num'] = DPS_num\n",
    "    submit_result['tile_num'] = INPUT_TILE_NUM\n",
    "    submit_result['submit_time'] = datetime.datetime.now()\n",
    "    submit_result['dbs_job_hour'] =datetime.datetime.now().hour\n",
    "    submit_result['algo_id'] = ALGO_ID\n",
    "    submit_result['user'] = USER\n",
    "    submit_result['worker_type'] = WORKER_TYPE\n",
    "\n",
    "    # Append to a list of data frames of submission results\n",
    "    submit_results_df_list.append(pd.DataFrame([submit_result]))\n",
    "    \n",
    "    if DPS_num in [1, 2, 25, 50, 100, 500, 1000, 1500, 2000, 3000, 5000, 7000, 9000, 11000, 13000, 15000, 17000, 19000, 21000, 24000]:\n",
    "        print(f\"DPS run #: {DPS_num}\\t| tile num: {INPUT_TILE_NUM}\\t| submit status: {submit_result['status']}\\t| job id: {submit_result['job_id']}\") \n",
    "        #local_path\n",
    "\n",
    "# Build a final submission results df and save\n",
    "submit_results_df = pd.concat(submit_results_df_list)\n",
    "nowtime = pd.Timestamp.now().strftime('%Y%m%d%H%M')\n",
    "print(f\"Current time:\\t{nowtime}\")\n",
    "submit_results_df.to_csv(f'/projects/my-public-bucket/DPS_{IDENTIFIER}_submission_results_{len_input_list}_{nowtime}.csv')\n",
    "submit_results_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "virtual-operation",
   "metadata": {},
   "source": [
    "## Assess DPS Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "id": "latin-assault",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Count total jobs:\t4881\n",
      "Count pending jobs:\t0\n",
      "Count running jobs:\t0\n",
      "Count succeeded jobs:\t2387\n",
      "Count failed jobs:\t2494\n",
      "% of failed jobs:\t51.1\n",
      "CPU times: user 54.5 s, sys: 3.43 s, total: 57.9 s\n",
      "Wall time: 1min 53s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "#submit_results_df = pd.read_csv('/projects/my-public-bucket/DPS_run_boreal_biomass_v5_submission_results_4581_202205092316.csv')\n",
    "submit_results_df = pd.concat(submit_results_df_list)\n",
    "\n",
    "def BUILD_TABLE_JOBSTATUS(submit_results_df):\n",
    "    import xmltodict\n",
    "    df = pd.concat([pd.DataFrame(xmltodict.parse(maap.getJobStatus(job_id).content)).transpose() for job_id in submit_results_df.job_id.to_list()])\n",
    "    return df\n",
    "\n",
    "job_status_df = BUILD_TABLE_JOBSTATUS(submit_results_df)\n",
    "#print(job_status_df.head())\n",
    "\n",
    "num_jobs = submit_results_df.shape[0]\n",
    "z = submit_results_df.merge(job_status_df, how='left', left_on='job_id',  right_on='wps:JobID')\n",
    "\n",
    "print(f'Count total jobs:\\t{num_jobs}')\n",
    "print(f\"Count pending jobs:\\t{z[z['wps:Status'] =='Accepted'].shape[0]}\")\n",
    "print(f\"Count running jobs:\\t{z[z['wps:Status'] =='Running'].shape[0]}\")\n",
    "print(f\"Count succeeded jobs:\\t{z[z['wps:Status'] =='Succeeded'].shape[0]}\")\n",
    "print(f\"Count failed jobs:\\t{z[z['wps:Status'] =='Failed'].shape[0]}\")\n",
    "print(f\"% of failed jobs:\\t{round(z[z['wps:Status'] =='Failed'].shape[0] / ( z[z['wps:Status'] =='Failed'].shape[0] + z[z['wps:Status'] =='Succeeded'].shape[0] ), 4) * 100}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "id": "editorial-christopher",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 4881 entries, 0 to 0\n",
      "Data columns (total 10 columns):\n",
      " #   Column            Non-Null Count  Dtype         \n",
      "---  ------            --------------  -----         \n",
      " 0   status            4881 non-null   object        \n",
      " 1   http_status_code  4881 non-null   int64         \n",
      " 2   job_id            4881 non-null   object        \n",
      " 3   dps_num           4881 non-null   int64         \n",
      " 4   tile_num          4881 non-null   int64         \n",
      " 5   submit_time       4881 non-null   datetime64[ns]\n",
      " 6   dbs_job_hour      4881 non-null   int64         \n",
      " 7   algo_id           4881 non-null   object        \n",
      " 8   user              4881 non-null   object        \n",
      " 9   worker_type       4881 non-null   object        \n",
      "dtypes: datetime64[ns](1), int64(4), object(5)\n",
      "memory usage: 419.5+ KB\n"
     ]
    }
   ],
   "source": [
    "submit_results_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "surface-husband",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "OrderedDict([('wps:Result',\n",
       "              OrderedDict([('@xmlns:ows', 'http://www.opengis.net/ows/2.0'),\n",
       "                           ('@xmlns:schemaLocation',\n",
       "                            'http://schemas.opengis.net/wps/2.0/wps.xsd'),\n",
       "                           ('@xmlns:wps', 'http://www.opengis.net/wps/2.0'),\n",
       "                           ('@xmlns:xsi',\n",
       "                            'http://www.w3.org/2001/XMLSchema-instance'),\n",
       "                           ('wps:JobID',\n",
       "                            '5e4fd861-5d92-4e5d-b5b8-1d4e8e6dd463'),\n",
       "                           ('wps:Output',\n",
       "                            OrderedDict([('@id',\n",
       "                                          'output-2022-05-06T21:13:23.330599'),\n",
       "                                         ('wps:Data',\n",
       "                                          ['http://maap-ops-workspace.s3-website-us-west-2.amazonaws.com/lduncanson/dps_output/run_boreal_biomass_v4_ubuntu/master/2022/05/06/21/13/23/330599',\n",
       "                                           's3://s3.us-west-2.amazonaws.com:80/maap-ops-workspace/lduncanson/dps_output/run_boreal_biomass_v4_ubuntu/master/2022/05/06/21/13/23/330599',\n",
       "                                           'https://s3.console.aws.amazon.com/s3/buckets/maap-ops-workspace/lduncanson/dps_output/run_boreal_biomass_v4_ubuntu/master/2022/05/06/21/13/23/330599/?region=us-east-1&tab=overview'])]))]))])"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xmltodict.parse(maap.getJobResult(z[z['wps:Status'] =='Succeeded'].iloc[0].job_id).content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "id": "composite-peripheral",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'wps:Result': {'@xmlns:ows': 'http://www.opengis.net/ows/2.0',\n",
       "  '@xmlns:schemaLocation': 'http://schemas.opengis.net/wps/2.0/wps.xsd',\n",
       "  '@xmlns:wps': 'http://www.opengis.net/wps/2.0',\n",
       "  '@xmlns:xsi': 'http://www.w3.org/2001/XMLSchema-instance',\n",
       "  'wps:JobID': '167d1e36-6d6e-4d4c-9549-b02dae4d038e',\n",
       "  'wps:Output': {'@id': 'traceback',\n",
       "   'wps:Data': 'Traceback (most recent call last):\\n  File \"/home/ops/verdi/ops/hysds-0.3.11/hysds/job_worker.py\", line 1085, in run_job\\n    monitoredRunner.join()\\n  File \"/home/ops/verdi/lib/python3.7/site-packages/billiard/process.py\", line 148, in join\\n    res = self._popen.wait(timeout)\\n  File \"/home/ops/verdi/lib/python3.7/site-packages/billiard/popen_fork.py\", line 57, in wait\\n    return self.poll(os.WNOHANG if timeout == 0.0 else 0)\\n  File \"/home/ops/verdi/lib/python3.7/site-packages/billiard/popen_fork.py\", line 33, in poll\\n    pid, sts = os.waitpid(self.pid, flag)\\n  File \"/home/ops/verdi/lib/python3.7/site-packages/billiard/pool.py\", line 229, in soft_timeout_sighandler\\n    raise SoftTimeLimitExceeded()\\nbilliard.exceptions.SoftTimeLimitExceeded: SoftTimeLimitExceeded()'}}}"
      ]
     },
     "execution_count": 136,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xmltodict.parse(maap.getJobResult(z[z['wps:Status'] =='Failed'].iloc[20].job_id).content)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "functioning-preservation",
   "metadata": {},
   "source": [
    "## After successful DPS run, create AGB tindex"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "supposed-arrest",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/projects/.local/lib/python3.7/site-packages/geopandas/_compat.py:110: UserWarning: The Shapely GEOS version (3.8.0-CAPI-1.13.1 ) is incompatible with the GEOS version PyGEOS was compiled with (3.10.1-CAPI-1.16.0). Conversions between both will be slow.\n",
      "  shapely_geos_version, geos_capi_version_string\n",
      "\n",
      "Building a list of tiles:\n",
      "MAAP version:\t\tmap_boreal_2022_v3\n",
      "Type:\t\tAGB\n",
      "Year:\t\t2022\n",
      "Month:\t\t['11']\n",
      "Days:\t\t1-31\n",
      "\n",
      "Output dir:  /projects/my-public-bucket/DPS_tile_lists/fall2022/\n",
      "                                             s3_path  ...                                     file\n",
      "0  s3://maap-ops-workspace/lduncanson/dps_output/...  ...   boreal_agb_202211111668203884_2348.tif\n",
      "1  s3://maap-ops-workspace/lduncanson/dps_output/...  ...  boreal_agb_202211111668204477_37079.tif\n",
      "2  s3://maap-ops-workspace/lduncanson/dps_output/...  ...   boreal_agb_202211111668204586_3943.tif\n",
      "3  s3://maap-ops-workspace/lduncanson/dps_output/...  ...  boreal_agb_202211111668205557_26297.tif\n",
      "4  s3://maap-ops-workspace/lduncanson/dps_output/...  ...  boreal_agb_202211111668206230_25745.tif\n",
      "\n",
      "[5 rows x 3 columns]\n",
      "/opt/conda/lib/python3.7/site-packages/pandas/core/indexing.py:1597: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  self.obj[key] = value\n",
      "/opt/conda/lib/python3.7/site-packages/pandas/core/indexing.py:1720: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  self._setitem_single_column(loc, value, pi)\n",
      "/projects/icesat2_boreal/lib/build_tindex_master.py:73: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df['tile_num'] = df['tile_num'].astype(str).astype(int)\n",
      "# of duplicate tiles: 1\n",
      "Final # of tiles: 4064\n",
      "df shape :                                                s3_path  ... tile_num\n",
      "140  s3://maap-ops-workspace/lduncanson/dps_output/...  ...     3722\n",
      "139  s3://maap-ops-workspace/lduncanson/dps_output/...  ...     2909\n",
      "138  s3://maap-ops-workspace/lduncanson/dps_output/...  ...     3377\n",
      "137  s3://maap-ops-workspace/lduncanson/dps_output/...  ...     3494\n",
      "136  s3://maap-ops-workspace/lduncanson/dps_output/...  ...    27915\n",
      "\n",
      "[5 rows x 4 columns]\n",
      "Writing tindex master csv: /projects/my-public-bucket/DPS_tile_lists/fall2022/AGB_tindex_master.csv\n"
     ]
    }
   ],
   "source": [
    "## create AGB tindex \n",
    "month_dir_str = '11'\n",
    "alg_name_str = 'run_boreal_biomass_quick_v2_ubuntu'\n",
    "maap_version_str = 'map_boreal_2022_v3'\n",
    "#index_out_dir = os.path.join('/projects/my-private-bucket/dps_output/run_boreal_biomass_qiuck_v2_ubuntu/map_boreal_2022_v3/2022/', month_dir_str)\n",
    "index_out_dir = '/projects/my-public-bucket/DPS_tile_lists/fall2022/'\n",
    "!python /projects/icesat2_boreal/lib/build_tindex_master.py -t 'AGB' -alg_name $alg_name_str --maap_version $maap_version_str -y 2022 -m $month_dir_str -o $index_out_dir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "ecological-large",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# of tiles to run: 817\n",
      " [4, 4100, 11, 4108, 13, 2062, 2063, 16, 17, 34833, 2064, 4118, 26, 27, 28699, 28, 28701, 28702, 31, 4129, 28703, 28707, 37, 38, 24615, 39, 40, 28709, 24619, 43, 45, 46, 47, 2094, 4138, 4137, 4142, 4149, 54, 36917, 4152, 2105, 2107, 4157, 65, 2113, 67, 2122, 4176, 82, 34899, 34900, 85, 2133, 87, 88, 34903, 2138, 2139, 41052, 94, 24670, 2145, 24673, 99, 4196, 24678, 106, 2155, 108, 4204, 4207, 4208, 4209, 4211, 4212, 117, 2165, 4214, 2168, 4215, 127, 128, 2195, 4244, 4245, 4250, 2206, 159, 4256, 2210, 2211, 2213, 4262, 2216, 4266, 4268, 2221, 177, 2227, 181, 183, 184, 4286, 192, 2240, 4288, 4293, 4295, 26824, 201, 26825, 26826, 4296, 205, 2254, 4299, 37071, 209, 26834, 211, 2257, 213, 2261, 4304, 2264, 2265, 218, 2267, 220, 26841, 225, 2274, 4323, 228, 4325, 2280, 2283, 240, 2292, 2293, 4342, 4343, 4344, 255, 4358, 4359, 265, 33033, 4361, 268, 271, 4372, 2326, 279, 37142, 37143, 2332, 2333, 4380, 287, 41248, 291, 293, 2341, 2343, 296, 2345, 4389, 28969, 4396, 4395, 31016, 28967, 306, 2355, 4403, 35123, 2360, 313, 314, 2362, 2363, 2364, 43326, 4408, 320, 321, 4411, 4417, 327, 2375, 334, 4430, 4431, 339, 2388, 4435, 342, 343, 344, 4440, 348, 4444, 352, 354, 4450, 4451, 4452, 2408, 361, 362, 2411, 4457, 366, 4463, 2416, 369, 2417, 4464, 372, 4467, 4470, 24951, 376, 377, 378, 2425, 380, 2426, 24955, 4477, 4478, 2435, 388, 4483, 2438, 391, 4484, 4491, 4492, 4493, 398, 399, 401, 2451, 4499, 4501, 411, 412, 2460, 4510, 2463, 417, 418, 419, 2467, 4513, 2471, 425, 2474, 2475, 430, 4527, 4528, 4529, 2482, 436, 437, 4534, 439, 2488, 442, 4540, 445, 2494, 447, 2496, 4541, 2499, 4551, 457, 460, 463, 464, 41428, 469, 2516, 41429, 475, 476, 41437, 478, 2524, 480, 481, 2526, 27106, 485, 2536, 27112, 27114, 493, 494, 2548, 502, 33270, 504, 506, 2555, 2556, 511, 513, 2565, 518, 519, 2566, 522, 524, 35348, 2586, 2587, 35356, 35357, 31263, 544, 2597, 550, 2600, 553, 39464, 558, 564, 566, 568, 2616, 573, 575, 578, 579, 581, 582, 2630, 2634, 590, 592, 593, 595, 596, 2645, 598, 2647, 2650, 2652, 2654, 25183, 612, 613, 614, 615, 2665, 621, 624, 626, 627, 2680, 2687, 640, 643, 2692, 649, 654, 25232, 657, 2705, 659, 37522, 661, 662, 25239, 37524, 665, 37529, 664, 668, 669, 2724, 688, 23219, 693, 35511, 698, 2746, 706, 710, 2759, 718, 2766, 37583, 723, 37587, 735, 737, 27364, 741, 27365, 2789, 753, 754, 2803, 35574, 35575, 27384, 27383, 2810, 27385, 2815, 35583, 2822, 2823, 786, 2838, 31511, 31512, 2842, 795, 2845, 798, 2849, 806, 2858, 827, 831, 2883, 2890, 843, 844, 2906, 859, 2907, 2912, 868, 2920, 873, 874, 875, 876, 877, 25460, 887, 895, 897, 2945, 904, 907, 2958, 45970, 2966, 922, 2971, 2972, 927, 928, 931, 935, 25512, 25518, 953, 3002, 954, 959, 3011, 3012, 3013, 23497, 33741, 35796, 3029, 3032, 987, 3036, 3042, 3045, 3047, 3048, 1006, 1007, 27635, 27638, 3065, 23550, 23551, 3078, 27655, 3081, 1036, 41998, 31761, 1050, 3103, 3104, 1058, 1062, 1069, 3127, 3129, 3130, 3132, 3143, 37963, 3149, 1103, 1105, 3160, 40037, 3178, 3179, 3180, 1134, 1136, 1138, 1139, 3188, 1149, 3199, 25735, 30760, 1167, 25747, 30762, 4306, 4307, 3239, 3240, 36016, 36018, 36020, 1205, 3253, 3255, 1208, 3257, 3258, 3262, 25790, 1216, 3270, 42187, 3285, 3294, 1248, 3299, 1263, 3311, 3315, 3316, 3318, 3320, 3322, 3326, 3330, 1282, 3333, 27911, 27917, 27919, 3344, 27920, 3343, 3347, 3346, 27922, 3350, 23833, 3353, 38169, 1307, 3355, 1309, 3357, 38173, 3360, 3361, 3363, 29994, 3371, 3373, 1327, 1336, 1347, 3397, 3398, 3404, 3407, 36177, 1363, 1370, 1371, 3423, 1377, 3425, 3431, 3434, 3435, 3437, 3439, 3449, 1403, 3453, 3457, 3458, 1413, 3463, 1416, 3465, 3466, 3468, 3471, 1426, 3474, 3478, 3479, 1432, 36249, 36250, 1438, 1439, 1440, 34210, 3490, 26020, 26021, 3498, 3500, 3501, 3503, 3506, 3513, 3523, 1476, 3527, 3528, 1482, 3531, 3533, 3537, 26066, 1492, 1493, 3542, 3543, 3544, 1494, 1498, 3546, 3547, 3548, 1504, 38382, 38383, 3575, 24056, 24057, 1531, 24061, 1535, 1539, 3590, 3591, 1546, 3599, 28175, 3608, 1562, 28187, 3622, 3623, 30251, 30252, 24108, 30255, 24111, 3633, 3636, 1590, 3639, 1593, 3644, 1597, 42558, 1604, 1606, 34375, 1617, 1618, 3666, 36459, 36468, 1669, 3724, 3725, 34446, 34447, 3729, 1682, 3731, 1684, 3733, 3734, 1696, 3748, 3749, 1706, 1707, 3762, 1718, 26296, 1721, 3770, 26299, 1724, 1730, 1731, 3800, 3806, 1762, 26341, 26342, 1766, 26343, 3821, 1779, 42745, 42746, 3835, 3839, 3840, 1796, 1798, 3846, 36627, 24342, 28441, 3870, 28448, 1825, 1828, 1831, 3882, 30508, 34605, 3892, 3893, 3895, 1848, 1850, 1851, 1852, 3898, 24389, 3911, 24391, 3913, 24393, 1867, 1869, 36692, 1877, 36695, 3931, 3941, 34673, 1906, 34674, 34675, 1909, 1910, 3958, 1914, 1916, 1917, 3966, 1919, 1920, 1921, 1922, 1926, 1927, 3977, 1930, 1933, 1936, 3985, 3986, 1939, 3991, 40857, 4000, 4001, 1954, 4007, 4008, 26554, 4027, 26557, 4040, 26569, 26571, 4044, 4468, 2003, 4058, 2016, 4074, 2034, 4083, 4093]\n"
     ]
    }
   ],
   "source": [
    "TEST_DPS  = True\n",
    "\n",
    "if TEST_DPS:\n",
    "    \n",
    "    if True:\n",
    "        #!python /projects/icesat2_boreal/lib/build_tindex_master_v2.py -t AGB -y 2022 -m $month_dir_str -o $index_out_dir\n",
    "        t = pd.read_csv(os.path.join(index_out_dir,'AGB_tindex_master.csv'))\n",
    "        COMPLETED_TILES = t.tile_num.to_list()\n",
    "        NEED_TILES = list(set(DPS_INPUT_TILE_NUM_LIST) - set(COMPLETED_TILES))\n",
    "\n",
    "        #print(NEED_TILES)\n",
    "        DPS_INPUT_TILE_NUM_LIST = NEED_TILES\n",
    "    \n",
    "else:\n",
    "    DPS_INPUT_TILE_NUM_LIST = INPUT_TILE_NUM_LIST\n",
    "   \n",
    "\n",
    "#DPS_INPUT_TILE_NUM_LIST = [248, 273, 272, 271, 324]\n",
    "print(f\"# of tiles to run: {len(DPS_INPUT_TILE_NUM_LIST)}\\n\", DPS_INPUT_TILE_NUM_LIST)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "public-buffalo",
   "metadata": {},
   "source": [
    "## Re-run Failed Tiles in DPS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "simplified-victim",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# of input tiles for DPS: 958\n",
      "DPS run #: 1\t| tile num: 4\t| submit status: success\t| job id: 48638479-f72f-40a5-bd1a-a2b3f1d493f1\n",
      "DPS run #: 2\t| tile num: 4100\t| submit status: success\t| job id: cd1cf5d5-6308-40bc-9b37-f7aecc349600\n",
      "DPS run #: 25\t| tile num: 37\t| submit status: success\t| job id: d25ad3eb-6fda-43d5-afef-ce37ba39ff2c\n",
      "DPS run #: 50\t| tile num: 2122\t| submit status: success\t| job id: dbffc866-050f-46e0-80dc-0d8495244f73\n",
      "DPS run #: 100\t| tile num: 167\t| submit status: success\t| job id: df34625b-c997-4c19-a5db-4fd7dfbddd22\n",
      "DPS run #: 500\t| tile num: 886\t| submit status: success\t| job id: d14d66a0-80fd-4c46-ace0-bbd761795bae\n",
      "Current time:\t202211150536\n"
     ]
    },
    {
     "ename": "ImportError",
     "evalue": "cannot import name 'CompressionOptions' from 'pandas._typing' (/opt/conda/lib/python3.7/site-packages/pandas/_typing.py)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[0;32m<timed exec>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/pandas/core/generic.py\u001b[0m in \u001b[0;36mto_csv\u001b[0;34m(self, path_or_buf, sep, na_rep, float_format, columns, header, index, index_label, mode, encoding, compression, quoting, quotechar, line_terminator, chunksize, date_format, doublequote, escapechar, decimal, errors)\u001b[0m\n\u001b[1;32m   3143\u001b[0m         \u001b[0mDataFrame\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_html\u001b[0m \u001b[0;34m:\u001b[0m \u001b[0mRender\u001b[0m \u001b[0ma\u001b[0m \u001b[0mDataFrame\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0man\u001b[0m \u001b[0mHTML\u001b[0m \u001b[0mtable\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3144\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3145\u001b[0;31m         \u001b[0mExamples\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3146\u001b[0m         \u001b[0;34m-\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3147\u001b[0m         >>> df = pd.DataFrame(dict(name=['Raphael', 'Donatello'],\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/pandas/io/formats/csvs.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mpandas\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_libs\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mwriters\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mlibwriters\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 12\u001b[0;31m from pandas._typing import (\n\u001b[0m\u001b[1;32m     13\u001b[0m     \u001b[0mCompressionOptions\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m     \u001b[0mFilePathOrBuffer\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mImportError\u001b[0m: cannot import name 'CompressionOptions' from 'pandas._typing' (/opt/conda/lib/python3.7/site-packages/pandas/_typing.py)"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "submit_results_df_list = []\n",
    "len_input_list = len(DPS_INPUT_TILE_NUM_LIST)\n",
    "print(f\"# of input tiles for DPS: {len_input_list}\")\n",
    "\n",
    "for i, INPUT_TILE_NUM in enumerate(DPS_INPUT_TILE_NUM_LIST):\n",
    "\n",
    "    DPS_num = i+1\n",
    "    IDENTIFIER = 'run_boreal_biomass_quick_v2'\n",
    "    ALGO_ID = f'{IDENTIFIER}_ubuntu'\n",
    "    USER = 'lduncanson'\n",
    "    WORKER_TYPE = 'maap-dps-worker-32gb'\n",
    "    \n",
    "    # Maybe we're using an input tile list that isnt built directly from an ATL08_filt CSV\n",
    "    # so, check if we have filtered ATL08 for this tile:\n",
    "    if INPUT_TILE_NUM in atl08_filt_tindex_master['tile_num'].to_list():\n",
    "        \n",
    "        # Get the s3 paths of the corresponding input filenames with an input tile_num\n",
    "        in_atl08_https =  atl08_filt_tindex_master['https'].loc[atl08_filt_tindex_master['tile_num'] == INPUT_TILE_NUM].tolist()[0]\n",
    "        in_topo_https = topo_tindex_master['https'].loc[topo_tindex_master['tile_num'] == INPUT_TILE_NUM].tolist()[0]\n",
    "        in_landsat_https = landsat_tindex_master['https'].loc[landsat_tindex_master['tile_num'] == INPUT_TILE_NUM].tolist()[0]\n",
    "        in_lc_https = lc_tindex_master['https'].loc[lc_tindex_master['tile_num'] == INPUT_TILE_NUM].tolist()[0]\n",
    " \n",
    "    else:\n",
    "        print(f\"No filtered ATL08 for tile {INPUT_TILE_NUM}. Moving on..\" )\n",
    "        continue\n",
    "    \n",
    "    # iters is the number of iterations of RH model fits; set to low (2-5) to test, 30-50 for production\n",
    "    # 30 yields run times ~4 hours\n",
    "        \n",
    "    # ppside is the number of subtile splits. 2=4 subtiles, 3=9 subtiles\n",
    "    # increasing ppside reduces memory, increases length to completion\n",
    "    \n",
    "    # minDOY is the min possible DOY to search for tile training data. The default is set to May 1\n",
    "    # If sufficient data are found in growing season, minDOY will not be used\n",
    "    \n",
    "    # maxDOY is the max possible DOY to search for tile training data. The default is Sept 30.\n",
    "    \n",
    "    # max_sol_el is the max solar elevation possible to search. The default is 0\n",
    "    \n",
    "    # expand_training as TRUE sets iterative searching for training data up to min_n, starting with solar_el<0 and growing season and then:\n",
    "    # searches solar_el up to max_sol_el then\n",
    "    # searches iteratively one month later after growing season until maxDOY then\n",
    "    # searches iteratively one month earlier before growing season until minDOY\n",
    "    # if expand_training=FALSE the growing season sol_el<0 will be taken, and if none, no data will return\n",
    "    \n",
    "    # min_n is the tile training number desired, that expand_training will search until it is fulfilled (or the max available)\n",
    "    \n",
    "    #local_train_perc is the percent tile training data vs. boreal-wide training data. 100 = all local, 0 = all boreal wide\n",
    "    \n",
    "    \n",
    "    in_param_dict = {\n",
    "                                    'in_atl08_fn': 's3://maap-ops-workspace/shared/lduncanson/DPS_tile_lists/fall2022/ATL08_filt_tindex_master.csv',\n",
    "                                    #'in_atl08_fn': f\"input/{os.path.basename(in_atl08_https)}\",\n",
    "                                    'in_topo_fn': f\"input/{os.path.basename(in_topo_https)}\",\n",
    "                                    'in_landsat_fn': f\"input/{os.path.basename(in_landsat_https)}\",\n",
    "                                    'in_lc_fn': f\"input/{os.path.basename(in_lc_https)}\",\n",
    "                                    'in_atl08_fn_url': in_atl08_https,\n",
    "                                    'in_topo_fn_url': in_topo_https,\n",
    "                                    'in_landsat_fn_url': in_landsat_https,\n",
    "                                    'in_lc_fn_url': in_lc_https,\n",
    "                                    'DO_SLOPE_VALID_MASK': 'TRUE',\n",
    "                                    'in_atl08_sample_fn':f\"input/{os.path.basename(train_data_https)}\",\n",
    "                                    'in_atl08_sample_url':train_data_https,\n",
    "                                    'in_tile_num': INPUT_TILE_NUM,\n",
    "                                    'in_tile_fn_url': 'https://maap-ops-workspace.s3.amazonaws.com/shared/nathanmthomas/boreal_tiles_v003.gpkg',\n",
    "                                    'in_tile_fn': 'input/boreal_tiles_v003.gpkg',\n",
    "                                    'in_tile_field': 'tile_num',\n",
    "                                    'iters': 31,\n",
    "                                    'ppside': 2,\n",
    "                                    'minDOY':130,\n",
    "                                    'maxDOY':250,\n",
    "                                    'max_sol_el':5,\n",
    "                                    'expand_training': 'TRUE',\n",
    "                                    'local_train_perc': 100,\n",
    "                                    'min_n': 5000, \n",
    "                                    'boreal_vect': 'https://maap-ops-workspace.s3.us-west-2.amazonaws.com/shared/nathanmthomas/analyze_agb/input_zones/wwf_circumboreal_Dissolve_reprj.geojson',\n",
    "                                    'boreal_vect_fn': 'input/wwf_circumboreal_Dissolve_reprj.geojson'\n",
    "                }\n",
    "    \n",
    "    submit_result = maap.submitJob(\n",
    "            identifier=IDENTIFIER,\n",
    "            algo_id=ALGO_ID,\n",
    "            version='map_boreal_2022_v3',\n",
    "            username=USER, # username needs to be the same as whoever created the workspace\n",
    "            queue=WORKER_TYPE,\n",
    "            **in_param_dict\n",
    "        )\n",
    "\n",
    "    # Build a dataframe of submission details\n",
    "    submit_result['dps_num'] = DPS_num\n",
    "    submit_result['tile_num'] = INPUT_TILE_NUM\n",
    "    submit_result['submit_time'] = datetime.datetime.now()\n",
    "    submit_result['dbs_job_hour'] =datetime.datetime.now().hour\n",
    "    submit_result['algo_id'] = ALGO_ID\n",
    "    submit_result['user'] = USER\n",
    "    submit_result['worker_type'] = WORKER_TYPE\n",
    "\n",
    "    # Append to a list of data frames of submission results\n",
    "    submit_results_df_list.append(pd.DataFrame([submit_result]))\n",
    "    \n",
    "    if DPS_num in [1, 2, 25, 50, 100, 500, 1000, 1500, 2000, 3000, 5000, 7000, 9000, 11000, 13000, 15000, 17000, 19000, 21000, 24000]:\n",
    "        print(f\"DPS run #: {DPS_num}\\t| tile num: {INPUT_TILE_NUM}\\t| submit status: {submit_result['status']}\\t| job id: {submit_result['job_id']}\") \n",
    "        #local_path\n",
    "\n",
    "# Build a final submission results df and save\n",
    "submit_results_df = pd.concat(submit_results_df_list)\n",
    "nowtime = pd.Timestamp.now().strftime('%Y%m%d%H%M')\n",
    "print(f\"Current time:\\t{nowtime}\")\n",
    "submit_results_df.to_csv(f'/projects/my-public-bucket/DPS_{IDENTIFIER}_submission_results_{len_input_list}_{nowtime}.csv')\n",
    "submit_results_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "friendly-finish",
   "metadata": {},
   "source": [
    "## Re-Assess Re-submission\n",
    "Continue with last few steps until all jobs successful: create tindex, create new tile list, re-run missing tiles in DPS, re-assess"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "understood-christianity",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Count total jobs:\t958\n",
      "Count pending jobs:\t0\n",
      "Count running jobs:\t159\n",
      "Count succeeded jobs:\t285\n",
      "Count failed jobs:\t514\n",
      "% of failed jobs:\t64.33\n",
      "CPU times: user 11.7 s, sys: 755 ms, total: 12.4 s\n",
      "Wall time: 23.6 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "#submit_results_df = pd.read_csv('/projects/my-public-bucket/DPS_run_boreal_biomass_quick_v2_submission_results_2494_202211132259.csv')\n",
    "submit_results_df = pd.concat(submit_results_df_list)\n",
    "\n",
    "def BUILD_TABLE_JOBSTATUS(submit_results_df):\n",
    "    import xmltodict\n",
    "    df = pd.concat([pd.DataFrame(xmltodict.parse(maap.getJobStatus(job_id).content)).transpose() for job_id in submit_results_df.job_id.to_list()])\n",
    "    return df\n",
    "\n",
    "job_status_df = BUILD_TABLE_JOBSTATUS(submit_results_df)\n",
    "#print(job_status_df.head())\n",
    "\n",
    "num_jobs = submit_results_df.shape[0]\n",
    "z = submit_results_df.merge(job_status_df, how='left', left_on='job_id',  right_on='wps:JobID')\n",
    "\n",
    "print(f'Count total jobs:\\t{num_jobs}')\n",
    "print(f\"Count pending jobs:\\t{z[z['wps:Status'] =='Accepted'].shape[0]}\")\n",
    "print(f\"Count running jobs:\\t{z[z['wps:Status'] =='Running'].shape[0]}\")\n",
    "print(f\"Count succeeded jobs:\\t{z[z['wps:Status'] =='Succeeded'].shape[0]}\")\n",
    "print(f\"Count failed jobs:\\t{z[z['wps:Status'] =='Failed'].shape[0]}\")\n",
    "print(f\"% of failed jobs:\\t{round(z[z['wps:Status'] =='Failed'].shape[0] / ( z[z['wps:Status'] =='Failed'].shape[0] + z[z['wps:Status'] =='Succeeded'].shape[0] ), 4) * 100}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aquatic-colors",
   "metadata": {},
   "source": [
    "## Get other lists just of missing tiles (various ways)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "golden-convenience",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "1\n"
     ]
    }
   ],
   "source": [
    "need_tindex_master = pd.read_csv('/projects/my-public-bucket/DPS_tile_lists/Need_AGB_tindex_master.csv')\n",
    "print(len(need_tindex_master))\n",
    "\n",
    "INPUT_TILE_NUM_LIST = need_tindex_master.tile_num.tolist()\n",
    "\n",
    "# Remove duplicate tile nums\n",
    "INPUT_TILE_NUM_LIST = list(set(INPUT_TILE_NUM_LIST))\n",
    "\n",
    "print(len(INPUT_TILE_NUM_LIST))\n",
    "\n",
    "INPUT_TILE_NUM_LIST_NEED = INPUT_TILE_NUM_LIST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "intended-apparatus",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "11"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "weird_tiles = [4304, 4305, 4221, 4220, 1785, 1718, 1720, 1661, 1257, 1318, 1317]\n",
    "werid_tiles = [1255, 1196, 949, 1062, 1063, 1005, 950, 1004]\n",
    "INPUT_TILE_NUM_LIST = weird_tiles\n",
    "len(INPUT_TILE_NUM_LIST)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "prompt-polish",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "45\n",
      "[978, 988, 978, 988, 1263, 1261, 1264, 794, 2932, 3190, 3012, 3014, 3360, 3017, 378, 765, 812, 821, 764, 861, 1302, 1308, 1469, 2894, 2883, 2965, 2976, 3327, 3321, 3510, 3509, 4372, 4440, 4477, 2994, 1406, 2840, 411, 380, 3335, 2495, 4403, 2906, 2907, 2814]\n"
     ]
    }
   ],
   "source": [
    "# Get all boreal tiles\n",
    "ATL08_filt_tindex_master =   pd.read_csv('s3://maap-ops-workspace/shared/lduncanson/DPS_tile_lists/ATL08_filt_tindex_master.csv')\n",
    "boreal_tile_index_path = '/projects/shared-buckets/nathanmthomas/boreal_grid_albers90k_gpkg.gpkg'\n",
    "boreal_tile_index = geopandas.read_file(boreal_tile_index_path)\n",
    "boreal_tile_index.rename(columns={\"layer\":\"tile_num\"}, inplace=True)\n",
    "boreal_tile_index[\"tile_num\"] = boreal_tile_index[\"tile_num\"].astype(int)\n",
    "\n",
    "bad_tiles = [3540,3634,3728,3823,3916,4004] #Dropping the tiles near antimeridian that reproject poorly.\n",
    "select_needs = [3360,2994,3190,2840,3012,3014,3017,2932,1261,1263,1264,988,978,794, 380,378,411,821,861,\n",
    "                812,765,764,1308,1302,1469,1406,2495,2883,2965,3321,3509,3510,3327,3335,2976,2906,2907,2894,2814,4253,4293,4403,4440,4408,4372,4477,3986]\n",
    "\n",
    "# Remove bad tiles\n",
    "boreal_tile_index = boreal_tile_index[~boreal_tile_index['tile_num'].isin(bad_tiles)]\n",
    "    \n",
    "#print(boreal_tile_index.head())\n",
    "tile_matches_select_needs = boreal_tile_index.merge(ATL08_filt_tindex_master[ATL08_filt_tindex_master['tile_num'].isin(select_needs)], how='right', on='tile_num')\n",
    "print(len(tile_matches_select_needs))\n",
    "select_needs_filt = print([t for t in tile_matches_select_needs.tile_num])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "negative-evening",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "45\n",
      "4\n",
      "[3986 4253 4293 4408]\n",
      "70\n",
      "[  65  106  127  250  361  417  493  566  568  618  741  753  786  798\n",
      "  801  830  848  876  877  927 1273 1287 1318 1402 1438 1439 1440 1604\n",
      " 1848 1850 1852 1936 2425 2426 2952 3124 3355 3540 3542 3634 3728 3823\n",
      " 3845 3846 3895 3916 4004 4007 4018 4083 4176 4204 4250 4256 4307 4325\n",
      " 4342 4395 4417 4444 4450 4451 4463 4467 4468 4483 4499 4510 4527 4534]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "70"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#select_needs_filt = [978, 988, 978, 988, 1263, 1261, 1264, 794, 2932, 3190, 3012, 3014, 3360, 3017, 378, 765, 812, 821, 764, 861, 1302, 1308, 1469, 2894, 2883, 2965, 2976, 3327, 3321, 3510, 3509, 4372, 4440, 4477, 2994, 1406, 2840, 411, 380, 3335, 2495, 4403, 2906, 2907, 2814]\n",
    "\n",
    "print(len(select_needs_filt))\n",
    "\n",
    "import numpy as np\n",
    "tile_nums_missing_but_wont_run = np.setdiff1d(select_needs, select_needs_filt)\n",
    "print(len(tile_nums_missing_but_wont_run))\n",
    "print(tile_nums_missing_but_wont_run)\n",
    "\n",
    "tile_nums_missing_periphery = np.setdiff1d(INPUT_TILE_NUM_LIST_NEED, select_needs_filt)\n",
    "print(len(tile_nums_missing_periphery))\n",
    "print(tile_nums_missing_periphery)\n",
    "INPUT_TILE_NUM_LIST = tile_nums_missing_periphery\n",
    "len(INPUT_TILE_NUM_LIST)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "posted-lancaster",
   "metadata": {},
   "outputs": [],
   "source": [
    "INPUT_TILE_NUM_LIST = [4440,4372,4477]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "civilian-market",
   "metadata": {},
   "source": [
    "## Send output cog.tif tiles somewhere"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "correct-dallas",
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "out_files = glob.glob(\"/projects/my-private-bucket/dps_output/run_boreal_biomass_ubuntu/master/2022/02/baseline_run/**/*cog.tif\", recursive=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "mathematical-conditions",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['/projects/my-private-bucket/dps_output/run_boreal_biomass_ubuntu/master/2022/02/baseline_run/02/23/49/35/272239/boreal_agb_20220202_0200_cog.tif', '/projects/my-private-bucket/dps_output/run_boreal_biomass_ubuntu/master/2022/02/baseline_run/03/01/42/37/290043/boreal_agb_20220203_0224_cog.tif', '/projects/my-private-bucket/dps_output/run_boreal_biomass_ubuntu/master/2022/02/baseline_run/03/01/52/46/430279/boreal_agb_20220203_0387_cog.tif', '/projects/my-private-bucket/dps_output/run_boreal_biomass_ubuntu/master/2022/02/baseline_run/03/02/21/50/348844/boreal_agb_20220203_0386_cog.tif', '/projects/my-private-bucket/dps_output/run_boreal_biomass_ubuntu/master/2022/02/baseline_run/03/03/01/42/237812/boreal_agb_20220203_0199_cog.tif', '/projects/my-private-bucket/dps_output/run_boreal_biomass_ubuntu/master/2022/02/baseline_run/03/03/06/47/336472/boreal_agb_20220203_0223_cog.tif', '/projects/my-private-bucket/dps_output/run_boreal_biomass_ubuntu/master/2022/02/baseline_run/03/03/08/52/152954/boreal_agb_20220203_0042_cog.tif', '/projects/my-private-bucket/dps_output/run_boreal_biomass_ubuntu/master/2022/02/baseline_run/03/06/47/53/128079/boreal_agb_20220203_0111_cog.tif', '/projects/my-private-bucket/dps_output/run_boreal_biomass_ubuntu/master/2022/02/baseline_run/03/06/59/17/037689/boreal_agb_20220203_0112_cog.tif', '/projects/my-private-bucket/dps_output/run_boreal_biomass_ubuntu/master/2022/02/baseline_run/03/07/25/06/085526/boreal_agb_20220203_0049_cog.tif']\n"
     ]
    }
   ],
   "source": [
    "print(out_files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "operational-average",
   "metadata": {},
   "outputs": [],
   "source": [
    "TEST_SUBDIR = 'add_solar'\n",
    "OUTDIR = f'/projects/my-private-bucket/dps_output/run_boreal_biomass_v2_ubuntu/master/2022/{TEST_SUBDIR}'\n",
    "!python /projects/icesat2_boreal/lib/build_tindex_master.py -y 2022 -m $TEST_SUBDIR -o $OUTDIR"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:root] *",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
